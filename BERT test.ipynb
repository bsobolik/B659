{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT in [flair](https://github.com/zalandoresearch/flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "from typing import List\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to download the corpus from [here](https://github.com/Franck-Dernoncourt/NeuroNER/tree/master/data/conll2003/en). Move the files train.txt, test.txt, and valid.txt to ~/.flair/datasets/conll_03/ and rename valid.txt to dev.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 19:49:35,553 Reading data from /Users/bsobolik/.flair/datasets/conll_03\n",
      "2019-02-07 19:49:35,555 Train: /Users/bsobolik/.flair/datasets/conll_03/train.txt\n",
      "2019-02-07 19:49:35,556 Dev: /Users/bsobolik/.flair/datasets/conll_03/dev.txt\n",
      "2019-02-07 19:49:35,557 Test: /Users/bsobolik/.flair/datasets/conll_03/test.txt\n",
      "TaggedCorpus: 1499 train + 347 dev + 369 test sentences\n"
     ]
    }
   ],
   "source": [
    "# 1. get the corpus\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_corpus(NLPTask.CONLL_03).downsample(0.1)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'<unk>', b'O', b'S-PER', b'S-ORG', b'S-LOC', b'S-MISC', b'B-ORG', b'E-ORG', b'I-ORG', b'B-LOC', b'E-LOC', b'B-PER', b'E-PER', b'B-MISC', b'E-MISC', b'I-PER', b'I-MISC', b'I-LOC', b'<START>', b'<STOP>']\n"
     ]
    }
   ],
   "source": [
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A small test with BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import BertEmbeddings\n",
    "FOLDER = 'resources/taggers/bert_downsampled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. initialize embeddings\n",
    "embeddings = BertEmbeddings(bert_model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. initialize sequence tagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. initialize trainer\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 19:50:04,000 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 19:50:04,001 Evaluation method: MICRO_F1_SCORE\n",
      "2019-02-07 19:50:04,004 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 19:50:10,506 epoch 1 - iter 0/47 - loss 36.39482117\n",
      "2019-02-07 19:50:31,854 epoch 1 - iter 4/47 - loss 36.12932510\n",
      "2019-02-07 19:50:55,618 epoch 1 - iter 8/47 - loss 33.01892959\n",
      "2019-02-07 19:51:18,668 epoch 1 - iter 12/47 - loss 29.56648372\n",
      "2019-02-07 19:51:43,872 epoch 1 - iter 16/47 - loss 27.04365225\n",
      "2019-02-07 19:52:07,631 epoch 1 - iter 20/47 - loss 24.49633689\n",
      "2019-02-07 19:52:31,096 epoch 1 - iter 24/47 - loss 23.29601273\n",
      "2019-02-07 19:52:55,867 epoch 1 - iter 28/47 - loss 22.00649597\n",
      "2019-02-07 19:53:20,062 epoch 1 - iter 32/47 - loss 21.17541409\n",
      "2019-02-07 19:53:52,715 epoch 1 - iter 36/47 - loss 20.72477743\n",
      "2019-02-07 19:54:14,490 epoch 1 - iter 40/47 - loss 20.02066577\n",
      "2019-02-07 19:54:39,663 epoch 1 - iter 44/47 - loss 19.40982721\n",
      "2019-02-07 19:54:49,835 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 19:54:49,836 EPOCH 1 done: loss 19.2821 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 19:55:34,046 DEV  : loss 15.52366924 - f-score 0.0000 - acc 0.0000\n",
      "2019-02-07 19:56:16,396 TEST : loss 11.88866615 - f-score 0.0033 - acc 0.0034\n",
      "2019-02-07 19:56:17,072 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 19:56:19,374 epoch 2 - iter 0/47 - loss 8.51140881\n",
      "2019-02-07 19:56:27,744 epoch 2 - iter 4/47 - loss 12.97361736\n",
      "2019-02-07 19:56:36,516 epoch 2 - iter 8/47 - loss 13.47990587\n",
      "2019-02-07 19:56:49,936 epoch 2 - iter 12/47 - loss 14.00829909\n",
      "2019-02-07 19:57:00,502 epoch 2 - iter 16/47 - loss 13.60828871\n",
      "2019-02-07 19:57:08,612 epoch 2 - iter 20/47 - loss 13.35053353\n",
      "2019-02-07 19:57:16,889 epoch 2 - iter 24/47 - loss 13.41925594\n",
      "2019-02-07 19:57:26,464 epoch 2 - iter 28/47 - loss 13.13666827\n",
      "2019-02-07 19:57:36,459 epoch 2 - iter 32/47 - loss 13.03830358\n",
      "2019-02-07 19:57:45,952 epoch 2 - iter 36/47 - loss 12.87048546\n",
      "2019-02-07 19:57:54,118 epoch 2 - iter 40/47 - loss 12.68762302\n",
      "2019-02-07 19:58:02,701 epoch 2 - iter 44/47 - loss 12.51647597\n",
      "2019-02-07 19:58:06,538 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 19:58:06,539 EPOCH 2 done: loss 12.4361 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 19:58:10,591 DEV  : loss 11.82769299 - f-score 0.0301 - acc 0.0302\n",
      "2019-02-07 19:58:14,239 TEST : loss 8.95782948 - f-score 0.0687 - acc 0.0687\n",
      "2019-02-07 19:58:14,767 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 19:58:17,225 epoch 3 - iter 0/47 - loss 12.44326115\n",
      "2019-02-07 19:58:26,058 epoch 3 - iter 4/47 - loss 11.78805637\n",
      "2019-02-07 19:58:34,189 epoch 3 - iter 8/47 - loss 10.97954867\n",
      "2019-02-07 19:58:44,162 epoch 3 - iter 12/47 - loss 11.12382038\n",
      "2019-02-07 19:58:53,553 epoch 3 - iter 16/47 - loss 10.97949337\n",
      "2019-02-07 19:59:02,244 epoch 3 - iter 20/47 - loss 10.51924821\n",
      "2019-02-07 19:59:10,558 epoch 3 - iter 24/47 - loss 10.45275400\n",
      "2019-02-07 19:59:20,587 epoch 3 - iter 28/47 - loss 10.43336235\n",
      "2019-02-07 19:59:29,088 epoch 3 - iter 32/47 - loss 10.50166068\n",
      "2019-02-07 19:59:37,179 epoch 3 - iter 36/47 - loss 10.37946473\n",
      "2019-02-07 19:59:45,129 epoch 3 - iter 40/47 - loss 10.26397521\n",
      "2019-02-07 19:59:53,474 epoch 3 - iter 44/47 - loss 10.26854225\n",
      "2019-02-07 19:59:57,311 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 19:59:57,312 EPOCH 3 done: loss 10.1271 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:00:01,369 DEV  : loss 9.77264023 - f-score 0.0823 - acc 0.0822\n",
      "2019-02-07 20:00:05,039 TEST : loss 7.28589773 - f-score 0.1345 - acc 0.1346\n",
      "2019-02-07 20:00:05,613 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:00:08,022 epoch 4 - iter 0/47 - loss 9.76924038\n",
      "2019-02-07 20:00:17,116 epoch 4 - iter 4/47 - loss 10.25101032\n",
      "2019-02-07 20:00:25,272 epoch 4 - iter 8/47 - loss 9.86771976\n",
      "2019-02-07 20:00:34,597 epoch 4 - iter 12/47 - loss 9.64320410\n",
      "2019-02-07 20:00:42,939 epoch 4 - iter 16/47 - loss 9.28455263\n",
      "2019-02-07 20:00:52,726 epoch 4 - iter 20/47 - loss 9.25680113\n",
      "2019-02-07 20:01:00,730 epoch 4 - iter 24/47 - loss 9.18388638\n",
      "2019-02-07 20:01:09,019 epoch 4 - iter 28/47 - loss 9.04975566\n",
      "2019-02-07 20:01:17,424 epoch 4 - iter 32/47 - loss 8.93997622\n",
      "2019-02-07 20:01:27,179 epoch 4 - iter 36/47 - loss 8.90285689\n",
      "2019-02-07 20:01:37,210 epoch 4 - iter 40/47 - loss 8.91451568\n",
      "2019-02-07 20:01:44,854 epoch 4 - iter 44/47 - loss 8.79081301\n",
      "2019-02-07 20:01:48,842 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:01:48,843 EPOCH 4 done: loss 8.7196 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:01:53,022 DEV  : loss 8.69266129 - f-score 0.3142 - acc 0.3142\n",
      "2019-02-07 20:01:56,697 TEST : loss 6.40150595 - f-score 0.3448 - acc 0.3448\n",
      "2019-02-07 20:01:57,173 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:01:59,115 epoch 5 - iter 0/47 - loss 8.84221363\n",
      "2019-02-07 20:02:08,462 epoch 5 - iter 4/47 - loss 9.01325569\n",
      "2019-02-07 20:02:17,321 epoch 5 - iter 8/47 - loss 8.67068794\n",
      "2019-02-07 20:02:26,160 epoch 5 - iter 12/47 - loss 8.44087887\n",
      "2019-02-07 20:02:35,298 epoch 5 - iter 16/47 - loss 8.34226973\n",
      "2019-02-07 20:02:43,676 epoch 5 - iter 20/47 - loss 8.04871234\n",
      "2019-02-07 20:02:52,644 epoch 5 - iter 24/47 - loss 8.21187424\n",
      "2019-02-07 20:03:03,433 epoch 5 - iter 28/47 - loss 8.18966111\n",
      "2019-02-07 20:03:10,924 epoch 5 - iter 32/47 - loss 7.98763579\n",
      "2019-02-07 20:03:20,086 epoch 5 - iter 36/47 - loss 7.98213329\n",
      "2019-02-07 20:03:29,437 epoch 5 - iter 40/47 - loss 7.95797870\n",
      "2019-02-07 20:03:37,982 epoch 5 - iter 44/47 - loss 7.91906022\n",
      "2019-02-07 20:03:42,252 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:03:42,253 EPOCH 5 done: loss 7.8931 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:03:46,192 DEV  : loss 7.92944813 - f-score 0.4032 - acc 0.4032\n",
      "2019-02-07 20:03:49,843 TEST : loss 5.76208067 - f-score 0.4362 - acc 0.4362\n",
      "2019-02-07 20:03:50,322 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:03:52,793 epoch 6 - iter 0/47 - loss 11.34704399\n",
      "2019-02-07 20:04:01,178 epoch 6 - iter 4/47 - loss 7.85114737\n",
      "2019-02-07 20:04:10,628 epoch 6 - iter 8/47 - loss 7.47821776\n",
      "2019-02-07 20:04:19,814 epoch 6 - iter 12/47 - loss 7.38710572\n",
      "2019-02-07 20:04:27,512 epoch 6 - iter 16/47 - loss 6.99510709\n",
      "2019-02-07 20:04:38,144 epoch 6 - iter 20/47 - loss 7.05522580\n",
      "2019-02-07 20:04:46,367 epoch 6 - iter 24/47 - loss 7.09352325\n",
      "2019-02-07 20:04:54,893 epoch 6 - iter 28/47 - loss 7.10800503\n",
      "2019-02-07 20:05:03,222 epoch 6 - iter 32/47 - loss 7.13734280\n",
      "2019-02-07 20:05:11,863 epoch 6 - iter 36/47 - loss 7.20527825\n",
      "2019-02-07 20:05:18,790 epoch 6 - iter 40/47 - loss 7.17890188\n",
      "2019-02-07 20:05:26,503 epoch 6 - iter 44/47 - loss 7.20808741\n",
      "2019-02-07 20:05:30,805 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:05:30,806 EPOCH 6 done: loss 7.2381 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:05:34,735 DEV  : loss 7.22357035 - f-score 0.4513 - acc 0.4514\n",
      "2019-02-07 20:05:38,407 TEST : loss 5.19201803 - f-score 0.4821 - acc 0.4821\n",
      "2019-02-07 20:05:38,855 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:05:41,019 epoch 7 - iter 0/47 - loss 8.59280205\n",
      "2019-02-07 20:05:50,329 epoch 7 - iter 4/47 - loss 8.24306488\n",
      "2019-02-07 20:05:58,831 epoch 7 - iter 8/47 - loss 8.12263293\n",
      "2019-02-07 20:06:06,879 epoch 7 - iter 12/47 - loss 7.73522634\n",
      "2019-02-07 20:06:17,415 epoch 7 - iter 16/47 - loss 7.51434551\n",
      "2019-02-07 20:06:25,663 epoch 7 - iter 20/47 - loss 7.37397407\n",
      "2019-02-07 20:06:33,638 epoch 7 - iter 24/47 - loss 7.41231920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 20:06:42,745 epoch 7 - iter 28/47 - loss 7.18696956\n",
      "2019-02-07 20:06:50,788 epoch 7 - iter 32/47 - loss 7.06366932\n",
      "2019-02-07 20:06:59,017 epoch 7 - iter 36/47 - loss 6.94190729\n",
      "2019-02-07 20:07:08,006 epoch 7 - iter 40/47 - loss 6.96630608\n",
      "2019-02-07 20:07:15,932 epoch 7 - iter 44/47 - loss 6.83770725\n",
      "2019-02-07 20:07:20,668 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:07:20,669 EPOCH 7 done: loss 6.8383 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:07:24,479 DEV  : loss 6.59043741 - f-score 0.4931 - acc 0.4931\n",
      "2019-02-07 20:07:27,990 TEST : loss 4.74788666 - f-score 0.5394 - acc 0.5395\n",
      "2019-02-07 20:07:28,428 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:07:30,528 epoch 8 - iter 0/47 - loss 7.10455704\n",
      "2019-02-07 20:07:39,226 epoch 8 - iter 4/47 - loss 6.28868809\n",
      "2019-02-07 20:07:48,169 epoch 8 - iter 8/47 - loss 5.81359037\n",
      "2019-02-07 20:07:56,406 epoch 8 - iter 12/47 - loss 5.93316584\n",
      "2019-02-07 20:08:05,344 epoch 8 - iter 16/47 - loss 6.08107965\n",
      "2019-02-07 20:08:12,944 epoch 8 - iter 20/47 - loss 6.15792386\n",
      "2019-02-07 20:08:21,793 epoch 8 - iter 24/47 - loss 6.25198679\n",
      "2019-02-07 20:08:29,990 epoch 8 - iter 28/47 - loss 6.13011398\n",
      "2019-02-07 20:08:39,139 epoch 8 - iter 32/47 - loss 6.30913044\n",
      "2019-02-07 20:08:47,567 epoch 8 - iter 36/47 - loss 6.24595708\n",
      "2019-02-07 20:08:56,825 epoch 8 - iter 40/47 - loss 6.20910617\n",
      "2019-02-07 20:09:05,849 epoch 8 - iter 44/47 - loss 6.29106064\n",
      "2019-02-07 20:09:10,258 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:09:10,259 EPOCH 8 done: loss 6.2480 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:09:14,220 DEV  : loss 6.04493856 - f-score 0.5316 - acc 0.5316\n",
      "2019-02-07 20:09:17,691 TEST : loss 4.32159519 - f-score 0.5719 - acc 0.5719\n",
      "2019-02-07 20:09:18,132 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:09:20,206 epoch 9 - iter 0/47 - loss 5.69331169\n",
      "2019-02-07 20:09:28,469 epoch 9 - iter 4/47 - loss 5.40251713\n",
      "2019-02-07 20:09:36,922 epoch 9 - iter 8/47 - loss 5.44784546\n",
      "2019-02-07 20:09:45,709 epoch 9 - iter 12/47 - loss 5.57134709\n",
      "2019-02-07 20:09:54,750 epoch 9 - iter 16/47 - loss 5.95875597\n",
      "2019-02-07 20:10:03,290 epoch 9 - iter 20/47 - loss 5.93183288\n",
      "2019-02-07 20:10:11,817 epoch 9 - iter 24/47 - loss 5.81396929\n",
      "2019-02-07 20:10:20,179 epoch 9 - iter 28/47 - loss 5.75154939\n",
      "2019-02-07 20:10:28,593 epoch 9 - iter 32/47 - loss 5.78770049\n",
      "2019-02-07 20:10:36,536 epoch 9 - iter 36/47 - loss 5.70507255\n",
      "2019-02-07 20:10:44,706 epoch 9 - iter 40/47 - loss 5.76753803\n",
      "2019-02-07 20:10:54,260 epoch 9 - iter 44/47 - loss 5.77620163\n",
      "2019-02-07 20:10:57,938 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:10:57,940 EPOCH 9 done: loss 5.8268 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:11:01,893 DEV  : loss 5.57181358 - f-score 0.5664 - acc 0.5664\n",
      "2019-02-07 20:11:06,015 TEST : loss 3.97210217 - f-score 0.6051 - acc 0.6051\n",
      "2019-02-07 20:11:06,902 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:11:09,355 epoch 10 - iter 0/47 - loss 3.84730625\n",
      "2019-02-07 20:11:23,010 epoch 10 - iter 4/47 - loss 4.90346794\n",
      "2019-02-07 20:11:32,139 epoch 10 - iter 8/47 - loss 5.20536274\n",
      "2019-02-07 20:11:44,302 epoch 10 - iter 12/47 - loss 5.34629180\n",
      "2019-02-07 20:11:55,363 epoch 10 - iter 16/47 - loss 5.29014272\n",
      "2019-02-07 20:12:06,819 epoch 10 - iter 20/47 - loss 5.36411615\n",
      "2019-02-07 20:12:17,847 epoch 10 - iter 24/47 - loss 5.48262505\n",
      "2019-02-07 20:12:28,618 epoch 10 - iter 28/47 - loss 5.59736785\n",
      "2019-02-07 20:12:37,681 epoch 10 - iter 32/47 - loss 5.57331446\n",
      "2019-02-07 20:12:47,876 epoch 10 - iter 36/47 - loss 5.52584377\n",
      "2019-02-07 20:12:57,096 epoch 10 - iter 40/47 - loss 5.51607615\n",
      "2019-02-07 20:13:06,276 epoch 10 - iter 44/47 - loss 5.52997504\n",
      "2019-02-07 20:13:11,438 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:13:11,439 EPOCH 10 done: loss 5.5732 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:13:15,909 DEV  : loss 5.22401333 - f-score 0.5899 - acc 0.5899\n",
      "2019-02-07 20:13:19,979 TEST : loss 3.66260982 - f-score 0.6272 - acc 0.6271\n",
      "2019-02-07 20:13:20,417 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:13:23,005 epoch 11 - iter 0/47 - loss 4.21904898\n",
      "2019-02-07 20:13:31,253 epoch 11 - iter 4/47 - loss 4.49520946\n",
      "2019-02-07 20:13:40,479 epoch 11 - iter 8/47 - loss 4.86526010\n",
      "2019-02-07 20:13:49,882 epoch 11 - iter 12/47 - loss 5.38316607\n",
      "2019-02-07 20:13:59,246 epoch 11 - iter 16/47 - loss 5.21592209\n",
      "2019-02-07 20:14:09,143 epoch 11 - iter 20/47 - loss 5.28516298\n",
      "2019-02-07 20:14:19,076 epoch 11 - iter 24/47 - loss 5.09051985\n",
      "2019-02-07 20:14:28,551 epoch 11 - iter 28/47 - loss 5.07559443\n",
      "2019-02-07 20:14:38,029 epoch 11 - iter 32/47 - loss 5.14972367\n",
      "2019-02-07 20:14:48,565 epoch 11 - iter 36/47 - loss 5.03000007\n",
      "2019-02-07 20:14:58,524 epoch 11 - iter 40/47 - loss 5.02582517\n",
      "2019-02-07 20:15:09,218 epoch 11 - iter 44/47 - loss 5.12060088\n",
      "2019-02-07 20:15:14,057 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:15:14,058 EPOCH 11 done: loss 5.0977 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:15:18,556 DEV  : loss 4.90677881 - f-score 0.6063 - acc 0.6063\n",
      "2019-02-07 20:15:22,584 TEST : loss 3.46816969 - f-score 0.6318 - acc 0.6318\n",
      "2019-02-07 20:15:23,180 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:15:26,137 epoch 12 - iter 0/47 - loss 6.81980324\n",
      "2019-02-07 20:15:37,256 epoch 12 - iter 4/47 - loss 5.43486266\n",
      "2019-02-07 20:15:46,776 epoch 12 - iter 8/47 - loss 5.40364244\n",
      "2019-02-07 20:15:55,599 epoch 12 - iter 12/47 - loss 5.31413097\n",
      "2019-02-07 20:16:05,766 epoch 12 - iter 16/47 - loss 5.16057891\n",
      "2019-02-07 20:16:14,568 epoch 12 - iter 20/47 - loss 5.03136995\n",
      "2019-02-07 20:16:24,133 epoch 12 - iter 24/47 - loss 4.99380393\n",
      "2019-02-07 20:16:34,094 epoch 12 - iter 28/47 - loss 4.89654668\n",
      "2019-02-07 20:16:45,445 epoch 12 - iter 32/47 - loss 4.74892536\n",
      "2019-02-07 20:16:56,088 epoch 12 - iter 36/47 - loss 4.93070334\n",
      "2019-02-07 20:17:06,250 epoch 12 - iter 40/47 - loss 4.89424033\n",
      "2019-02-07 20:17:16,307 epoch 12 - iter 44/47 - loss 4.89693636\n",
      "2019-02-07 20:17:21,290 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:17:21,291 EPOCH 12 done: loss 4.8867 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:17:25,779 DEV  : loss 4.67245960 - f-score 0.6422 - acc 0.6421\n",
      "2019-02-07 20:17:29,832 TEST : loss 3.23154664 - f-score 0.6472 - acc 0.6473\n",
      "2019-02-07 20:17:30,265 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:17:33,889 epoch 13 - iter 0/47 - loss 5.15041494\n",
      "2019-02-07 20:17:44,316 epoch 13 - iter 4/47 - loss 4.41921501\n",
      "2019-02-07 20:17:53,677 epoch 13 - iter 8/47 - loss 4.44645614\n",
      "2019-02-07 20:18:02,976 epoch 13 - iter 12/47 - loss 4.70928979\n",
      "2019-02-07 20:18:13,114 epoch 13 - iter 16/47 - loss 4.55808985\n",
      "2019-02-07 20:18:22,602 epoch 13 - iter 20/47 - loss 4.75218247\n",
      "2019-02-07 20:18:31,765 epoch 13 - iter 24/47 - loss 4.74811458\n",
      "2019-02-07 20:18:41,437 epoch 13 - iter 28/47 - loss 4.77200735\n",
      "2019-02-07 20:18:50,938 epoch 13 - iter 32/47 - loss 4.84451324\n",
      "2019-02-07 20:19:01,085 epoch 13 - iter 36/47 - loss 4.79373346\n",
      "2019-02-07 20:19:11,168 epoch 13 - iter 40/47 - loss 4.82512220\n",
      "2019-02-07 20:19:19,703 epoch 13 - iter 44/47 - loss 4.77262403\n",
      "2019-02-07 20:19:24,379 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:19:24,380 EPOCH 13 done: loss 4.7712 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:19:28,983 DEV  : loss 4.41673994 - f-score 0.6575 - acc 0.6575\n",
      "2019-02-07 20:19:33,060 TEST : loss 3.04153299 - f-score 0.6655 - acc 0.6655\n",
      "2019-02-07 20:19:33,520 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 20:19:35,972 epoch 14 - iter 0/47 - loss 4.61798954\n",
      "2019-02-07 20:19:46,456 epoch 14 - iter 4/47 - loss 4.23762321\n",
      "2019-02-07 20:19:57,932 epoch 14 - iter 8/47 - loss 4.56750229\n",
      "2019-02-07 20:20:08,563 epoch 14 - iter 12/47 - loss 4.32303122\n",
      "2019-02-07 20:20:17,627 epoch 14 - iter 16/47 - loss 4.57123899\n",
      "2019-02-07 20:20:27,971 epoch 14 - iter 20/47 - loss 4.63590763\n",
      "2019-02-07 20:20:36,400 epoch 14 - iter 24/47 - loss 4.61749541\n",
      "2019-02-07 20:20:46,195 epoch 14 - iter 28/47 - loss 4.62746041\n",
      "2019-02-07 20:20:56,251 epoch 14 - iter 32/47 - loss 4.59265827\n",
      "2019-02-07 20:21:04,101 epoch 14 - iter 36/47 - loss 4.56437514\n",
      "2019-02-07 20:21:14,799 epoch 14 - iter 40/47 - loss 4.53628238\n",
      "2019-02-07 20:21:24,655 epoch 14 - iter 44/47 - loss 4.62423377\n",
      "2019-02-07 20:21:29,013 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:21:29,014 EPOCH 14 done: loss 4.6014 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:21:33,538 DEV  : loss 4.23129511 - f-score 0.6662 - acc 0.6662\n",
      "2019-02-07 20:21:37,628 TEST : loss 2.87936378 - f-score 0.6661 - acc 0.6661\n",
      "2019-02-07 20:21:38,077 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:21:40,336 epoch 15 - iter 0/47 - loss 2.15486431\n",
      "2019-02-07 20:21:50,694 epoch 15 - iter 4/47 - loss 3.60187330\n",
      "2019-02-07 20:22:00,870 epoch 15 - iter 8/47 - loss 4.06243576\n",
      "2019-02-07 20:22:10,442 epoch 15 - iter 12/47 - loss 4.19427954\n",
      "2019-02-07 20:22:21,306 epoch 15 - iter 16/47 - loss 4.34810183\n",
      "2019-02-07 20:22:30,568 epoch 15 - iter 20/47 - loss 4.20779103\n",
      "2019-02-07 20:22:39,269 epoch 15 - iter 24/47 - loss 4.24803167\n",
      "2019-02-07 20:22:49,739 epoch 15 - iter 28/47 - loss 4.41046277\n",
      "2019-02-07 20:22:58,855 epoch 15 - iter 32/47 - loss 4.40902899\n",
      "2019-02-07 20:23:08,962 epoch 15 - iter 36/47 - loss 4.44693007\n",
      "2019-02-07 20:23:18,537 epoch 15 - iter 40/47 - loss 4.47209166\n",
      "2019-02-07 20:23:27,711 epoch 15 - iter 44/47 - loss 4.51132198\n",
      "2019-02-07 20:23:33,018 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:23:33,019 EPOCH 15 done: loss 4.5188 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:23:37,541 DEV  : loss 4.01471090 - f-score 0.6667 - acc 0.6667\n",
      "2019-02-07 20:23:41,507 TEST : loss 2.75571656 - f-score 0.6786 - acc 0.6786\n",
      "2019-02-07 20:23:41,974 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:23:44,510 epoch 16 - iter 0/47 - loss 2.95197344\n",
      "2019-02-07 20:23:53,679 epoch 16 - iter 4/47 - loss 3.58114200\n",
      "2019-02-07 20:24:02,485 epoch 16 - iter 8/47 - loss 3.28254724\n",
      "2019-02-07 20:24:12,685 epoch 16 - iter 12/47 - loss 3.61316343\n",
      "2019-02-07 20:24:22,552 epoch 16 - iter 16/47 - loss 3.63377798\n",
      "2019-02-07 20:24:30,661 epoch 16 - iter 20/47 - loss 3.91880799\n",
      "2019-02-07 20:24:40,539 epoch 16 - iter 24/47 - loss 4.00949238\n",
      "2019-02-07 20:24:52,339 epoch 16 - iter 28/47 - loss 4.04752258\n",
      "2019-02-07 20:25:02,958 epoch 16 - iter 32/47 - loss 4.19175492\n",
      "2019-02-07 20:25:13,059 epoch 16 - iter 36/47 - loss 4.18707185\n",
      "2019-02-07 20:25:22,049 epoch 16 - iter 40/47 - loss 4.05533083\n",
      "2019-02-07 20:25:33,164 epoch 16 - iter 44/47 - loss 4.20298136\n",
      "2019-02-07 20:25:38,171 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:25:38,173 EPOCH 16 done: loss 4.1932 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:25:42,642 DEV  : loss 3.85564208 - f-score 0.7016 - acc 0.7016\n",
      "2019-02-07 20:25:46,682 TEST : loss 2.61957002 - f-score 0.7072 - acc 0.7072\n",
      "2019-02-07 20:25:47,132 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:25:49,038 epoch 17 - iter 0/47 - loss 2.00913835\n",
      "2019-02-07 20:25:58,213 epoch 17 - iter 4/47 - loss 3.48132415\n",
      "2019-02-07 20:26:08,762 epoch 17 - iter 8/47 - loss 4.66650311\n",
      "2019-02-07 20:26:17,993 epoch 17 - iter 12/47 - loss 4.61991129\n",
      "2019-02-07 20:26:27,146 epoch 17 - iter 16/47 - loss 4.36313744\n",
      "2019-02-07 20:26:35,992 epoch 17 - iter 20/47 - loss 4.20378435\n",
      "2019-02-07 20:26:45,614 epoch 17 - iter 24/47 - loss 4.02608657\n",
      "2019-02-07 20:26:54,413 epoch 17 - iter 28/47 - loss 3.94750995\n",
      "2019-02-07 20:27:04,870 epoch 17 - iter 32/47 - loss 3.99140643\n",
      "2019-02-07 20:27:14,521 epoch 17 - iter 36/47 - loss 4.08391110\n",
      "2019-02-07 20:27:25,939 epoch 17 - iter 40/47 - loss 4.05858681\n",
      "2019-02-07 20:27:36,685 epoch 17 - iter 44/47 - loss 4.06687669\n",
      "2019-02-07 20:27:41,191 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:27:41,193 EPOCH 17 done: loss 4.0966 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:27:45,671 DEV  : loss 3.68280792 - f-score 0.6871 - acc 0.6870\n",
      "2019-02-07 20:27:49,686 TEST : loss 2.51772022 - f-score 0.7150 - acc 0.7150\n",
      "2019-02-07 20:27:50,133 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:27:52,334 epoch 18 - iter 0/47 - loss 2.52839637\n",
      "2019-02-07 20:28:04,060 epoch 18 - iter 4/47 - loss 4.61228967\n",
      "2019-02-07 20:28:13,741 epoch 18 - iter 8/47 - loss 4.18643324\n",
      "2019-02-07 20:28:24,116 epoch 18 - iter 12/47 - loss 4.20870064\n",
      "2019-02-07 20:28:34,078 epoch 18 - iter 16/47 - loss 3.88849588\n",
      "2019-02-07 20:28:43,684 epoch 18 - iter 20/47 - loss 3.96066763\n",
      "2019-02-07 20:28:52,862 epoch 18 - iter 24/47 - loss 3.82944481\n",
      "2019-02-07 20:29:02,410 epoch 18 - iter 28/47 - loss 3.87040122\n",
      "2019-02-07 20:29:11,563 epoch 18 - iter 32/47 - loss 3.84558515\n",
      "2019-02-07 20:29:21,447 epoch 18 - iter 36/47 - loss 3.81282289\n",
      "2019-02-07 20:29:30,816 epoch 18 - iter 40/47 - loss 3.83357338\n",
      "2019-02-07 20:29:40,277 epoch 18 - iter 44/47 - loss 3.86555191\n",
      "2019-02-07 20:29:45,471 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:29:45,472 EPOCH 18 done: loss 3.8678 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:29:50,010 DEV  : loss 3.53310418 - f-score 0.7341 - acc 0.7341\n",
      "2019-02-07 20:29:54,149 TEST : loss 2.38716173 - f-score 0.7430 - acc 0.7430\n",
      "2019-02-07 20:29:54,596 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:29:56,953 epoch 19 - iter 0/47 - loss 5.45512629\n",
      "2019-02-07 20:30:06,192 epoch 19 - iter 4/47 - loss 4.36047659\n",
      "2019-02-07 20:30:17,258 epoch 19 - iter 8/47 - loss 4.07772912\n",
      "2019-02-07 20:30:27,211 epoch 19 - iter 12/47 - loss 4.04242050\n",
      "2019-02-07 20:30:36,061 epoch 19 - iter 16/47 - loss 3.92097521\n",
      "2019-02-07 20:30:48,536 epoch 19 - iter 20/47 - loss 4.13554496\n",
      "2019-02-07 20:30:58,127 epoch 19 - iter 24/47 - loss 3.98248585\n",
      "2019-02-07 20:31:07,769 epoch 19 - iter 28/47 - loss 3.95056614\n",
      "2019-02-07 20:31:17,405 epoch 19 - iter 32/47 - loss 3.85053265\n",
      "2019-02-07 20:31:25,640 epoch 19 - iter 36/47 - loss 3.78684715\n",
      "2019-02-07 20:31:34,278 epoch 19 - iter 40/47 - loss 3.71587950\n",
      "2019-02-07 20:31:44,735 epoch 19 - iter 44/47 - loss 3.74408596\n",
      "2019-02-07 20:31:50,353 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:31:50,354 EPOCH 19 done: loss 3.8149 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:31:54,787 DEV  : loss 3.40638113 - f-score 0.7502 - acc 0.7502\n",
      "2019-02-07 20:31:58,928 TEST : loss 2.30814147 - f-score 0.7485 - acc 0.7485\n",
      "2019-02-07 20:31:59,385 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:32:02,157 epoch 20 - iter 0/47 - loss 4.05460596\n",
      "2019-02-07 20:32:12,334 epoch 20 - iter 4/47 - loss 3.83382902\n",
      "2019-02-07 20:32:22,501 epoch 20 - iter 8/47 - loss 3.67573774\n",
      "2019-02-07 20:32:32,638 epoch 20 - iter 12/47 - loss 3.83621560\n",
      "2019-02-07 20:32:43,079 epoch 20 - iter 16/47 - loss 3.95564940\n",
      "2019-02-07 20:32:51,987 epoch 20 - iter 20/47 - loss 4.01391753\n",
      "2019-02-07 20:33:02,708 epoch 20 - iter 24/47 - loss 3.94535805\n",
      "2019-02-07 20:33:12,644 epoch 20 - iter 28/47 - loss 3.74457616\n",
      "2019-02-07 20:33:20,758 epoch 20 - iter 32/47 - loss 3.66216931\n",
      "2019-02-07 20:33:29,680 epoch 20 - iter 36/47 - loss 3.57623080\n",
      "2019-02-07 20:33:39,754 epoch 20 - iter 40/47 - loss 3.55832388\n",
      "2019-02-07 20:33:49,202 epoch 20 - iter 44/47 - loss 3.45394201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 20:33:55,146 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:33:55,147 EPOCH 20 done: loss 3.4161 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:33:59,646 DEV  : loss 3.28934741 - f-score 0.7517 - acc 0.7517\n",
      "2019-02-07 20:34:03,725 TEST : loss 2.18165946 - f-score 0.7471 - acc 0.7471\n",
      "2019-02-07 20:34:04,162 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:34:06,555 epoch 21 - iter 0/47 - loss 3.92293978\n",
      "2019-02-07 20:34:15,830 epoch 21 - iter 4/47 - loss 3.84797130\n",
      "2019-02-07 20:34:27,008 epoch 21 - iter 8/47 - loss 3.63038966\n",
      "2019-02-07 20:34:36,221 epoch 21 - iter 12/47 - loss 3.43429529\n",
      "2019-02-07 20:34:46,994 epoch 21 - iter 16/47 - loss 3.39675614\n",
      "2019-02-07 20:34:57,260 epoch 21 - iter 20/47 - loss 3.39341038\n",
      "2019-02-07 20:35:06,594 epoch 21 - iter 24/47 - loss 3.26790454\n",
      "2019-02-07 20:35:16,320 epoch 21 - iter 28/47 - loss 3.37286643\n",
      "2019-02-07 20:35:27,422 epoch 21 - iter 32/47 - loss 3.43313352\n",
      "2019-02-07 20:35:36,694 epoch 21 - iter 36/47 - loss 3.52471151\n",
      "2019-02-07 20:35:46,545 epoch 21 - iter 40/47 - loss 3.46047330\n",
      "2019-02-07 20:35:56,166 epoch 21 - iter 44/47 - loss 3.41937118\n",
      "2019-02-07 20:36:01,348 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:36:01,349 EPOCH 21 done: loss 3.4426 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:36:05,937 DEV  : loss 3.18831182 - f-score 0.7630 - acc 0.7630\n",
      "2019-02-07 20:36:09,981 TEST : loss 2.12018418 - f-score 0.7619 - acc 0.7619\n",
      "2019-02-07 20:36:09,983 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:36:12,537 epoch 22 - iter 0/47 - loss 5.62528086\n",
      "2019-02-07 20:36:21,201 epoch 22 - iter 4/47 - loss 3.58632076\n",
      "2019-02-07 20:36:30,540 epoch 22 - iter 8/47 - loss 3.94758356\n",
      "2019-02-07 20:36:41,396 epoch 22 - iter 12/47 - loss 3.73975362\n",
      "2019-02-07 20:36:50,864 epoch 22 - iter 16/47 - loss 3.48429108\n",
      "2019-02-07 20:36:59,764 epoch 22 - iter 20/47 - loss 3.26787355\n",
      "2019-02-07 20:37:09,228 epoch 22 - iter 24/47 - loss 3.26662849\n",
      "2019-02-07 20:37:20,686 epoch 22 - iter 28/47 - loss 3.42011627\n",
      "2019-02-07 20:37:28,137 epoch 22 - iter 32/47 - loss 3.39737127\n",
      "2019-02-07 20:37:37,733 epoch 22 - iter 36/47 - loss 3.37057710\n",
      "2019-02-07 20:37:46,959 epoch 22 - iter 40/47 - loss 3.34633716\n",
      "2019-02-07 20:37:58,196 epoch 22 - iter 44/47 - loss 3.35119280\n",
      "2019-02-07 20:38:02,568 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:38:02,568 EPOCH 22 done: loss 3.3104 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 20:38:07,039 DEV  : loss 3.15846658 - f-score 0.7738 - acc 0.7738\n",
      "2019-02-07 20:38:11,142 TEST : loss 2.02364945 - f-score 0.7698 - acc 0.7698\n",
      "2019-02-07 20:38:11,588 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:38:13,972 epoch 23 - iter 0/47 - loss 4.09139061\n",
      "2019-02-07 20:38:23,954 epoch 23 - iter 4/47 - loss 2.86346521\n",
      "2019-02-07 20:38:34,017 epoch 23 - iter 8/47 - loss 3.10951429\n",
      "2019-02-07 20:38:42,616 epoch 23 - iter 12/47 - loss 2.90211148\n",
      "2019-02-07 20:38:53,180 epoch 23 - iter 16/47 - loss 2.79744337\n",
      "2019-02-07 20:39:04,600 epoch 23 - iter 20/47 - loss 2.75275690\n",
      "2019-02-07 20:39:13,837 epoch 23 - iter 24/47 - loss 2.74672632\n",
      "2019-02-07 20:39:24,423 epoch 23 - iter 28/47 - loss 2.94931659\n",
      "2019-02-07 20:39:33,320 epoch 23 - iter 32/47 - loss 2.99405787\n",
      "2019-02-07 20:39:43,411 epoch 23 - iter 36/47 - loss 3.12283440\n",
      "2019-02-07 20:39:52,967 epoch 23 - iter 40/47 - loss 3.13587339\n",
      "2019-02-07 20:40:03,155 epoch 23 - iter 44/47 - loss 3.14578067\n",
      "2019-02-07 20:40:07,575 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:40:07,576 EPOCH 23 done: loss 3.1190 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:40:12,145 DEV  : loss 3.01202345 - f-score 0.7837 - acc 0.7837\n",
      "2019-02-07 20:40:16,272 TEST : loss 1.96340036 - f-score 0.7850 - acc 0.7850\n",
      "2019-02-07 20:40:16,701 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:40:19,797 epoch 24 - iter 0/47 - loss 4.13467360\n",
      "2019-02-07 20:40:27,923 epoch 24 - iter 4/47 - loss 2.65191574\n",
      "2019-02-07 20:40:40,853 epoch 24 - iter 8/47 - loss 2.77931354\n",
      "2019-02-07 20:40:50,591 epoch 24 - iter 12/47 - loss 2.84880372\n",
      "2019-02-07 20:40:59,704 epoch 24 - iter 16/47 - loss 2.96851465\n",
      "2019-02-07 20:41:09,785 epoch 24 - iter 20/47 - loss 3.09424162\n",
      "2019-02-07 20:41:18,995 epoch 24 - iter 24/47 - loss 3.04600462\n",
      "2019-02-07 20:41:27,896 epoch 24 - iter 28/47 - loss 2.98985979\n",
      "2019-02-07 20:41:38,086 epoch 24 - iter 32/47 - loss 3.01837589\n",
      "2019-02-07 20:41:48,462 epoch 24 - iter 36/47 - loss 3.04550834\n",
      "2019-02-07 20:41:58,606 epoch 24 - iter 40/47 - loss 3.12877297\n",
      "2019-02-07 20:42:07,832 epoch 24 - iter 44/47 - loss 3.18162634\n",
      "2019-02-07 20:42:11,955 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:42:11,956 EPOCH 24 done: loss 3.1840 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:42:16,518 DEV  : loss 2.96728158 - f-score 0.8006 - acc 0.8006\n",
      "2019-02-07 20:42:20,559 TEST : loss 1.90615582 - f-score 0.7882 - acc 0.7882\n",
      "2019-02-07 20:42:20,561 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:42:22,373 epoch 25 - iter 0/47 - loss 1.93163013\n",
      "2019-02-07 20:42:34,226 epoch 25 - iter 4/47 - loss 2.65603437\n",
      "2019-02-07 20:42:44,155 epoch 25 - iter 8/47 - loss 2.70382863\n",
      "2019-02-07 20:42:54,701 epoch 25 - iter 12/47 - loss 2.98480080\n",
      "2019-02-07 20:43:04,760 epoch 25 - iter 16/47 - loss 2.98246813\n",
      "2019-02-07 20:43:13,561 epoch 25 - iter 20/47 - loss 3.03264838\n",
      "2019-02-07 20:43:21,992 epoch 25 - iter 24/47 - loss 3.00112903\n",
      "2019-02-07 20:43:30,975 epoch 25 - iter 28/47 - loss 2.98809386\n",
      "2019-02-07 20:43:40,624 epoch 25 - iter 32/47 - loss 3.14475805\n",
      "2019-02-07 20:43:50,376 epoch 25 - iter 36/47 - loss 3.10367351\n",
      "2019-02-07 20:44:00,716 epoch 25 - iter 40/47 - loss 3.10519669\n",
      "2019-02-07 20:44:09,530 epoch 25 - iter 44/47 - loss 3.13911424\n",
      "2019-02-07 20:44:13,542 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:44:13,543 EPOCH 25 done: loss 3.0946 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 20:44:18,105 DEV  : loss 2.84466577 - f-score 0.8009 - acc 0.8009\n",
      "2019-02-07 20:44:22,196 TEST : loss 1.85705853 - f-score 0.7965 - acc 0.7964\n",
      "2019-02-07 20:44:22,655 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:44:24,234 epoch 26 - iter 0/47 - loss 1.93468678\n",
      "2019-02-07 20:44:32,458 epoch 26 - iter 4/47 - loss 2.35011971\n",
      "2019-02-07 20:44:42,376 epoch 26 - iter 8/47 - loss 2.60098583\n",
      "2019-02-07 20:44:52,240 epoch 26 - iter 12/47 - loss 2.73284903\n",
      "2019-02-07 20:45:01,146 epoch 26 - iter 16/47 - loss 2.69781469\n",
      "2019-02-07 20:45:11,337 epoch 26 - iter 20/47 - loss 2.94631617\n",
      "2019-02-07 20:45:21,387 epoch 26 - iter 24/47 - loss 2.99446291\n",
      "2019-02-07 20:45:30,781 epoch 26 - iter 28/47 - loss 2.94101862\n",
      "2019-02-07 20:45:40,296 epoch 26 - iter 32/47 - loss 2.95613788\n",
      "2019-02-07 20:45:49,405 epoch 26 - iter 36/47 - loss 2.86968222\n",
      "2019-02-07 20:46:00,457 epoch 26 - iter 40/47 - loss 2.85861667\n",
      "2019-02-07 20:46:11,427 epoch 26 - iter 44/47 - loss 2.83926709\n",
      "2019-02-07 20:46:16,348 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:46:16,349 EPOCH 26 done: loss 2.9545 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:46:20,819 DEV  : loss 2.74828458 - f-score 0.8056 - acc 0.8056\n",
      "2019-02-07 20:46:24,988 TEST : loss 1.82101047 - f-score 0.7971 - acc 0.7972\n",
      "2019-02-07 20:46:25,438 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:46:27,968 epoch 27 - iter 0/47 - loss 2.54673171\n",
      "2019-02-07 20:46:38,729 epoch 27 - iter 4/47 - loss 3.25681410\n",
      "2019-02-07 20:46:49,628 epoch 27 - iter 8/47 - loss 3.39703735\n",
      "2019-02-07 20:46:58,420 epoch 27 - iter 12/47 - loss 3.29078536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 20:47:08,048 epoch 27 - iter 16/47 - loss 3.17438847\n",
      "2019-02-07 20:47:18,226 epoch 27 - iter 20/47 - loss 2.99523504\n",
      "2019-02-07 20:47:28,166 epoch 27 - iter 24/47 - loss 3.01629696\n",
      "2019-02-07 20:47:36,858 epoch 27 - iter 28/47 - loss 2.91727894\n",
      "2019-02-07 20:47:46,205 epoch 27 - iter 32/47 - loss 2.87577404\n",
      "2019-02-07 20:47:55,219 epoch 27 - iter 36/47 - loss 2.91327636\n",
      "2019-02-07 20:48:04,584 epoch 27 - iter 40/47 - loss 2.90529425\n",
      "2019-02-07 20:48:15,564 epoch 27 - iter 44/47 - loss 2.87463037\n",
      "2019-02-07 20:48:20,010 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:48:20,011 EPOCH 27 done: loss 2.8529 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:48:24,550 DEV  : loss 2.70928240 - f-score 0.8098 - acc 0.8098\n",
      "2019-02-07 20:48:28,659 TEST : loss 1.75887322 - f-score 0.8075 - acc 0.8075\n",
      "2019-02-07 20:48:29,095 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:48:30,969 epoch 28 - iter 0/47 - loss 1.61554646\n",
      "2019-02-07 20:48:40,948 epoch 28 - iter 4/47 - loss 2.86098814\n",
      "2019-02-07 20:48:49,984 epoch 28 - iter 8/47 - loss 2.45660210\n",
      "2019-02-07 20:49:01,074 epoch 28 - iter 12/47 - loss 2.60528031\n",
      "2019-02-07 20:49:11,317 epoch 28 - iter 16/47 - loss 2.68943425\n",
      "2019-02-07 20:49:20,460 epoch 28 - iter 20/47 - loss 2.89626643\n",
      "2019-02-07 20:49:32,426 epoch 28 - iter 24/47 - loss 2.91655798\n",
      "2019-02-07 20:49:42,050 epoch 28 - iter 28/47 - loss 3.03319064\n",
      "2019-02-07 20:49:51,958 epoch 28 - iter 32/47 - loss 2.94282992\n",
      "2019-02-07 20:50:00,027 epoch 28 - iter 36/47 - loss 2.87435899\n",
      "2019-02-07 20:50:09,066 epoch 28 - iter 40/47 - loss 2.99182283\n",
      "2019-02-07 20:50:19,646 epoch 28 - iter 44/47 - loss 2.98141705\n",
      "2019-02-07 20:50:24,133 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:50:24,134 EPOCH 28 done: loss 2.9465 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:50:28,671 DEV  : loss 2.63492155 - f-score 0.8120 - acc 0.8120\n",
      "2019-02-07 20:50:32,731 TEST : loss 1.74640119 - f-score 0.8018 - acc 0.8018\n",
      "2019-02-07 20:50:32,734 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:50:35,238 epoch 29 - iter 0/47 - loss 3.26105452\n",
      "2019-02-07 20:50:45,189 epoch 29 - iter 4/47 - loss 2.73774574\n",
      "2019-02-07 20:50:54,245 epoch 29 - iter 8/47 - loss 2.73126381\n",
      "2019-02-07 20:51:02,553 epoch 29 - iter 12/47 - loss 2.96750632\n",
      "2019-02-07 20:51:10,954 epoch 29 - iter 16/47 - loss 2.72514379\n",
      "2019-02-07 20:51:21,437 epoch 29 - iter 20/47 - loss 2.69065552\n",
      "2019-02-07 20:51:30,514 epoch 29 - iter 24/47 - loss 2.77057769\n",
      "2019-02-07 20:51:39,520 epoch 29 - iter 28/47 - loss 2.73395160\n",
      "2019-02-07 20:51:48,922 epoch 29 - iter 32/47 - loss 2.81208987\n",
      "2019-02-07 20:51:59,383 epoch 29 - iter 36/47 - loss 2.87097351\n",
      "2019-02-07 20:52:09,436 epoch 29 - iter 40/47 - loss 2.88554426\n",
      "2019-02-07 20:52:20,015 epoch 29 - iter 44/47 - loss 2.85697286\n",
      "2019-02-07 20:52:24,568 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:52:24,569 EPOCH 29 done: loss 2.8646 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 20:52:29,018 DEV  : loss 2.57711458 - f-score 0.8142 - acc 0.8142\n",
      "2019-02-07 20:52:33,070 TEST : loss 1.69438076 - f-score 0.8229 - acc 0.8229\n",
      "2019-02-07 20:52:33,072 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:52:35,521 epoch 30 - iter 0/47 - loss 1.75702643\n",
      "2019-02-07 20:52:45,348 epoch 30 - iter 4/47 - loss 2.06296420\n",
      "2019-02-07 20:52:56,185 epoch 30 - iter 8/47 - loss 2.50565128\n",
      "2019-02-07 20:53:04,988 epoch 30 - iter 12/47 - loss 2.57815576\n",
      "2019-02-07 20:53:15,260 epoch 30 - iter 16/47 - loss 2.72556419\n",
      "2019-02-07 20:53:25,034 epoch 30 - iter 20/47 - loss 2.64817225\n",
      "2019-02-07 20:53:34,280 epoch 30 - iter 24/47 - loss 2.61761293\n",
      "2019-02-07 20:53:43,818 epoch 30 - iter 28/47 - loss 2.60993321\n",
      "2019-02-07 20:53:52,057 epoch 30 - iter 32/47 - loss 2.59534475\n",
      "2019-02-07 20:54:03,900 epoch 30 - iter 36/47 - loss 2.61988283\n",
      "2019-02-07 20:54:13,217 epoch 30 - iter 40/47 - loss 2.59167531\n",
      "2019-02-07 20:54:22,978 epoch 30 - iter 44/47 - loss 2.63856682\n",
      "2019-02-07 20:54:28,041 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:54:28,042 EPOCH 30 done: loss 2.6351 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 20:54:32,481 DEV  : loss 2.55901361 - f-score 0.8207 - acc 0.8207\n",
      "2019-02-07 20:54:36,518 TEST : loss 1.64093745 - f-score 0.8126 - acc 0.8126\n",
      "2019-02-07 20:54:36,976 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:54:39,904 epoch 31 - iter 0/47 - loss 2.65321279\n",
      "2019-02-07 20:54:50,414 epoch 31 - iter 4/47 - loss 2.68556871\n",
      "2019-02-07 20:54:59,600 epoch 31 - iter 8/47 - loss 2.68735223\n",
      "2019-02-07 20:55:08,598 epoch 31 - iter 12/47 - loss 2.78844324\n",
      "2019-02-07 20:55:18,466 epoch 31 - iter 16/47 - loss 2.71672842\n",
      "2019-02-07 20:55:29,143 epoch 31 - iter 20/47 - loss 2.67027739\n",
      "2019-02-07 20:55:39,365 epoch 31 - iter 24/47 - loss 2.66966947\n",
      "2019-02-07 20:55:48,397 epoch 31 - iter 28/47 - loss 2.60233600\n",
      "2019-02-07 20:55:57,873 epoch 31 - iter 32/47 - loss 2.71297106\n",
      "2019-02-07 20:56:07,096 epoch 31 - iter 36/47 - loss 2.74844559\n",
      "2019-02-07 20:56:18,355 epoch 31 - iter 40/47 - loss 2.78282246\n",
      "2019-02-07 20:56:28,894 epoch 31 - iter 44/47 - loss 2.73001702\n",
      "2019-02-07 20:56:33,319 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:56:33,321 EPOCH 31 done: loss 2.6801 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 20:56:37,902 DEV  : loss 2.45702219 - f-score 0.8237 - acc 0.8237\n",
      "2019-02-07 20:56:42,136 TEST : loss 1.61524475 - f-score 0.8172 - acc 0.8171\n",
      "2019-02-07 20:56:42,138 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:56:44,964 epoch 32 - iter 0/47 - loss 3.48624659\n",
      "2019-02-07 20:56:54,565 epoch 32 - iter 4/47 - loss 2.37843482\n",
      "2019-02-07 20:57:05,547 epoch 32 - iter 8/47 - loss 2.56211657\n",
      "2019-02-07 20:57:14,409 epoch 32 - iter 12/47 - loss 2.53546725\n",
      "2019-02-07 20:57:24,279 epoch 32 - iter 16/47 - loss 2.58125415\n",
      "2019-02-07 20:57:34,364 epoch 32 - iter 20/47 - loss 2.50399801\n",
      "2019-02-07 20:57:42,628 epoch 32 - iter 24/47 - loss 2.40614245\n",
      "2019-02-07 20:57:51,021 epoch 32 - iter 28/47 - loss 2.37851988\n",
      "2019-02-07 20:58:01,427 epoch 32 - iter 32/47 - loss 2.38612337\n",
      "2019-02-07 20:58:11,958 epoch 32 - iter 36/47 - loss 2.49386052\n",
      "2019-02-07 20:58:21,112 epoch 32 - iter 40/47 - loss 2.53693648\n",
      "2019-02-07 20:58:30,517 epoch 32 - iter 44/47 - loss 2.54374726\n",
      "2019-02-07 20:58:35,288 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:58:35,289 EPOCH 32 done: loss 2.5814 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 20:58:39,801 DEV  : loss 2.43373799 - f-score 0.8243 - acc 0.8243\n",
      "2019-02-07 20:58:43,855 TEST : loss 1.59244299 - f-score 0.8167 - acc 0.8167\n",
      "2019-02-07 20:58:44,305 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 20:58:46,484 epoch 33 - iter 0/47 - loss 2.28731704\n",
      "2019-02-07 20:58:55,962 epoch 33 - iter 4/47 - loss 1.96054051\n",
      "2019-02-07 20:59:08,045 epoch 33 - iter 8/47 - loss 2.09475805\n",
      "2019-02-07 20:59:22,393 epoch 33 - iter 12/47 - loss 2.21966469\n",
      "2019-02-07 20:59:31,075 epoch 33 - iter 16/47 - loss 2.09601257\n",
      "2019-02-07 20:59:42,143 epoch 33 - iter 20/47 - loss 2.20025074\n",
      "2019-02-07 20:59:51,588 epoch 33 - iter 24/47 - loss 2.13587052\n",
      "2019-02-07 21:00:01,267 epoch 33 - iter 28/47 - loss 2.11619480\n",
      "2019-02-07 21:00:11,714 epoch 33 - iter 32/47 - loss 2.16284044\n",
      "2019-02-07 21:00:19,850 epoch 33 - iter 36/47 - loss 2.17786556\n",
      "2019-02-07 21:00:28,494 epoch 33 - iter 40/47 - loss 2.21953207\n",
      "2019-02-07 21:00:37,018 epoch 33 - iter 44/47 - loss 2.26153241\n",
      "2019-02-07 21:00:42,041 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:00:42,042 EPOCH 33 done: loss 2.2824 - lr 0.1000 - bad epochs 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 21:00:45,927 DEV  : loss 2.35975170 - f-score 0.8328 - acc 0.8328\n",
      "2019-02-07 21:00:49,583 TEST : loss 1.56778705 - f-score 0.8242 - acc 0.8243\n",
      "2019-02-07 21:00:50,025 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:00:53,658 epoch 34 - iter 0/47 - loss 2.70491982\n",
      "2019-02-07 21:01:04,056 epoch 34 - iter 4/47 - loss 2.14563034\n",
      "2019-02-07 21:01:15,061 epoch 34 - iter 8/47 - loss 2.34773085\n",
      "2019-02-07 21:01:23,715 epoch 34 - iter 12/47 - loss 2.46666934\n",
      "2019-02-07 21:01:33,595 epoch 34 - iter 16/47 - loss 2.47693914\n",
      "2019-02-07 21:01:42,969 epoch 34 - iter 20/47 - loss 2.35801746\n",
      "2019-02-07 21:01:52,596 epoch 34 - iter 24/47 - loss 2.29955460\n",
      "2019-02-07 21:02:01,018 epoch 34 - iter 28/47 - loss 2.37610579\n",
      "2019-02-07 21:02:09,313 epoch 34 - iter 32/47 - loss 2.31422712\n",
      "2019-02-07 21:02:17,131 epoch 34 - iter 36/47 - loss 2.27687943\n",
      "2019-02-07 21:02:27,228 epoch 34 - iter 40/47 - loss 2.33603138\n",
      "2019-02-07 21:02:36,546 epoch 34 - iter 44/47 - loss 2.32549285\n",
      "2019-02-07 21:02:40,187 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:02:40,188 EPOCH 34 done: loss 2.3154 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 21:02:44,069 DEV  : loss 2.35312533 - f-score 0.8295 - acc 0.8295\n",
      "2019-02-07 21:02:47,924 TEST : loss 1.51462340 - f-score 0.8308 - acc 0.8308\n",
      "2019-02-07 21:02:47,926 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:02:49,977 epoch 35 - iter 0/47 - loss 2.44515729\n",
      "2019-02-07 21:02:58,370 epoch 35 - iter 4/47 - loss 2.44163713\n",
      "2019-02-07 21:03:09,085 epoch 35 - iter 8/47 - loss 2.64424215\n",
      "2019-02-07 21:03:17,905 epoch 35 - iter 12/47 - loss 2.57447711\n",
      "2019-02-07 21:03:26,587 epoch 35 - iter 16/47 - loss 2.47423234\n",
      "2019-02-07 21:03:35,393 epoch 35 - iter 20/47 - loss 2.45457768\n",
      "2019-02-07 21:03:45,330 epoch 35 - iter 24/47 - loss 2.34390298\n",
      "2019-02-07 21:03:54,690 epoch 35 - iter 28/47 - loss 2.31604613\n",
      "2019-02-07 21:04:02,776 epoch 35 - iter 32/47 - loss 2.27707175\n",
      "2019-02-07 21:04:12,477 epoch 35 - iter 36/47 - loss 2.35985436\n",
      "2019-02-07 21:04:20,427 epoch 35 - iter 40/47 - loss 2.30445854\n",
      "2019-02-07 21:04:29,577 epoch 35 - iter 44/47 - loss 2.30404572\n",
      "2019-02-07 21:04:35,925 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:04:35,926 EPOCH 35 done: loss 2.3270 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 21:04:40,641 DEV  : loss 2.30487847 - f-score 0.8285 - acc 0.8285\n",
      "2019-02-07 21:04:44,728 TEST : loss 1.50329304 - f-score 0.8257 - acc 0.8257\n",
      "2019-02-07 21:04:44,730 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:04:48,553 epoch 36 - iter 0/47 - loss 2.48224139\n",
      "2019-02-07 21:04:57,152 epoch 36 - iter 4/47 - loss 2.12126696\n",
      "2019-02-07 21:05:05,819 epoch 36 - iter 8/47 - loss 2.21373170\n",
      "2019-02-07 21:05:16,241 epoch 36 - iter 12/47 - loss 2.17931956\n",
      "2019-02-07 21:05:26,149 epoch 36 - iter 16/47 - loss 2.12401659\n",
      "2019-02-07 21:05:35,266 epoch 36 - iter 20/47 - loss 2.11243860\n",
      "2019-02-07 21:05:43,775 epoch 36 - iter 24/47 - loss 2.11093933\n",
      "2019-02-07 21:05:53,345 epoch 36 - iter 28/47 - loss 2.19777710\n",
      "2019-02-07 21:06:02,503 epoch 36 - iter 32/47 - loss 2.24084877\n",
      "2019-02-07 21:06:10,719 epoch 36 - iter 36/47 - loss 2.17567099\n",
      "2019-02-07 21:06:18,875 epoch 36 - iter 40/47 - loss 2.16451299\n",
      "2019-02-07 21:06:27,541 epoch 36 - iter 44/47 - loss 2.16769466\n",
      "2019-02-07 21:06:32,618 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:06:32,619 EPOCH 36 done: loss 2.1635 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 21:06:36,489 DEV  : loss 2.33162451 - f-score 0.8382 - acc 0.8382\n",
      "2019-02-07 21:06:40,024 TEST : loss 1.46552789 - f-score 0.8368 - acc 0.8368\n",
      "2019-02-07 21:06:40,478 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:06:42,102 epoch 37 - iter 0/47 - loss 2.07468390\n",
      "2019-02-07 21:06:51,889 epoch 37 - iter 4/47 - loss 3.21789536\n",
      "2019-02-07 21:07:00,912 epoch 37 - iter 8/47 - loss 2.64679302\n",
      "2019-02-07 21:07:09,818 epoch 37 - iter 12/47 - loss 2.60942088\n",
      "2019-02-07 21:07:21,346 epoch 37 - iter 16/47 - loss 2.36722839\n",
      "2019-02-07 21:07:29,876 epoch 37 - iter 20/47 - loss 2.38275139\n",
      "2019-02-07 21:07:38,513 epoch 37 - iter 24/47 - loss 2.27621059\n",
      "2019-02-07 21:07:46,756 epoch 37 - iter 28/47 - loss 2.23269004\n",
      "2019-02-07 21:07:55,475 epoch 37 - iter 32/47 - loss 2.27768275\n",
      "2019-02-07 21:08:05,386 epoch 37 - iter 36/47 - loss 2.23953912\n",
      "2019-02-07 21:08:13,387 epoch 37 - iter 40/47 - loss 2.18349897\n",
      "2019-02-07 21:08:23,555 epoch 37 - iter 44/47 - loss 2.17631358\n",
      "2019-02-07 21:08:27,864 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:08:27,865 EPOCH 37 done: loss 2.1619 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 21:08:32,004 DEV  : loss 2.24010324 - f-score 0.8448 - acc 0.8448\n",
      "2019-02-07 21:08:35,850 TEST : loss 1.48812902 - f-score 0.8477 - acc 0.8477\n",
      "2019-02-07 21:08:36,311 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:08:38,671 epoch 38 - iter 0/47 - loss 2.55930781\n",
      "2019-02-07 21:08:48,041 epoch 38 - iter 4/47 - loss 2.50799403\n",
      "2019-02-07 21:08:57,306 epoch 38 - iter 8/47 - loss 2.28365990\n",
      "2019-02-07 21:09:06,498 epoch 38 - iter 12/47 - loss 2.47745821\n",
      "2019-02-07 21:09:15,535 epoch 38 - iter 16/47 - loss 2.43298507\n",
      "2019-02-07 21:09:24,100 epoch 38 - iter 20/47 - loss 2.27961273\n",
      "2019-02-07 21:09:32,719 epoch 38 - iter 24/47 - loss 2.24772856\n",
      "2019-02-07 21:09:43,699 epoch 38 - iter 28/47 - loss 2.32667119\n",
      "2019-02-07 21:09:52,795 epoch 38 - iter 32/47 - loss 2.35443894\n",
      "2019-02-07 21:10:01,875 epoch 38 - iter 36/47 - loss 2.40215107\n",
      "2019-02-07 21:10:12,076 epoch 38 - iter 40/47 - loss 2.33891782\n",
      "2019-02-07 21:10:20,937 epoch 38 - iter 44/47 - loss 2.34483958\n",
      "2019-02-07 21:10:25,219 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:10:25,220 EPOCH 38 done: loss 2.3948 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 21:10:29,354 DEV  : loss 2.21557331 - f-score 0.8442 - acc 0.8442\n",
      "2019-02-07 21:10:33,147 TEST : loss 1.44534826 - f-score 0.8466 - acc 0.8466\n",
      "2019-02-07 21:10:33,149 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:10:35,775 epoch 39 - iter 0/47 - loss 1.64120793\n",
      "2019-02-07 21:10:46,628 epoch 39 - iter 4/47 - loss 2.39325356\n",
      "2019-02-07 21:10:57,815 epoch 39 - iter 8/47 - loss 2.17423152\n",
      "2019-02-07 21:11:09,226 epoch 39 - iter 12/47 - loss 2.62674103\n",
      "2019-02-07 21:11:20,204 epoch 39 - iter 16/47 - loss 2.67300838\n",
      "2019-02-07 21:11:29,545 epoch 39 - iter 20/47 - loss 2.53859773\n",
      "2019-02-07 21:11:38,836 epoch 39 - iter 24/47 - loss 2.48510451\n",
      "2019-02-07 21:11:47,649 epoch 39 - iter 28/47 - loss 2.43363415\n",
      "2019-02-07 21:11:57,806 epoch 39 - iter 32/47 - loss 2.44985617\n",
      "2019-02-07 21:12:09,186 epoch 39 - iter 36/47 - loss 2.38790947\n",
      "2019-02-07 21:12:17,644 epoch 39 - iter 40/47 - loss 2.36169221\n",
      "2019-02-07 21:12:27,569 epoch 39 - iter 44/47 - loss 2.26225242\n",
      "2019-02-07 21:12:32,916 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:12:32,916 EPOCH 39 done: loss 2.2847 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 21:12:36,835 DEV  : loss 2.22082829 - f-score 0.8426 - acc 0.8426\n",
      "2019-02-07 21:12:40,460 TEST : loss 1.41268051 - f-score 0.8381 - acc 0.8381\n",
      "2019-02-07 21:12:40,461 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:12:43,759 epoch 40 - iter 0/47 - loss 2.80047393\n",
      "2019-02-07 21:12:52,852 epoch 40 - iter 4/47 - loss 2.73734729\n",
      "2019-02-07 21:13:01,364 epoch 40 - iter 8/47 - loss 2.24735377\n",
      "2019-02-07 21:13:10,532 epoch 40 - iter 12/47 - loss 2.01616958\n",
      "2019-02-07 21:13:20,206 epoch 40 - iter 16/47 - loss 2.03483711\n",
      "2019-02-07 21:13:28,709 epoch 40 - iter 20/47 - loss 2.01763767\n",
      "2019-02-07 21:13:37,269 epoch 40 - iter 24/47 - loss 1.95797328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 21:13:45,504 epoch 40 - iter 28/47 - loss 1.89339962\n",
      "2019-02-07 21:13:53,383 epoch 40 - iter 32/47 - loss 1.88806065\n",
      "2019-02-07 21:14:01,955 epoch 40 - iter 36/47 - loss 1.84681025\n",
      "2019-02-07 21:14:11,362 epoch 40 - iter 40/47 - loss 1.86890572\n",
      "2019-02-07 21:14:20,900 epoch 40 - iter 44/47 - loss 1.93826836\n",
      "2019-02-07 21:14:25,268 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:14:25,269 EPOCH 40 done: loss 1.9597 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 21:14:29,134 DEV  : loss 2.13464141 - f-score 0.8472 - acc 0.8472\n",
      "2019-02-07 21:14:32,679 TEST : loss 1.42769837 - f-score 0.8549 - acc 0.8548\n",
      "2019-02-07 21:14:33,137 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:14:35,187 epoch 41 - iter 0/47 - loss 1.93415225\n",
      "2019-02-07 21:14:45,881 epoch 41 - iter 4/47 - loss 2.38064976\n",
      "2019-02-07 21:14:55,323 epoch 41 - iter 8/47 - loss 2.05729205\n",
      "2019-02-07 21:15:04,711 epoch 41 - iter 12/47 - loss 1.98422250\n",
      "2019-02-07 21:15:14,019 epoch 41 - iter 16/47 - loss 2.10856500\n",
      "2019-02-07 21:15:22,413 epoch 41 - iter 20/47 - loss 2.08668638\n",
      "2019-02-07 21:15:30,670 epoch 41 - iter 24/47 - loss 2.04128152\n",
      "2019-02-07 21:15:38,635 epoch 41 - iter 28/47 - loss 2.05564626\n",
      "2019-02-07 21:15:46,392 epoch 41 - iter 32/47 - loss 2.09959840\n",
      "2019-02-07 21:15:55,032 epoch 41 - iter 36/47 - loss 2.17929392\n",
      "2019-02-07 21:16:03,355 epoch 41 - iter 40/47 - loss 2.16515468\n",
      "2019-02-07 21:16:13,937 epoch 41 - iter 44/47 - loss 2.13918180\n",
      "2019-02-07 21:16:18,310 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:16:18,311 EPOCH 41 done: loss 2.1128 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 21:16:22,410 DEV  : loss 2.18171668 - f-score 0.8544 - acc 0.8544\n",
      "2019-02-07 21:16:26,100 TEST : loss 1.38433266 - f-score 0.8505 - acc 0.8505\n",
      "2019-02-07 21:16:26,102 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:16:27,951 epoch 42 - iter 0/47 - loss 1.69790435\n",
      "2019-02-07 21:16:38,492 epoch 42 - iter 4/47 - loss 2.87022417\n",
      "2019-02-07 21:16:47,795 epoch 42 - iter 8/47 - loss 2.34728763\n",
      "2019-02-07 21:16:56,815 epoch 42 - iter 12/47 - loss 2.26862346\n",
      "2019-02-07 21:17:04,540 epoch 42 - iter 16/47 - loss 2.16359696\n",
      "2019-02-07 21:17:14,257 epoch 42 - iter 20/47 - loss 2.09665565\n",
      "2019-02-07 21:17:22,198 epoch 42 - iter 24/47 - loss 2.03496267\n",
      "2019-02-07 21:17:30,678 epoch 42 - iter 28/47 - loss 1.92685579\n",
      "2019-02-07 21:17:40,384 epoch 42 - iter 32/47 - loss 2.07276471\n",
      "2019-02-07 21:17:49,069 epoch 42 - iter 36/47 - loss 2.15383613\n",
      "2019-02-07 21:17:58,315 epoch 42 - iter 40/47 - loss 2.14481556\n",
      "2019-02-07 21:18:08,274 epoch 42 - iter 44/47 - loss 2.18112227\n",
      "2019-02-07 21:18:12,326 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:18:12,328 EPOCH 42 done: loss 2.1660 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 21:18:16,259 DEV  : loss 2.12241483 - f-score 0.8553 - acc 0.8553\n",
      "2019-02-07 21:18:19,803 TEST : loss 1.36552751 - f-score 0.8561 - acc 0.8561\n",
      "2019-02-07 21:18:19,805 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:18:21,727 epoch 43 - iter 0/47 - loss 0.78629255\n",
      "2019-02-07 21:18:29,684 epoch 43 - iter 4/47 - loss 1.86159513\n",
      "2019-02-07 21:18:39,919 epoch 43 - iter 8/47 - loss 2.16131763\n",
      "2019-02-07 21:18:51,283 epoch 43 - iter 12/47 - loss 2.07522049\n",
      "2019-02-07 21:19:00,592 epoch 43 - iter 16/47 - loss 1.92028999\n",
      "2019-02-07 21:19:09,027 epoch 43 - iter 20/47 - loss 1.84124852\n",
      "2019-02-07 21:19:16,531 epoch 43 - iter 24/47 - loss 1.77756447\n",
      "2019-02-07 21:19:24,721 epoch 43 - iter 28/47 - loss 1.89372792\n",
      "2019-02-07 21:19:33,641 epoch 43 - iter 32/47 - loss 1.86099018\n",
      "2019-02-07 21:19:43,905 epoch 43 - iter 36/47 - loss 2.02683783\n",
      "2019-02-07 21:19:52,149 epoch 43 - iter 40/47 - loss 1.96118250\n",
      "2019-02-07 21:20:01,272 epoch 43 - iter 44/47 - loss 1.95525269\n",
      "2019-02-07 21:20:05,931 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:20:05,932 EPOCH 43 done: loss 1.9924 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 21:20:09,807 DEV  : loss 2.08519316 - f-score 0.8524 - acc 0.8524\n",
      "2019-02-07 21:20:13,326 TEST : loss 1.36322284 - f-score 0.8636 - acc 0.8636\n",
      "2019-02-07 21:20:13,327 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:20:15,512 epoch 44 - iter 0/47 - loss 2.66974306\n",
      "2019-02-07 21:20:24,835 epoch 44 - iter 4/47 - loss 1.79448233\n",
      "2019-02-07 21:20:33,558 epoch 44 - iter 8/47 - loss 1.88944851\n",
      "2019-02-07 21:20:42,780 epoch 44 - iter 12/47 - loss 2.10151791\n",
      "2019-02-07 21:20:50,570 epoch 44 - iter 16/47 - loss 2.02075311\n",
      "2019-02-07 21:20:59,126 epoch 44 - iter 20/47 - loss 2.05859024\n",
      "2019-02-07 21:21:08,492 epoch 44 - iter 24/47 - loss 1.97393245\n",
      "2019-02-07 21:21:18,438 epoch 44 - iter 28/47 - loss 1.99454953\n",
      "2019-02-07 21:21:27,349 epoch 44 - iter 32/47 - loss 2.07547708\n",
      "2019-02-07 21:21:35,756 epoch 44 - iter 36/47 - loss 2.14531216\n",
      "2019-02-07 21:21:43,373 epoch 44 - iter 40/47 - loss 2.12397511\n",
      "2019-02-07 21:21:54,022 epoch 44 - iter 44/47 - loss 2.14581860\n",
      "2019-02-07 21:21:58,670 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:21:58,672 EPOCH 44 done: loss 2.1052 - lr 0.1000 - bad epochs 3\n",
      "2019-02-07 21:22:02,566 DEV  : loss 2.06481743 - f-score 0.8578 - acc 0.8578\n",
      "2019-02-07 21:22:06,134 TEST : loss 1.35636389 - f-score 0.8569 - acc 0.8569\n",
      "Epoch    43: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-02-07 21:22:06,136 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:22:07,952 epoch 45 - iter 0/47 - loss 0.76080227\n",
      "2019-02-07 21:22:17,885 epoch 45 - iter 4/47 - loss 1.69664507\n",
      "2019-02-07 21:22:26,091 epoch 45 - iter 8/47 - loss 1.76095964\n",
      "2019-02-07 21:22:38,055 epoch 45 - iter 12/47 - loss 1.91052385\n",
      "2019-02-07 21:22:47,431 epoch 45 - iter 16/47 - loss 1.83187835\n",
      "2019-02-07 21:22:57,506 epoch 45 - iter 20/47 - loss 1.89545048\n",
      "2019-02-07 21:23:09,114 epoch 45 - iter 24/47 - loss 1.89928682\n",
      "2019-02-07 21:23:18,027 epoch 45 - iter 28/47 - loss 1.82695623\n",
      "2019-02-07 21:23:26,141 epoch 45 - iter 32/47 - loss 1.76794219\n",
      "2019-02-07 21:23:36,884 epoch 45 - iter 36/47 - loss 1.86564680\n",
      "2019-02-07 21:23:47,192 epoch 45 - iter 40/47 - loss 1.98550953\n",
      "2019-02-07 21:23:55,179 epoch 45 - iter 44/47 - loss 1.95267413\n",
      "2019-02-07 21:23:59,305 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:23:59,306 EPOCH 45 done: loss 1.9625 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 21:24:03,324 DEV  : loss 2.05104566 - f-score 0.8565 - acc 0.8565\n",
      "2019-02-07 21:24:06,981 TEST : loss 1.34565270 - f-score 0.8703 - acc 0.8704\n",
      "2019-02-07 21:24:06,983 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:24:09,250 epoch 46 - iter 0/47 - loss 2.06939435\n",
      "2019-02-07 21:24:17,725 epoch 46 - iter 4/47 - loss 2.47722874\n",
      "2019-02-07 21:24:25,904 epoch 46 - iter 8/47 - loss 2.26339167\n",
      "2019-02-07 21:24:35,936 epoch 46 - iter 12/47 - loss 2.02025772\n",
      "2019-02-07 21:24:47,287 epoch 46 - iter 16/47 - loss 1.88611205\n",
      "2019-02-07 21:24:57,775 epoch 46 - iter 20/47 - loss 1.91275895\n",
      "2019-02-07 21:25:07,031 epoch 46 - iter 24/47 - loss 1.89603555\n",
      "2019-02-07 21:25:15,767 epoch 46 - iter 28/47 - loss 2.00371379\n",
      "2019-02-07 21:25:26,604 epoch 46 - iter 32/47 - loss 2.02368374\n",
      "2019-02-07 21:25:35,860 epoch 46 - iter 36/47 - loss 2.00462388\n",
      "2019-02-07 21:25:43,547 epoch 46 - iter 40/47 - loss 1.99324270\n",
      "2019-02-07 21:25:52,120 epoch 46 - iter 44/47 - loss 1.95842203\n",
      "2019-02-07 21:25:56,172 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:25:56,174 EPOCH 46 done: loss 1.9408 - lr 0.0500 - bad epochs 1\n",
      "2019-02-07 21:26:00,096 DEV  : loss 2.04823756 - f-score 0.8513 - acc 0.8512\n",
      "2019-02-07 21:26:03,883 TEST : loss 1.34324300 - f-score 0.8690 - acc 0.8690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 21:26:04,327 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:26:06,286 epoch 47 - iter 0/47 - loss 2.34344530\n",
      "2019-02-07 21:26:14,967 epoch 47 - iter 4/47 - loss 1.54251854\n",
      "2019-02-07 21:26:24,932 epoch 47 - iter 8/47 - loss 1.73952583\n",
      "2019-02-07 21:26:33,526 epoch 47 - iter 12/47 - loss 1.76866619\n",
      "2019-02-07 21:26:43,166 epoch 47 - iter 16/47 - loss 1.64299885\n",
      "2019-02-07 21:26:52,825 epoch 47 - iter 20/47 - loss 1.83233272\n",
      "2019-02-07 21:27:02,110 epoch 47 - iter 24/47 - loss 1.95590379\n",
      "2019-02-07 21:27:12,883 epoch 47 - iter 28/47 - loss 1.98093320\n",
      "2019-02-07 21:27:21,696 epoch 47 - iter 32/47 - loss 1.96847246\n",
      "2019-02-07 21:27:31,576 epoch 47 - iter 36/47 - loss 1.92268818\n",
      "2019-02-07 21:27:41,927 epoch 47 - iter 40/47 - loss 1.92663670\n",
      "2019-02-07 21:27:52,540 epoch 47 - iter 44/47 - loss 1.86951336\n",
      "2019-02-07 21:27:57,569 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:27:57,571 EPOCH 47 done: loss 1.8610 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 21:28:02,426 DEV  : loss 2.05311084 - f-score 0.8558 - acc 0.8558\n",
      "2019-02-07 21:28:06,458 TEST : loss 1.33425486 - f-score 0.8672 - acc 0.8672\n",
      "2019-02-07 21:28:06,906 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:28:09,325 epoch 48 - iter 0/47 - loss 1.99291646\n",
      "2019-02-07 21:28:18,373 epoch 48 - iter 4/47 - loss 1.83162459\n",
      "2019-02-07 21:28:30,446 epoch 48 - iter 8/47 - loss 1.69356777\n",
      "2019-02-07 21:28:39,571 epoch 48 - iter 12/47 - loss 1.90547982\n",
      "2019-02-07 21:28:49,043 epoch 48 - iter 16/47 - loss 1.78565319\n",
      "2019-02-07 21:28:57,820 epoch 48 - iter 20/47 - loss 1.85724772\n",
      "2019-02-07 21:29:07,633 epoch 48 - iter 24/47 - loss 1.87812767\n",
      "2019-02-07 21:29:18,125 epoch 48 - iter 28/47 - loss 1.84682475\n",
      "2019-02-07 21:29:27,225 epoch 48 - iter 32/47 - loss 1.75897682\n",
      "2019-02-07 21:29:37,662 epoch 48 - iter 36/47 - loss 1.76517407\n",
      "2019-02-07 21:29:46,889 epoch 48 - iter 40/47 - loss 1.74735617\n",
      "2019-02-07 21:29:55,826 epoch 48 - iter 44/47 - loss 1.85983309\n",
      "2019-02-07 21:30:00,632 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:30:00,633 EPOCH 48 done: loss 1.8633 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 21:30:05,128 DEV  : loss 2.04257131 - f-score 0.8549 - acc 0.8549\n",
      "2019-02-07 21:30:09,423 TEST : loss 1.32783616 - f-score 0.8584 - acc 0.8584\n",
      "2019-02-07 21:30:09,425 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:30:11,744 epoch 49 - iter 0/47 - loss 1.30926847\n",
      "2019-02-07 21:30:20,030 epoch 49 - iter 4/47 - loss 2.00507147\n",
      "2019-02-07 21:30:33,173 epoch 49 - iter 8/47 - loss 1.99401524\n",
      "2019-02-07 21:30:50,231 epoch 49 - iter 12/47 - loss 2.03529284\n",
      "2019-02-07 21:31:03,832 epoch 49 - iter 16/47 - loss 2.02312026\n",
      "2019-02-07 21:31:14,103 epoch 49 - iter 20/47 - loss 1.97454774\n",
      "2019-02-07 21:31:25,569 epoch 49 - iter 24/47 - loss 2.00629494\n",
      "2019-02-07 21:31:37,666 epoch 49 - iter 28/47 - loss 1.93920868\n",
      "2019-02-07 21:31:46,125 epoch 49 - iter 32/47 - loss 1.93528373\n",
      "2019-02-07 21:31:54,882 epoch 49 - iter 36/47 - loss 1.82182968\n",
      "2019-02-07 21:32:03,841 epoch 49 - iter 40/47 - loss 1.90656196\n",
      "2019-02-07 21:32:13,320 epoch 49 - iter 44/47 - loss 1.91243694\n",
      "2019-02-07 21:32:17,382 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:32:17,383 EPOCH 49 done: loss 1.9177 - lr 0.0500 - bad epochs 1\n",
      "2019-02-07 21:32:21,119 DEV  : loss 2.07849216 - f-score 0.8619 - acc 0.8620\n",
      "2019-02-07 21:32:24,561 TEST : loss 1.31730247 - f-score 0.8597 - acc 0.8597\n",
      "2019-02-07 21:32:24,562 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:32:26,798 epoch 50 - iter 0/47 - loss 1.72499537\n",
      "2019-02-07 21:32:36,977 epoch 50 - iter 4/47 - loss 1.58805900\n",
      "2019-02-07 21:32:46,543 epoch 50 - iter 8/47 - loss 1.80012442\n",
      "2019-02-07 21:32:54,640 epoch 50 - iter 12/47 - loss 1.75247612\n",
      "2019-02-07 21:33:03,248 epoch 50 - iter 16/47 - loss 1.82023040\n",
      "2019-02-07 21:33:12,593 epoch 50 - iter 20/47 - loss 1.81731905\n",
      "2019-02-07 21:33:20,747 epoch 50 - iter 24/47 - loss 1.83018051\n",
      "2019-02-07 21:33:31,981 epoch 50 - iter 28/47 - loss 1.85955094\n",
      "2019-02-07 21:33:40,775 epoch 50 - iter 32/47 - loss 1.83568402\n",
      "2019-02-07 21:33:49,358 epoch 50 - iter 36/47 - loss 1.86579129\n",
      "2019-02-07 21:33:57,496 epoch 50 - iter 40/47 - loss 1.92086082\n",
      "2019-02-07 21:34:05,784 epoch 50 - iter 44/47 - loss 1.86578452\n",
      "2019-02-07 21:34:10,611 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:34:10,612 EPOCH 50 done: loss 1.8572 - lr 0.0500 - bad epochs 2\n",
      "2019-02-07 21:34:14,525 DEV  : loss 2.01455426 - f-score 0.8585 - acc 0.8585\n",
      "2019-02-07 21:34:18,044 TEST : loss 1.32337022 - f-score 0.8626 - acc 0.8626\n",
      "2019-02-07 21:34:18,501 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:34:20,874 epoch 51 - iter 0/47 - loss 1.42321134\n",
      "2019-02-07 21:34:29,088 epoch 51 - iter 4/47 - loss 1.68255141\n",
      "2019-02-07 21:34:37,319 epoch 51 - iter 8/47 - loss 1.32352903\n",
      "2019-02-07 21:34:46,726 epoch 51 - iter 12/47 - loss 1.50647692\n",
      "2019-02-07 21:34:55,215 epoch 51 - iter 16/47 - loss 1.54524113\n",
      "2019-02-07 21:35:04,805 epoch 51 - iter 20/47 - loss 1.65284935\n",
      "2019-02-07 21:35:13,307 epoch 51 - iter 24/47 - loss 1.69325018\n",
      "2019-02-07 21:35:22,766 epoch 51 - iter 28/47 - loss 1.67806548\n",
      "2019-02-07 21:35:32,066 epoch 51 - iter 32/47 - loss 1.67775617\n",
      "2019-02-07 21:35:40,396 epoch 51 - iter 36/47 - loss 1.67655286\n",
      "2019-02-07 21:35:49,345 epoch 51 - iter 40/47 - loss 1.70883098\n",
      "2019-02-07 21:35:58,325 epoch 51 - iter 44/47 - loss 1.74818853\n",
      "2019-02-07 21:36:02,820 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:36:02,820 EPOCH 51 done: loss 1.7753 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 21:36:07,218 DEV  : loss 1.99721396 - f-score 0.8567 - acc 0.8567\n",
      "2019-02-07 21:36:10,902 TEST : loss 1.31686163 - f-score 0.8706 - acc 0.8706\n",
      "2019-02-07 21:36:11,336 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:36:13,427 epoch 52 - iter 0/47 - loss 1.08857453\n",
      "2019-02-07 21:36:21,921 epoch 52 - iter 4/47 - loss 1.45084057\n",
      "2019-02-07 21:36:29,810 epoch 52 - iter 8/47 - loss 1.39091400\n",
      "2019-02-07 21:36:39,030 epoch 52 - iter 12/47 - loss 1.41749987\n",
      "2019-02-07 21:36:47,523 epoch 52 - iter 16/47 - loss 1.35206703\n",
      "2019-02-07 21:36:58,389 epoch 52 - iter 20/47 - loss 1.37835691\n",
      "2019-02-07 21:37:07,324 epoch 52 - iter 24/47 - loss 1.48350009\n",
      "2019-02-07 21:37:15,010 epoch 52 - iter 28/47 - loss 1.44650714\n",
      "2019-02-07 21:37:24,578 epoch 52 - iter 32/47 - loss 1.55643256\n",
      "2019-02-07 21:37:33,530 epoch 52 - iter 36/47 - loss 1.56663130\n",
      "2019-02-07 21:37:41,843 epoch 52 - iter 40/47 - loss 1.62082050\n",
      "2019-02-07 21:37:51,225 epoch 52 - iter 44/47 - loss 1.64430749\n",
      "2019-02-07 21:37:55,842 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:37:55,844 EPOCH 52 done: loss 1.6581 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 21:37:59,766 DEV  : loss 1.98609662 - f-score 0.8546 - acc 0.8546\n",
      "2019-02-07 21:38:03,262 TEST : loss 1.30827188 - f-score 0.8742 - acc 0.8742\n",
      "2019-02-07 21:38:03,694 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:38:06,121 epoch 53 - iter 0/47 - loss 1.55841970\n",
      "2019-02-07 21:38:13,765 epoch 53 - iter 4/47 - loss 1.44902251\n",
      "2019-02-07 21:38:23,566 epoch 53 - iter 8/47 - loss 1.54937635\n",
      "2019-02-07 21:38:32,856 epoch 53 - iter 12/47 - loss 1.53336566\n",
      "2019-02-07 21:38:41,393 epoch 53 - iter 16/47 - loss 1.71059178\n",
      "2019-02-07 21:38:50,506 epoch 53 - iter 20/47 - loss 1.67888759\n",
      "2019-02-07 21:38:59,033 epoch 53 - iter 24/47 - loss 1.77538990\n",
      "2019-02-07 21:39:06,612 epoch 53 - iter 28/47 - loss 1.76079131\n",
      "2019-02-07 21:39:16,960 epoch 53 - iter 32/47 - loss 1.70001923\n",
      "2019-02-07 21:39:25,876 epoch 53 - iter 36/47 - loss 1.69602653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 21:39:34,348 epoch 53 - iter 40/47 - loss 1.68012038\n",
      "2019-02-07 21:39:43,435 epoch 53 - iter 44/47 - loss 1.64295541\n",
      "2019-02-07 21:39:48,146 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:39:48,147 EPOCH 53 done: loss 1.7272 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 21:39:52,043 DEV  : loss 1.99834538 - f-score 0.8560 - acc 0.8560\n",
      "2019-02-07 21:39:55,685 TEST : loss 1.30115867 - f-score 0.8724 - acc 0.8724\n",
      "2019-02-07 21:39:55,687 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:39:57,956 epoch 54 - iter 0/47 - loss 0.88997406\n",
      "2019-02-07 21:40:06,350 epoch 54 - iter 4/47 - loss 1.68164502\n",
      "2019-02-07 21:40:16,408 epoch 54 - iter 8/47 - loss 2.07049458\n",
      "2019-02-07 21:40:24,828 epoch 54 - iter 12/47 - loss 1.84808755\n",
      "2019-02-07 21:40:34,082 epoch 54 - iter 16/47 - loss 1.78648039\n",
      "2019-02-07 21:40:43,261 epoch 54 - iter 20/47 - loss 1.75962599\n",
      "2019-02-07 21:40:53,059 epoch 54 - iter 24/47 - loss 1.66612110\n",
      "2019-02-07 21:41:01,221 epoch 54 - iter 28/47 - loss 1.68011414\n",
      "2019-02-07 21:41:09,916 epoch 54 - iter 32/47 - loss 1.68095626\n",
      "2019-02-07 21:41:19,721 epoch 54 - iter 36/47 - loss 1.74977116\n",
      "2019-02-07 21:41:28,117 epoch 54 - iter 40/47 - loss 1.79435628\n",
      "2019-02-07 21:41:36,410 epoch 54 - iter 44/47 - loss 1.82474850\n",
      "2019-02-07 21:41:40,284 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:41:40,285 EPOCH 54 done: loss 1.8281 - lr 0.0500 - bad epochs 1\n",
      "2019-02-07 21:41:44,139 DEV  : loss 1.97821677 - f-score 0.8556 - acc 0.8556\n",
      "2019-02-07 21:41:47,683 TEST : loss 1.30792058 - f-score 0.8696 - acc 0.8696\n",
      "2019-02-07 21:41:47,685 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:41:50,042 epoch 55 - iter 0/47 - loss 1.79686618\n",
      "2019-02-07 21:41:58,682 epoch 55 - iter 4/47 - loss 1.46917102\n",
      "2019-02-07 21:42:07,794 epoch 55 - iter 8/47 - loss 1.37540501\n",
      "2019-02-07 21:42:17,236 epoch 55 - iter 12/47 - loss 1.35695806\n",
      "2019-02-07 21:42:26,939 epoch 55 - iter 16/47 - loss 1.40444135\n",
      "2019-02-07 21:42:34,641 epoch 55 - iter 20/47 - loss 1.57546984\n",
      "2019-02-07 21:42:44,054 epoch 55 - iter 24/47 - loss 1.60080920\n",
      "2019-02-07 21:42:52,439 epoch 55 - iter 28/47 - loss 1.63323408\n",
      "2019-02-07 21:43:01,197 epoch 55 - iter 32/47 - loss 1.71263066\n",
      "2019-02-07 21:43:10,160 epoch 55 - iter 36/47 - loss 1.68961463\n",
      "2019-02-07 21:43:19,581 epoch 55 - iter 40/47 - loss 1.69622767\n",
      "2019-02-07 21:43:28,665 epoch 55 - iter 44/47 - loss 1.70222942\n",
      "2019-02-07 21:43:33,339 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:43:33,340 EPOCH 55 done: loss 1.7086 - lr 0.0500 - bad epochs 2\n",
      "2019-02-07 21:43:37,204 DEV  : loss 1.95737267 - f-score 0.8549 - acc 0.8549\n",
      "2019-02-07 21:43:40,782 TEST : loss 1.32645595 - f-score 0.8734 - acc 0.8734\n",
      "2019-02-07 21:43:40,784 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:43:42,723 epoch 56 - iter 0/47 - loss 1.51628864\n",
      "2019-02-07 21:43:52,065 epoch 56 - iter 4/47 - loss 1.84856133\n",
      "2019-02-07 21:44:01,536 epoch 56 - iter 8/47 - loss 1.81258065\n",
      "2019-02-07 21:44:10,835 epoch 56 - iter 12/47 - loss 1.83408026\n",
      "2019-02-07 21:44:18,826 epoch 56 - iter 16/47 - loss 1.88561618\n",
      "2019-02-07 21:44:27,148 epoch 56 - iter 20/47 - loss 1.83016359\n",
      "2019-02-07 21:44:37,665 epoch 56 - iter 24/47 - loss 1.78903399\n",
      "2019-02-07 21:44:47,095 epoch 56 - iter 28/47 - loss 1.74098568\n",
      "2019-02-07 21:44:54,941 epoch 56 - iter 32/47 - loss 1.68372258\n",
      "2019-02-07 21:45:03,218 epoch 56 - iter 36/47 - loss 1.71112652\n",
      "2019-02-07 21:45:11,542 epoch 56 - iter 40/47 - loss 1.71427283\n",
      "2019-02-07 21:45:20,022 epoch 56 - iter 44/47 - loss 1.73356387\n",
      "2019-02-07 21:45:25,020 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:45:25,021 EPOCH 56 done: loss 1.7330 - lr 0.0500 - bad epochs 3\n",
      "2019-02-07 21:45:28,882 DEV  : loss 1.97247672 - f-score 0.8558 - acc 0.8558\n",
      "2019-02-07 21:45:32,408 TEST : loss 1.29635954 - f-score 0.8696 - acc 0.8696\n",
      "Epoch    55: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2019-02-07 21:45:32,410 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:45:34,883 epoch 57 - iter 0/47 - loss 1.00212026\n",
      "2019-02-07 21:45:44,145 epoch 57 - iter 4/47 - loss 1.64441512\n",
      "2019-02-07 21:45:52,982 epoch 57 - iter 8/47 - loss 1.75538015\n",
      "2019-02-07 21:46:01,921 epoch 57 - iter 12/47 - loss 1.83273808\n",
      "2019-02-07 21:46:10,407 epoch 57 - iter 16/47 - loss 1.68857121\n",
      "2019-02-07 21:46:20,389 epoch 57 - iter 20/47 - loss 1.64616705\n",
      "2019-02-07 21:46:28,607 epoch 57 - iter 24/47 - loss 1.64065973\n",
      "2019-02-07 21:46:38,273 epoch 57 - iter 28/47 - loss 1.69551982\n",
      "2019-02-07 21:46:46,350 epoch 57 - iter 32/47 - loss 1.69272891\n",
      "2019-02-07 21:46:54,361 epoch 57 - iter 36/47 - loss 1.74963472\n",
      "2019-02-07 21:47:04,251 epoch 57 - iter 40/47 - loss 1.78483903\n",
      "2019-02-07 21:47:12,712 epoch 57 - iter 44/47 - loss 1.82362818\n",
      "2019-02-07 21:47:17,607 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:47:17,608 EPOCH 57 done: loss 1.8023 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 21:47:21,454 DEV  : loss 1.97886038 - f-score 0.8603 - acc 0.8603\n",
      "2019-02-07 21:47:25,001 TEST : loss 1.28659487 - f-score 0.8730 - acc 0.8730\n",
      "2019-02-07 21:47:25,003 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:47:27,099 epoch 58 - iter 0/47 - loss 1.46786475\n",
      "2019-02-07 21:47:36,148 epoch 58 - iter 4/47 - loss 1.79617791\n",
      "2019-02-07 21:47:43,925 epoch 58 - iter 8/47 - loss 1.55257336\n",
      "2019-02-07 21:47:52,682 epoch 58 - iter 12/47 - loss 1.78000303\n",
      "2019-02-07 21:48:02,912 epoch 58 - iter 16/47 - loss 1.69479993\n",
      "2019-02-07 21:48:11,043 epoch 58 - iter 20/47 - loss 1.62172049\n",
      "2019-02-07 21:48:20,246 epoch 58 - iter 24/47 - loss 1.59065993\n",
      "2019-02-07 21:48:28,782 epoch 58 - iter 28/47 - loss 1.61825639\n",
      "2019-02-07 21:48:38,778 epoch 58 - iter 32/47 - loss 1.60100178\n",
      "2019-02-07 21:48:47,126 epoch 58 - iter 36/47 - loss 1.65996864\n",
      "2019-02-07 21:48:56,927 epoch 58 - iter 40/47 - loss 1.70196295\n",
      "2019-02-07 21:49:05,784 epoch 58 - iter 44/47 - loss 1.70333987\n",
      "2019-02-07 21:49:10,476 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:49:10,477 EPOCH 58 done: loss 1.6875 - lr 0.0250 - bad epochs 1\n",
      "2019-02-07 21:49:14,355 DEV  : loss 1.96436250 - f-score 0.8597 - acc 0.8596\n",
      "2019-02-07 21:49:17,918 TEST : loss 1.28734040 - f-score 0.8685 - acc 0.8685\n",
      "2019-02-07 21:49:17,919 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:49:19,779 epoch 59 - iter 0/47 - loss 1.93307519\n",
      "2019-02-07 21:49:27,848 epoch 59 - iter 4/47 - loss 1.38095949\n",
      "2019-02-07 21:49:36,818 epoch 59 - iter 8/47 - loss 1.73136617\n",
      "2019-02-07 21:49:47,160 epoch 59 - iter 12/47 - loss 1.72580153\n",
      "2019-02-07 21:49:56,605 epoch 59 - iter 16/47 - loss 1.67682980\n",
      "2019-02-07 21:50:04,476 epoch 59 - iter 20/47 - loss 1.66386588\n",
      "2019-02-07 21:50:13,998 epoch 59 - iter 24/47 - loss 1.67812449\n",
      "2019-02-07 21:50:22,842 epoch 59 - iter 28/47 - loss 1.76775459\n",
      "2019-02-07 21:50:30,766 epoch 59 - iter 32/47 - loss 1.77136404\n",
      "2019-02-07 21:50:39,395 epoch 59 - iter 36/47 - loss 1.81354684\n",
      "2019-02-07 21:50:47,635 epoch 59 - iter 40/47 - loss 1.77374744\n",
      "2019-02-07 21:50:56,643 epoch 59 - iter 44/47 - loss 1.73860165\n",
      "2019-02-07 21:51:01,107 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:51:01,107 EPOCH 59 done: loss 1.7064 - lr 0.0250 - bad epochs 2\n",
      "2019-02-07 21:51:04,955 DEV  : loss 1.97048962 - f-score 0.8581 - acc 0.8581\n",
      "2019-02-07 21:51:08,568 TEST : loss 1.28571391 - f-score 0.8712 - acc 0.8711\n",
      "2019-02-07 21:51:08,570 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:51:10,870 epoch 60 - iter 0/47 - loss 2.65017271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 21:51:19,923 epoch 60 - iter 4/47 - loss 1.79005198\n",
      "2019-02-07 21:51:29,504 epoch 60 - iter 8/47 - loss 1.86922567\n",
      "2019-02-07 21:51:36,803 epoch 60 - iter 12/47 - loss 1.93805697\n",
      "2019-02-07 21:51:45,954 epoch 60 - iter 16/47 - loss 1.94051068\n",
      "2019-02-07 21:51:56,843 epoch 60 - iter 20/47 - loss 1.82653777\n",
      "2019-02-07 21:52:05,824 epoch 60 - iter 24/47 - loss 1.81794239\n",
      "2019-02-07 21:52:15,013 epoch 60 - iter 28/47 - loss 1.86151596\n",
      "2019-02-07 21:52:23,662 epoch 60 - iter 32/47 - loss 1.84268655\n",
      "2019-02-07 21:52:32,536 epoch 60 - iter 36/47 - loss 1.83727409\n",
      "2019-02-07 21:52:42,203 epoch 60 - iter 40/47 - loss 1.79512193\n",
      "2019-02-07 21:52:50,056 epoch 60 - iter 44/47 - loss 1.80958802\n",
      "2019-02-07 21:52:54,241 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:52:54,242 EPOCH 60 done: loss 1.8277 - lr 0.0250 - bad epochs 3\n",
      "2019-02-07 21:52:57,971 DEV  : loss 1.95116413 - f-score 0.8558 - acc 0.8558\n",
      "2019-02-07 21:53:01,380 TEST : loss 1.28575385 - f-score 0.8732 - acc 0.8732\n",
      "Epoch    59: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2019-02-07 21:53:01,382 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:53:03,169 epoch 61 - iter 0/47 - loss 2.35785079\n",
      "2019-02-07 21:53:13,938 epoch 61 - iter 4/47 - loss 2.18845739\n",
      "2019-02-07 21:53:22,581 epoch 61 - iter 8/47 - loss 1.88124924\n",
      "2019-02-07 21:53:30,986 epoch 61 - iter 12/47 - loss 1.94450626\n",
      "2019-02-07 21:53:39,125 epoch 61 - iter 16/47 - loss 1.71647832\n",
      "2019-02-07 21:53:46,875 epoch 61 - iter 20/47 - loss 1.64942712\n",
      "2019-02-07 21:53:56,910 epoch 61 - iter 24/47 - loss 1.66483478\n",
      "2019-02-07 21:54:05,730 epoch 61 - iter 28/47 - loss 1.68978888\n",
      "2019-02-07 21:54:14,574 epoch 61 - iter 32/47 - loss 1.72998583\n",
      "2019-02-07 21:54:23,867 epoch 61 - iter 36/47 - loss 1.77340109\n",
      "2019-02-07 21:54:32,302 epoch 61 - iter 40/47 - loss 1.80113827\n",
      "2019-02-07 21:54:41,049 epoch 61 - iter 44/47 - loss 1.79211045\n",
      "2019-02-07 21:54:44,771 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:54:44,773 EPOCH 61 done: loss 1.7810 - lr 0.0125 - bad epochs 0\n",
      "2019-02-07 21:54:48,692 DEV  : loss 1.94305825 - f-score 0.8551 - acc 0.8551\n",
      "2019-02-07 21:54:52,081 TEST : loss 1.28492820 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 21:54:52,083 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:54:54,997 epoch 62 - iter 0/47 - loss 0.81827199\n",
      "2019-02-07 21:55:02,655 epoch 62 - iter 4/47 - loss 1.71733322\n",
      "2019-02-07 21:55:10,671 epoch 62 - iter 8/47 - loss 1.46642399\n",
      "2019-02-07 21:55:18,939 epoch 62 - iter 12/47 - loss 1.70385926\n",
      "2019-02-07 21:55:26,400 epoch 62 - iter 16/47 - loss 1.71822234\n",
      "2019-02-07 21:55:34,161 epoch 62 - iter 20/47 - loss 1.89353379\n",
      "2019-02-07 21:55:41,934 epoch 62 - iter 24/47 - loss 1.78992163\n",
      "2019-02-07 21:55:50,497 epoch 62 - iter 28/47 - loss 1.81552465\n",
      "2019-02-07 21:56:00,594 epoch 62 - iter 32/47 - loss 1.77407267\n",
      "2019-02-07 21:56:09,109 epoch 62 - iter 36/47 - loss 1.77570307\n",
      "2019-02-07 21:56:16,152 epoch 62 - iter 40/47 - loss 1.70854375\n",
      "2019-02-07 21:56:24,470 epoch 62 - iter 44/47 - loss 1.70351537\n",
      "2019-02-07 21:56:29,840 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:56:29,841 EPOCH 62 done: loss 1.7155 - lr 0.0125 - bad epochs 1\n",
      "2019-02-07 21:56:33,496 DEV  : loss 1.95000470 - f-score 0.8590 - acc 0.8590\n",
      "2019-02-07 21:56:36,853 TEST : loss 1.28085101 - f-score 0.8714 - acc 0.8714\n",
      "2019-02-07 21:56:36,855 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:56:38,646 epoch 63 - iter 0/47 - loss 2.85621715\n",
      "2019-02-07 21:56:46,738 epoch 63 - iter 4/47 - loss 1.63449976\n",
      "2019-02-07 21:56:54,701 epoch 63 - iter 8/47 - loss 1.73233445\n",
      "2019-02-07 21:57:03,141 epoch 63 - iter 12/47 - loss 1.66790331\n",
      "2019-02-07 21:57:12,287 epoch 63 - iter 16/47 - loss 1.58136253\n",
      "2019-02-07 21:57:20,306 epoch 63 - iter 20/47 - loss 1.55723437\n",
      "2019-02-07 21:57:29,141 epoch 63 - iter 24/47 - loss 1.54037925\n",
      "2019-02-07 21:57:37,118 epoch 63 - iter 28/47 - loss 1.64261506\n",
      "2019-02-07 21:57:45,594 epoch 63 - iter 32/47 - loss 1.61627060\n",
      "2019-02-07 21:57:53,675 epoch 63 - iter 36/47 - loss 1.59770727\n",
      "2019-02-07 21:58:02,172 epoch 63 - iter 40/47 - loss 1.65769996\n",
      "2019-02-07 21:58:11,188 epoch 63 - iter 44/47 - loss 1.69190446\n",
      "2019-02-07 21:58:16,468 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:58:16,469 EPOCH 63 done: loss 1.6808 - lr 0.0125 - bad epochs 2\n",
      "2019-02-07 21:58:20,338 DEV  : loss 1.95861399 - f-score 0.8542 - acc 0.8542\n",
      "2019-02-07 21:58:23,763 TEST : loss 1.27907419 - f-score 0.8721 - acc 0.8722\n",
      "2019-02-07 21:58:23,765 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 21:58:25,692 epoch 64 - iter 0/47 - loss 0.92611110\n",
      "2019-02-07 21:58:34,494 epoch 64 - iter 4/47 - loss 1.73480319\n",
      "2019-02-07 21:58:44,494 epoch 64 - iter 8/47 - loss 1.88347633\n",
      "2019-02-07 21:58:53,693 epoch 64 - iter 12/47 - loss 1.83979145\n",
      "2019-02-07 21:59:01,799 epoch 64 - iter 16/47 - loss 1.88818234\n",
      "2019-02-07 21:59:09,592 epoch 64 - iter 20/47 - loss 1.83043809\n",
      "2019-02-07 21:59:20,494 epoch 64 - iter 24/47 - loss 1.76608406\n",
      "2019-02-07 21:59:27,945 epoch 64 - iter 28/47 - loss 1.73116499\n",
      "2019-02-07 21:59:36,584 epoch 64 - iter 32/47 - loss 1.80379199\n",
      "2019-02-07 21:59:45,318 epoch 64 - iter 36/47 - loss 1.73972232\n",
      "2019-02-07 21:59:52,442 epoch 64 - iter 40/47 - loss 1.74838257\n",
      "2019-02-07 22:00:00,163 epoch 64 - iter 44/47 - loss 1.71674253\n",
      "2019-02-07 22:00:04,607 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:00:04,608 EPOCH 64 done: loss 1.7068 - lr 0.0125 - bad epochs 3\n",
      "2019-02-07 22:00:08,330 DEV  : loss 1.95590389 - f-score 0.8565 - acc 0.8565\n",
      "2019-02-07 22:00:11,725 TEST : loss 1.28063893 - f-score 0.8714 - acc 0.8714\n",
      "Epoch    63: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2019-02-07 22:00:11,726 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:00:13,660 epoch 65 - iter 0/47 - loss 1.27996290\n",
      "2019-02-07 22:00:22,506 epoch 65 - iter 4/47 - loss 1.97346735\n",
      "2019-02-07 22:00:31,391 epoch 65 - iter 8/47 - loss 1.96300010\n",
      "2019-02-07 22:00:39,540 epoch 65 - iter 12/47 - loss 1.84248704\n",
      "2019-02-07 22:00:47,404 epoch 65 - iter 16/47 - loss 1.87903850\n",
      "2019-02-07 22:00:55,688 epoch 65 - iter 20/47 - loss 1.77894551\n",
      "2019-02-07 22:01:03,805 epoch 65 - iter 24/47 - loss 1.72286304\n",
      "2019-02-07 22:01:12,796 epoch 65 - iter 28/47 - loss 1.72995387\n",
      "2019-02-07 22:01:20,952 epoch 65 - iter 32/47 - loss 1.72163313\n",
      "2019-02-07 22:01:28,482 epoch 65 - iter 36/47 - loss 1.68650405\n",
      "2019-02-07 22:01:38,180 epoch 65 - iter 40/47 - loss 1.65481537\n",
      "2019-02-07 22:01:46,465 epoch 65 - iter 44/47 - loss 1.68328146\n",
      "2019-02-07 22:01:50,050 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:01:50,052 EPOCH 65 done: loss 1.6593 - lr 0.0063 - bad epochs 0\n",
      "2019-02-07 22:01:53,842 DEV  : loss 1.95551658 - f-score 0.8565 - acc 0.8565\n",
      "2019-02-07 22:01:57,331 TEST : loss 1.27953410 - f-score 0.8721 - acc 0.8722\n",
      "2019-02-07 22:01:57,333 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:01:59,600 epoch 66 - iter 0/47 - loss 1.56641567\n",
      "2019-02-07 22:02:09,611 epoch 66 - iter 4/47 - loss 1.94718537\n",
      "2019-02-07 22:02:17,911 epoch 66 - iter 8/47 - loss 1.64206670\n",
      "2019-02-07 22:02:26,309 epoch 66 - iter 12/47 - loss 1.62512508\n",
      "2019-02-07 22:02:34,470 epoch 66 - iter 16/47 - loss 1.61820930\n",
      "2019-02-07 22:02:42,434 epoch 66 - iter 20/47 - loss 1.56939443\n",
      "2019-02-07 22:02:50,542 epoch 66 - iter 24/47 - loss 1.59508240\n",
      "2019-02-07 22:02:58,422 epoch 66 - iter 28/47 - loss 1.63582082\n",
      "2019-02-07 22:03:05,870 epoch 66 - iter 32/47 - loss 1.60716555\n",
      "2019-02-07 22:03:14,875 epoch 66 - iter 36/47 - loss 1.58245365\n",
      "2019-02-07 22:03:22,476 epoch 66 - iter 40/47 - loss 1.63339664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 22:03:32,134 epoch 66 - iter 44/47 - loss 1.59932840\n",
      "2019-02-07 22:03:38,187 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:03:38,188 EPOCH 66 done: loss 1.5854 - lr 0.0063 - bad epochs 1\n",
      "2019-02-07 22:03:42,113 DEV  : loss 1.95408010 - f-score 0.8587 - acc 0.8587\n",
      "2019-02-07 22:03:45,623 TEST : loss 1.27966750 - f-score 0.8721 - acc 0.8722\n",
      "2019-02-07 22:03:46,068 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:03:49,198 epoch 67 - iter 0/47 - loss 0.68057698\n",
      "2019-02-07 22:03:58,385 epoch 67 - iter 4/47 - loss 0.97869563\n",
      "2019-02-07 22:04:07,598 epoch 67 - iter 8/47 - loss 1.71555470\n",
      "2019-02-07 22:04:17,068 epoch 67 - iter 12/47 - loss 1.72224060\n",
      "2019-02-07 22:04:24,984 epoch 67 - iter 16/47 - loss 1.67467349\n",
      "2019-02-07 22:04:33,258 epoch 67 - iter 20/47 - loss 1.59752531\n",
      "2019-02-07 22:04:42,983 epoch 67 - iter 24/47 - loss 1.60851189\n",
      "2019-02-07 22:04:51,150 epoch 67 - iter 28/47 - loss 1.65774488\n",
      "2019-02-07 22:04:59,086 epoch 67 - iter 32/47 - loss 1.58398672\n",
      "2019-02-07 22:05:06,643 epoch 67 - iter 36/47 - loss 1.55025706\n",
      "2019-02-07 22:05:15,973 epoch 67 - iter 40/47 - loss 1.55169859\n",
      "2019-02-07 22:05:24,023 epoch 67 - iter 44/47 - loss 1.54729751\n",
      "2019-02-07 22:05:28,091 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:05:28,092 EPOCH 67 done: loss 1.5402 - lr 0.0063 - bad epochs 0\n",
      "2019-02-07 22:05:31,984 DEV  : loss 1.94044340 - f-score 0.8628 - acc 0.8628\n",
      "2019-02-07 22:05:35,542 TEST : loss 1.28547466 - f-score 0.8750 - acc 0.8750\n",
      "2019-02-07 22:05:35,971 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:05:37,869 epoch 68 - iter 0/47 - loss 1.23023200\n",
      "2019-02-07 22:05:46,531 epoch 68 - iter 4/47 - loss 1.08955356\n",
      "2019-02-07 22:05:53,613 epoch 68 - iter 8/47 - loss 1.21796800\n",
      "2019-02-07 22:06:04,099 epoch 68 - iter 12/47 - loss 1.32284659\n",
      "2019-02-07 22:06:12,180 epoch 68 - iter 16/47 - loss 1.25260680\n",
      "2019-02-07 22:06:20,931 epoch 68 - iter 20/47 - loss 1.38027465\n",
      "2019-02-07 22:06:29,278 epoch 68 - iter 24/47 - loss 1.50051320\n",
      "2019-02-07 22:06:37,602 epoch 68 - iter 28/47 - loss 1.48796001\n",
      "2019-02-07 22:06:46,586 epoch 68 - iter 32/47 - loss 1.64825598\n",
      "2019-02-07 22:06:54,617 epoch 68 - iter 36/47 - loss 1.69043398\n",
      "2019-02-07 22:07:04,516 epoch 68 - iter 40/47 - loss 1.68153663\n",
      "2019-02-07 22:07:13,050 epoch 68 - iter 44/47 - loss 1.68725391\n",
      "2019-02-07 22:07:17,560 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:07:17,561 EPOCH 68 done: loss 1.7017 - lr 0.0063 - bad epochs 0\n",
      "2019-02-07 22:07:21,431 DEV  : loss 1.94678843 - f-score 0.8581 - acc 0.8581\n",
      "2019-02-07 22:07:24,951 TEST : loss 1.28034127 - f-score 0.8740 - acc 0.8740\n",
      "2019-02-07 22:07:24,956 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:07:26,873 epoch 69 - iter 0/47 - loss 1.56826007\n",
      "2019-02-07 22:07:35,336 epoch 69 - iter 4/47 - loss 1.65670938\n",
      "2019-02-07 22:07:44,256 epoch 69 - iter 8/47 - loss 1.41765647\n",
      "2019-02-07 22:07:52,262 epoch 69 - iter 12/47 - loss 1.48193678\n",
      "2019-02-07 22:08:00,835 epoch 69 - iter 16/47 - loss 1.49912798\n",
      "2019-02-07 22:08:09,842 epoch 69 - iter 20/47 - loss 1.44302698\n",
      "2019-02-07 22:08:17,307 epoch 69 - iter 24/47 - loss 1.47902081\n",
      "2019-02-07 22:08:26,158 epoch 69 - iter 28/47 - loss 1.45703343\n",
      "2019-02-07 22:08:35,152 epoch 69 - iter 32/47 - loss 1.52026004\n",
      "2019-02-07 22:08:42,285 epoch 69 - iter 36/47 - loss 1.59454047\n",
      "2019-02-07 22:08:51,081 epoch 69 - iter 40/47 - loss 1.56561474\n",
      "2019-02-07 22:08:59,440 epoch 69 - iter 44/47 - loss 1.56414267\n",
      "2019-02-07 22:09:04,709 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:09:04,711 EPOCH 69 done: loss 1.5452 - lr 0.0063 - bad epochs 1\n",
      "2019-02-07 22:09:08,598 DEV  : loss 1.94701493 - f-score 0.8590 - acc 0.8590\n",
      "2019-02-07 22:09:12,054 TEST : loss 1.28038430 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:09:12,056 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:09:14,046 epoch 70 - iter 0/47 - loss 3.26123834\n",
      "2019-02-07 22:09:21,285 epoch 70 - iter 4/47 - loss 1.95558467\n",
      "2019-02-07 22:09:29,087 epoch 70 - iter 8/47 - loss 1.82177042\n",
      "2019-02-07 22:09:36,892 epoch 70 - iter 12/47 - loss 1.65259125\n",
      "2019-02-07 22:09:45,070 epoch 70 - iter 16/47 - loss 1.68257496\n",
      "2019-02-07 22:09:53,689 epoch 70 - iter 20/47 - loss 1.61205164\n",
      "2019-02-07 22:10:03,308 epoch 70 - iter 24/47 - loss 1.62516987\n",
      "2019-02-07 22:10:12,434 epoch 70 - iter 28/47 - loss 1.59337201\n",
      "2019-02-07 22:10:21,851 epoch 70 - iter 32/47 - loss 1.60889336\n",
      "2019-02-07 22:10:30,236 epoch 70 - iter 36/47 - loss 1.56559087\n",
      "2019-02-07 22:10:39,147 epoch 70 - iter 40/47 - loss 1.59680609\n",
      "2019-02-07 22:10:47,142 epoch 70 - iter 44/47 - loss 1.63546840\n",
      "2019-02-07 22:10:51,874 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:10:51,875 EPOCH 70 done: loss 1.6293 - lr 0.0063 - bad epochs 2\n",
      "2019-02-07 22:10:55,692 DEV  : loss 1.93937445 - f-score 0.8606 - acc 0.8606\n",
      "2019-02-07 22:10:59,164 TEST : loss 1.28487480 - f-score 0.8750 - acc 0.8750\n",
      "2019-02-07 22:10:59,166 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:11:01,034 epoch 71 - iter 0/47 - loss 2.62621617\n",
      "2019-02-07 22:11:09,611 epoch 71 - iter 4/47 - loss 1.80893123\n",
      "2019-02-07 22:11:17,513 epoch 71 - iter 8/47 - loss 1.47737502\n",
      "2019-02-07 22:11:25,755 epoch 71 - iter 12/47 - loss 1.54088892\n",
      "2019-02-07 22:11:33,805 epoch 71 - iter 16/47 - loss 1.43655315\n",
      "2019-02-07 22:11:42,447 epoch 71 - iter 20/47 - loss 1.77495041\n",
      "2019-02-07 22:11:51,191 epoch 71 - iter 24/47 - loss 1.72749557\n",
      "2019-02-07 22:11:59,207 epoch 71 - iter 28/47 - loss 1.70144580\n",
      "2019-02-07 22:12:08,534 epoch 71 - iter 32/47 - loss 1.68850480\n",
      "2019-02-07 22:12:16,962 epoch 71 - iter 36/47 - loss 1.61882244\n",
      "2019-02-07 22:12:26,426 epoch 71 - iter 40/47 - loss 1.66733040\n",
      "2019-02-07 22:12:34,505 epoch 71 - iter 44/47 - loss 1.69075317\n",
      "2019-02-07 22:12:39,120 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:12:39,121 EPOCH 71 done: loss 1.6770 - lr 0.0063 - bad epochs 3\n",
      "2019-02-07 22:12:43,137 DEV  : loss 1.94195747 - f-score 0.8583 - acc 0.8583\n",
      "2019-02-07 22:12:46,688 TEST : loss 1.28414738 - f-score 0.8750 - acc 0.8750\n",
      "Epoch    70: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2019-02-07 22:12:46,694 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:12:49,246 epoch 72 - iter 0/47 - loss 0.93158215\n",
      "2019-02-07 22:12:58,829 epoch 72 - iter 4/47 - loss 1.34063261\n",
      "2019-02-07 22:13:10,948 epoch 72 - iter 8/47 - loss 1.52950627\n",
      "2019-02-07 22:13:20,164 epoch 72 - iter 12/47 - loss 1.48188621\n",
      "2019-02-07 22:13:28,790 epoch 72 - iter 16/47 - loss 1.60681344\n",
      "2019-02-07 22:13:38,098 epoch 72 - iter 20/47 - loss 1.53523069\n",
      "2019-02-07 22:13:48,662 epoch 72 - iter 24/47 - loss 1.60265182\n",
      "2019-02-07 22:13:59,667 epoch 72 - iter 28/47 - loss 1.62507563\n",
      "2019-02-07 22:14:11,048 epoch 72 - iter 32/47 - loss 1.58666723\n",
      "2019-02-07 22:14:21,146 epoch 72 - iter 36/47 - loss 1.55863183\n",
      "2019-02-07 22:14:30,381 epoch 72 - iter 40/47 - loss 1.58863773\n",
      "2019-02-07 22:14:38,834 epoch 72 - iter 44/47 - loss 1.57665918\n",
      "2019-02-07 22:14:44,799 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:14:44,800 EPOCH 72 done: loss 1.5707 - lr 0.0031 - bad epochs 0\n",
      "2019-02-07 22:14:49,243 DEV  : loss 1.94430995 - f-score 0.8590 - acc 0.8590\n",
      "2019-02-07 22:14:53,148 TEST : loss 1.28137457 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:14:53,150 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:14:55,664 epoch 73 - iter 0/47 - loss 0.96909118\n",
      "2019-02-07 22:15:07,237 epoch 73 - iter 4/47 - loss 1.51796792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 22:15:15,291 epoch 73 - iter 8/47 - loss 1.42350111\n",
      "2019-02-07 22:15:24,257 epoch 73 - iter 12/47 - loss 1.42899255\n",
      "2019-02-07 22:15:32,201 epoch 73 - iter 16/47 - loss 1.39727687\n",
      "2019-02-07 22:15:40,522 epoch 73 - iter 20/47 - loss 1.52843411\n",
      "2019-02-07 22:15:48,334 epoch 73 - iter 24/47 - loss 1.56503147\n",
      "2019-02-07 22:15:57,246 epoch 73 - iter 28/47 - loss 1.49350730\n",
      "2019-02-07 22:16:05,157 epoch 73 - iter 32/47 - loss 1.49483584\n",
      "2019-02-07 22:16:13,819 epoch 73 - iter 36/47 - loss 1.47473585\n",
      "2019-02-07 22:16:22,872 epoch 73 - iter 40/47 - loss 1.51196150\n",
      "2019-02-07 22:16:32,637 epoch 73 - iter 44/47 - loss 1.54072827\n",
      "2019-02-07 22:16:37,168 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:16:37,169 EPOCH 73 done: loss 1.5620 - lr 0.0031 - bad epochs 1\n",
      "2019-02-07 22:16:41,277 DEV  : loss 1.94197595 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:16:44,985 TEST : loss 1.28163278 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:16:44,987 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:16:47,382 epoch 74 - iter 0/47 - loss 1.63958263\n",
      "2019-02-07 22:16:55,986 epoch 74 - iter 4/47 - loss 1.54608777\n",
      "2019-02-07 22:17:04,625 epoch 74 - iter 8/47 - loss 1.36861120\n",
      "2019-02-07 22:17:13,369 epoch 74 - iter 12/47 - loss 1.72227501\n",
      "2019-02-07 22:17:22,854 epoch 74 - iter 16/47 - loss 1.77436206\n",
      "2019-02-07 22:17:29,893 epoch 74 - iter 20/47 - loss 1.74268468\n",
      "2019-02-07 22:17:38,330 epoch 74 - iter 24/47 - loss 1.66784732\n",
      "2019-02-07 22:17:46,842 epoch 74 - iter 28/47 - loss 1.65427668\n",
      "2019-02-07 22:17:55,569 epoch 74 - iter 32/47 - loss 1.67785929\n",
      "2019-02-07 22:18:04,373 epoch 74 - iter 36/47 - loss 1.63753842\n",
      "2019-02-07 22:18:13,764 epoch 74 - iter 40/47 - loss 1.68443618\n",
      "2019-02-07 22:18:22,088 epoch 74 - iter 44/47 - loss 1.67626706\n",
      "2019-02-07 22:18:27,350 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:18:27,351 EPOCH 74 done: loss 1.6746 - lr 0.0031 - bad epochs 2\n",
      "2019-02-07 22:18:31,328 DEV  : loss 1.94059885 - f-score 0.8583 - acc 0.8583\n",
      "2019-02-07 22:18:34,989 TEST : loss 1.28186429 - f-score 0.8750 - acc 0.8750\n",
      "2019-02-07 22:18:34,990 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:18:37,316 epoch 75 - iter 0/47 - loss 2.39764881\n",
      "2019-02-07 22:18:47,318 epoch 75 - iter 4/47 - loss 2.00320754\n",
      "2019-02-07 22:18:55,467 epoch 75 - iter 8/47 - loss 1.73562684\n",
      "2019-02-07 22:19:04,319 epoch 75 - iter 12/47 - loss 1.62275014\n",
      "2019-02-07 22:19:12,273 epoch 75 - iter 16/47 - loss 1.75979432\n",
      "2019-02-07 22:19:20,415 epoch 75 - iter 20/47 - loss 1.64707929\n",
      "2019-02-07 22:19:29,989 epoch 75 - iter 24/47 - loss 1.71363755\n",
      "2019-02-07 22:19:39,198 epoch 75 - iter 28/47 - loss 1.62994537\n",
      "2019-02-07 22:19:47,241 epoch 75 - iter 32/47 - loss 1.64422840\n",
      "2019-02-07 22:19:55,072 epoch 75 - iter 36/47 - loss 1.60012480\n",
      "2019-02-07 22:20:04,701 epoch 75 - iter 40/47 - loss 1.60386587\n",
      "2019-02-07 22:20:11,657 epoch 75 - iter 44/47 - loss 1.56539839\n",
      "2019-02-07 22:20:15,945 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:20:15,946 EPOCH 75 done: loss 1.5622 - lr 0.0031 - bad epochs 3\n",
      "2019-02-07 22:20:19,923 DEV  : loss 1.94077671 - f-score 0.8635 - acc 0.8635\n",
      "2019-02-07 22:20:23,568 TEST : loss 1.28142726 - f-score 0.8750 - acc 0.8750\n",
      "Epoch    74: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2019-02-07 22:20:23,571 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:20:25,443 epoch 76 - iter 0/47 - loss 0.79411668\n",
      "2019-02-07 22:20:34,561 epoch 76 - iter 4/47 - loss 1.59492840\n",
      "2019-02-07 22:20:42,585 epoch 76 - iter 8/47 - loss 1.32864434\n",
      "2019-02-07 22:20:50,877 epoch 76 - iter 12/47 - loss 1.25632930\n",
      "2019-02-07 22:20:59,900 epoch 76 - iter 16/47 - loss 1.24452888\n",
      "2019-02-07 22:21:08,713 epoch 76 - iter 20/47 - loss 1.40165286\n",
      "2019-02-07 22:21:17,718 epoch 76 - iter 24/47 - loss 1.42302075\n",
      "2019-02-07 22:21:26,583 epoch 76 - iter 28/47 - loss 1.43750588\n",
      "2019-02-07 22:21:35,375 epoch 76 - iter 32/47 - loss 1.41413750\n",
      "2019-02-07 22:21:43,833 epoch 76 - iter 36/47 - loss 1.44730801\n",
      "2019-02-07 22:21:52,371 epoch 76 - iter 40/47 - loss 1.47173003\n",
      "2019-02-07 22:22:01,349 epoch 76 - iter 44/47 - loss 1.53531306\n",
      "2019-02-07 22:22:06,060 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:22:06,060 EPOCH 76 done: loss 1.5646 - lr 0.0016 - bad epochs 0\n",
      "2019-02-07 22:22:10,014 DEV  : loss 1.93985331 - f-score 0.8635 - acc 0.8635\n",
      "2019-02-07 22:22:13,664 TEST : loss 1.28155923 - f-score 0.8750 - acc 0.8750\n",
      "2019-02-07 22:22:13,666 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:22:15,916 epoch 77 - iter 0/47 - loss 0.88598263\n",
      "2019-02-07 22:22:25,085 epoch 77 - iter 4/47 - loss 1.17765372\n",
      "2019-02-07 22:22:32,753 epoch 77 - iter 8/47 - loss 1.39059590\n",
      "2019-02-07 22:22:42,563 epoch 77 - iter 12/47 - loss 1.38805333\n",
      "2019-02-07 22:22:51,301 epoch 77 - iter 16/47 - loss 1.35688443\n",
      "2019-02-07 22:22:59,291 epoch 77 - iter 20/47 - loss 1.34223098\n",
      "2019-02-07 22:23:08,270 epoch 77 - iter 24/47 - loss 1.34193554\n",
      "2019-02-07 22:23:15,752 epoch 77 - iter 28/47 - loss 1.36724751\n",
      "2019-02-07 22:23:22,911 epoch 77 - iter 32/47 - loss 1.35293561\n",
      "2019-02-07 22:23:32,520 epoch 77 - iter 36/47 - loss 1.44835740\n",
      "2019-02-07 22:23:41,242 epoch 77 - iter 40/47 - loss 1.51349820\n",
      "2019-02-07 22:23:48,859 epoch 77 - iter 44/47 - loss 1.50245732\n",
      "2019-02-07 22:23:53,911 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:23:53,912 EPOCH 77 done: loss 1.5561 - lr 0.0016 - bad epochs 1\n",
      "2019-02-07 22:23:58,170 DEV  : loss 1.94072747 - f-score 0.8635 - acc 0.8635\n",
      "2019-02-07 22:24:01,815 TEST : loss 1.28093612 - f-score 0.8750 - acc 0.8750\n",
      "2019-02-07 22:24:01,817 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:24:03,992 epoch 78 - iter 0/47 - loss 1.07521307\n",
      "2019-02-07 22:24:12,473 epoch 78 - iter 4/47 - loss 1.06703598\n",
      "2019-02-07 22:24:20,640 epoch 78 - iter 8/47 - loss 1.20015123\n",
      "2019-02-07 22:24:31,981 epoch 78 - iter 12/47 - loss 1.34752438\n",
      "2019-02-07 22:24:40,672 epoch 78 - iter 16/47 - loss 1.49113619\n",
      "2019-02-07 22:24:50,775 epoch 78 - iter 20/47 - loss 1.69555355\n",
      "2019-02-07 22:24:58,889 epoch 78 - iter 24/47 - loss 1.71299190\n",
      "2019-02-07 22:25:07,384 epoch 78 - iter 28/47 - loss 1.70770820\n",
      "2019-02-07 22:25:16,403 epoch 78 - iter 32/47 - loss 1.72262593\n",
      "2019-02-07 22:25:24,780 epoch 78 - iter 36/47 - loss 1.71199887\n",
      "2019-02-07 22:25:32,570 epoch 78 - iter 40/47 - loss 1.63466241\n",
      "2019-02-07 22:25:40,680 epoch 78 - iter 44/47 - loss 1.65492360\n",
      "2019-02-07 22:25:44,781 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:25:44,782 EPOCH 78 done: loss 1.6446 - lr 0.0016 - bad epochs 2\n",
      "2019-02-07 22:25:48,931 DEV  : loss 1.94244528 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:25:52,571 TEST : loss 1.27991343 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:25:52,572 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:25:54,911 epoch 79 - iter 0/47 - loss 2.05642557\n",
      "2019-02-07 22:26:03,647 epoch 79 - iter 4/47 - loss 2.25709105\n",
      "2019-02-07 22:26:11,964 epoch 79 - iter 8/47 - loss 1.81636154\n",
      "2019-02-07 22:26:20,373 epoch 79 - iter 12/47 - loss 1.81480736\n",
      "2019-02-07 22:26:29,483 epoch 79 - iter 16/47 - loss 1.71844117\n",
      "2019-02-07 22:26:37,351 epoch 79 - iter 20/47 - loss 1.68292228\n",
      "2019-02-07 22:26:46,139 epoch 79 - iter 24/47 - loss 1.66239280\n",
      "2019-02-07 22:26:54,435 epoch 79 - iter 28/47 - loss 1.58677191\n",
      "2019-02-07 22:27:01,843 epoch 79 - iter 32/47 - loss 1.56517690\n",
      "2019-02-07 22:27:11,096 epoch 79 - iter 36/47 - loss 1.55192110\n",
      "2019-02-07 22:27:19,526 epoch 79 - iter 40/47 - loss 1.57483551\n",
      "2019-02-07 22:27:28,212 epoch 79 - iter 44/47 - loss 1.56537248\n",
      "2019-02-07 22:27:32,913 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 22:27:32,914 EPOCH 79 done: loss 1.5763 - lr 0.0016 - bad epochs 3\n",
      "2019-02-07 22:27:36,760 DEV  : loss 1.94361615 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:27:40,360 TEST : loss 1.27959383 - f-score 0.8732 - acc 0.8732\n",
      "Epoch    78: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2019-02-07 22:27:40,361 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:27:43,062 epoch 80 - iter 0/47 - loss 1.26780498\n",
      "2019-02-07 22:27:52,260 epoch 80 - iter 4/47 - loss 1.55597007\n",
      "2019-02-07 22:28:02,448 epoch 80 - iter 8/47 - loss 1.88791709\n",
      "2019-02-07 22:28:10,822 epoch 80 - iter 12/47 - loss 1.71031110\n",
      "2019-02-07 22:28:18,380 epoch 80 - iter 16/47 - loss 1.66991237\n",
      "2019-02-07 22:28:28,376 epoch 80 - iter 20/47 - loss 1.72009221\n",
      "2019-02-07 22:28:35,952 epoch 80 - iter 24/47 - loss 1.65535127\n",
      "2019-02-07 22:28:44,642 epoch 80 - iter 28/47 - loss 1.74060037\n",
      "2019-02-07 22:28:53,053 epoch 80 - iter 32/47 - loss 1.70212635\n",
      "2019-02-07 22:29:00,824 epoch 80 - iter 36/47 - loss 1.64569327\n",
      "2019-02-07 22:29:10,120 epoch 80 - iter 40/47 - loss 1.62971889\n",
      "2019-02-07 22:29:17,342 epoch 80 - iter 44/47 - loss 1.60380090\n",
      "2019-02-07 22:29:21,573 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:29:21,574 EPOCH 80 done: loss 1.6030 - lr 0.0008 - bad epochs 0\n",
      "2019-02-07 22:29:25,477 DEV  : loss 1.94273973 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:29:29,064 TEST : loss 1.27970076 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:29:29,067 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:29:31,037 epoch 81 - iter 0/47 - loss 2.60960460\n",
      "2019-02-07 22:29:40,013 epoch 81 - iter 4/47 - loss 1.56280456\n",
      "2019-02-07 22:29:48,088 epoch 81 - iter 8/47 - loss 1.58086720\n",
      "2019-02-07 22:29:56,126 epoch 81 - iter 12/47 - loss 1.55546239\n",
      "2019-02-07 22:30:04,911 epoch 81 - iter 16/47 - loss 1.52021266\n",
      "2019-02-07 22:30:13,714 epoch 81 - iter 20/47 - loss 1.47130144\n",
      "2019-02-07 22:30:22,304 epoch 81 - iter 24/47 - loss 1.48482948\n",
      "2019-02-07 22:30:30,826 epoch 81 - iter 28/47 - loss 1.53063998\n",
      "2019-02-07 22:30:40,073 epoch 81 - iter 32/47 - loss 1.58737113\n",
      "2019-02-07 22:30:48,228 epoch 81 - iter 36/47 - loss 1.59438577\n",
      "2019-02-07 22:30:57,348 epoch 81 - iter 40/47 - loss 1.62090564\n",
      "2019-02-07 22:31:06,588 epoch 81 - iter 44/47 - loss 1.58413788\n",
      "2019-02-07 22:31:10,933 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:31:10,934 EPOCH 81 done: loss 1.6283 - lr 0.0008 - bad epochs 1\n",
      "2019-02-07 22:31:14,873 DEV  : loss 1.94253969 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:31:18,368 TEST : loss 1.27921271 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:31:18,370 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:31:21,939 epoch 82 - iter 0/47 - loss 2.29503083\n",
      "2019-02-07 22:31:29,692 epoch 82 - iter 4/47 - loss 1.71608069\n",
      "2019-02-07 22:31:38,303 epoch 82 - iter 8/47 - loss 1.61070322\n",
      "2019-02-07 22:31:46,360 epoch 82 - iter 12/47 - loss 1.91739644\n",
      "2019-02-07 22:31:55,465 epoch 82 - iter 16/47 - loss 1.70535120\n",
      "2019-02-07 22:32:03,719 epoch 82 - iter 20/47 - loss 1.59684935\n",
      "2019-02-07 22:32:13,468 epoch 82 - iter 24/47 - loss 1.59094158\n",
      "2019-02-07 22:32:21,741 epoch 82 - iter 28/47 - loss 1.65711055\n",
      "2019-02-07 22:32:30,844 epoch 82 - iter 32/47 - loss 1.64391709\n",
      "2019-02-07 22:32:39,791 epoch 82 - iter 36/47 - loss 1.63757450\n",
      "2019-02-07 22:32:48,777 epoch 82 - iter 40/47 - loss 1.68055610\n",
      "2019-02-07 22:32:56,130 epoch 82 - iter 44/47 - loss 1.68750594\n",
      "2019-02-07 22:33:00,440 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:33:00,441 EPOCH 82 done: loss 1.6829 - lr 0.0008 - bad epochs 2\n",
      "2019-02-07 22:33:04,320 DEV  : loss 1.94185174 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:33:07,980 TEST : loss 1.27945065 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:33:07,982 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:33:10,160 epoch 83 - iter 0/47 - loss 0.75057977\n",
      "2019-02-07 22:33:20,420 epoch 83 - iter 4/47 - loss 1.73880497\n",
      "2019-02-07 22:33:28,819 epoch 83 - iter 8/47 - loss 1.59322873\n",
      "2019-02-07 22:33:36,567 epoch 83 - iter 12/47 - loss 1.56313410\n",
      "2019-02-07 22:33:45,263 epoch 83 - iter 16/47 - loss 1.56314556\n",
      "2019-02-07 22:33:53,243 epoch 83 - iter 20/47 - loss 1.50648869\n",
      "2019-02-07 22:34:01,377 epoch 83 - iter 24/47 - loss 1.46275628\n",
      "2019-02-07 22:34:12,247 epoch 83 - iter 28/47 - loss 1.51853366\n",
      "2019-02-07 22:34:20,158 epoch 83 - iter 32/47 - loss 1.57527422\n",
      "2019-02-07 22:34:28,116 epoch 83 - iter 36/47 - loss 1.71631815\n",
      "2019-02-07 22:34:36,187 epoch 83 - iter 40/47 - loss 1.68219999\n",
      "2019-02-07 22:34:43,897 epoch 83 - iter 44/47 - loss 1.68336810\n",
      "2019-02-07 22:34:48,108 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:34:48,109 EPOCH 83 done: loss 1.7573 - lr 0.0008 - bad epochs 3\n",
      "2019-02-07 22:34:52,050 DEV  : loss 1.94178903 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:34:55,602 TEST : loss 1.27935910 - f-score 0.8732 - acc 0.8732\n",
      "Epoch    82: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2019-02-07 22:34:55,604 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:34:57,949 epoch 84 - iter 0/47 - loss 1.11537433\n",
      "2019-02-07 22:35:07,251 epoch 84 - iter 4/47 - loss 1.41565363\n",
      "2019-02-07 22:35:17,039 epoch 84 - iter 8/47 - loss 1.64128248\n",
      "2019-02-07 22:35:26,605 epoch 84 - iter 12/47 - loss 1.69792917\n",
      "2019-02-07 22:35:34,005 epoch 84 - iter 16/47 - loss 1.73424572\n",
      "2019-02-07 22:35:42,413 epoch 84 - iter 20/47 - loss 1.81136629\n",
      "2019-02-07 22:35:51,370 epoch 84 - iter 24/47 - loss 1.78281220\n",
      "2019-02-07 22:35:59,307 epoch 84 - iter 28/47 - loss 1.77314280\n",
      "2019-02-07 22:36:08,100 epoch 84 - iter 32/47 - loss 1.75121730\n",
      "2019-02-07 22:36:15,853 epoch 84 - iter 36/47 - loss 1.69474916\n",
      "2019-02-07 22:36:24,064 epoch 84 - iter 40/47 - loss 1.69355928\n",
      "2019-02-07 22:36:32,819 epoch 84 - iter 44/47 - loss 1.68474622\n",
      "2019-02-07 22:36:37,236 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:36:37,237 EPOCH 84 done: loss 1.7087 - lr 0.0004 - bad epochs 0\n",
      "2019-02-07 22:36:41,166 DEV  : loss 1.94159818 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:36:44,763 TEST : loss 1.27937150 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:36:44,765 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:36:46,697 epoch 85 - iter 0/47 - loss 1.01248765\n",
      "2019-02-07 22:36:54,794 epoch 85 - iter 4/47 - loss 1.78376329\n",
      "2019-02-07 22:37:04,290 epoch 85 - iter 8/47 - loss 1.45000616\n",
      "2019-02-07 22:37:13,114 epoch 85 - iter 12/47 - loss 1.43865833\n",
      "2019-02-07 22:37:21,586 epoch 85 - iter 16/47 - loss 1.60493362\n",
      "2019-02-07 22:37:29,629 epoch 85 - iter 20/47 - loss 1.71022496\n",
      "2019-02-07 22:37:36,948 epoch 85 - iter 24/47 - loss 1.70296483\n",
      "2019-02-07 22:37:45,449 epoch 85 - iter 28/47 - loss 1.64325979\n",
      "2019-02-07 22:37:54,366 epoch 85 - iter 32/47 - loss 1.65379377\n",
      "2019-02-07 22:38:02,978 epoch 85 - iter 36/47 - loss 1.64871056\n",
      "2019-02-07 22:38:11,075 epoch 85 - iter 40/47 - loss 1.70215510\n",
      "2019-02-07 22:38:19,014 epoch 85 - iter 44/47 - loss 1.67778198\n",
      "2019-02-07 22:38:22,443 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:38:22,444 EPOCH 85 done: loss 1.6555 - lr 0.0004 - bad epochs 1\n",
      "2019-02-07 22:38:26,188 DEV  : loss 1.94178128 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:38:29,549 TEST : loss 1.27919149 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:38:29,551 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:38:31,276 epoch 86 - iter 0/47 - loss 1.08138859\n",
      "2019-02-07 22:38:40,530 epoch 86 - iter 4/47 - loss 1.31005113\n",
      "2019-02-07 22:38:48,969 epoch 86 - iter 8/47 - loss 1.41598855\n",
      "2019-02-07 22:38:58,825 epoch 86 - iter 12/47 - loss 1.42658958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 22:39:07,993 epoch 86 - iter 16/47 - loss 1.48910367\n",
      "2019-02-07 22:39:16,021 epoch 86 - iter 20/47 - loss 1.64789842\n",
      "2019-02-07 22:39:24,218 epoch 86 - iter 24/47 - loss 1.66564376\n",
      "2019-02-07 22:39:31,205 epoch 86 - iter 28/47 - loss 1.57883384\n",
      "2019-02-07 22:39:39,912 epoch 86 - iter 32/47 - loss 1.58364351\n",
      "2019-02-07 22:39:47,674 epoch 86 - iter 36/47 - loss 1.70154754\n",
      "2019-02-07 22:39:55,928 epoch 86 - iter 40/47 - loss 1.71389996\n",
      "2019-02-07 22:40:03,639 epoch 86 - iter 44/47 - loss 1.69395329\n",
      "2019-02-07 22:40:07,242 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:40:07,243 EPOCH 86 done: loss 1.6629 - lr 0.0004 - bad epochs 2\n",
      "2019-02-07 22:40:11,012 DEV  : loss 1.94166064 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:40:14,433 TEST : loss 1.27922761 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:40:14,435 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:40:16,238 epoch 87 - iter 0/47 - loss 1.01926553\n",
      "2019-02-07 22:40:24,898 epoch 87 - iter 4/47 - loss 1.38493009\n",
      "2019-02-07 22:40:32,299 epoch 87 - iter 8/47 - loss 1.32234676\n",
      "2019-02-07 22:40:41,097 epoch 87 - iter 12/47 - loss 1.49047145\n",
      "2019-02-07 22:40:49,255 epoch 87 - iter 16/47 - loss 1.59663199\n",
      "2019-02-07 22:40:58,046 epoch 87 - iter 20/47 - loss 1.48571013\n",
      "2019-02-07 22:41:06,764 epoch 87 - iter 24/47 - loss 1.48120973\n",
      "2019-02-07 22:41:16,294 epoch 87 - iter 28/47 - loss 1.50286059\n",
      "2019-02-07 22:41:23,961 epoch 87 - iter 32/47 - loss 1.53618924\n",
      "2019-02-07 22:41:32,147 epoch 87 - iter 36/47 - loss 1.50986877\n",
      "2019-02-07 22:41:41,467 epoch 87 - iter 40/47 - loss 1.51684898\n",
      "2019-02-07 22:41:49,183 epoch 87 - iter 44/47 - loss 1.48562778\n",
      "2019-02-07 22:41:53,973 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:41:53,974 EPOCH 87 done: loss 1.4768 - lr 0.0004 - bad epochs 3\n",
      "2019-02-07 22:41:57,709 DEV  : loss 1.94129455 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:42:01,129 TEST : loss 1.27922976 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:42:01,563 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:42:03,779 epoch 88 - iter 0/47 - loss 0.94325364\n",
      "2019-02-07 22:42:13,910 epoch 88 - iter 4/47 - loss 1.18276243\n",
      "2019-02-07 22:42:22,611 epoch 88 - iter 8/47 - loss 1.29697057\n",
      "2019-02-07 22:42:30,192 epoch 88 - iter 12/47 - loss 1.24225226\n",
      "2019-02-07 22:42:37,815 epoch 88 - iter 16/47 - loss 1.29916289\n",
      "2019-02-07 22:42:47,034 epoch 88 - iter 20/47 - loss 1.29962607\n",
      "2019-02-07 22:42:55,061 epoch 88 - iter 24/47 - loss 1.34959099\n",
      "2019-02-07 22:43:02,778 epoch 88 - iter 28/47 - loss 1.39974279\n",
      "2019-02-07 22:43:12,060 epoch 88 - iter 32/47 - loss 1.49410077\n",
      "2019-02-07 22:43:20,962 epoch 88 - iter 36/47 - loss 1.54973386\n",
      "2019-02-07 22:43:29,133 epoch 88 - iter 40/47 - loss 1.56578403\n",
      "2019-02-07 22:43:36,469 epoch 88 - iter 44/47 - loss 1.52040185\n",
      "2019-02-07 22:43:42,296 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:43:42,296 EPOCH 88 done: loss 1.5050 - lr 0.0004 - bad epochs 0\n",
      "2019-02-07 22:43:46,025 DEV  : loss 1.94094825 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:43:49,379 TEST : loss 1.27951801 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:43:49,381 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:43:51,146 epoch 89 - iter 0/47 - loss 0.80185133\n",
      "2019-02-07 22:44:00,795 epoch 89 - iter 4/47 - loss 1.09380792\n",
      "2019-02-07 22:44:08,996 epoch 89 - iter 8/47 - loss 1.19847812\n",
      "2019-02-07 22:44:17,342 epoch 89 - iter 12/47 - loss 1.30225437\n",
      "2019-02-07 22:44:24,812 epoch 89 - iter 16/47 - loss 1.36881181\n",
      "2019-02-07 22:44:32,891 epoch 89 - iter 20/47 - loss 1.46920172\n",
      "2019-02-07 22:44:42,299 epoch 89 - iter 24/47 - loss 1.49627800\n",
      "2019-02-07 22:44:50,663 epoch 89 - iter 28/47 - loss 1.52285289\n",
      "2019-02-07 22:44:58,007 epoch 89 - iter 32/47 - loss 1.54734787\n",
      "2019-02-07 22:45:05,929 epoch 89 - iter 36/47 - loss 1.54215808\n",
      "2019-02-07 22:45:14,606 epoch 89 - iter 40/47 - loss 1.56913081\n",
      "2019-02-07 22:45:23,133 epoch 89 - iter 44/47 - loss 1.52885578\n",
      "2019-02-07 22:45:27,701 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:45:27,702 EPOCH 89 done: loss 1.5207 - lr 0.0004 - bad epochs 1\n",
      "2019-02-07 22:45:31,377 DEV  : loss 1.94089758 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:45:34,714 TEST : loss 1.27940369 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:45:34,716 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:45:36,564 epoch 90 - iter 0/47 - loss 2.03259015\n",
      "2019-02-07 22:45:43,725 epoch 90 - iter 4/47 - loss 2.12794328\n",
      "2019-02-07 22:45:53,027 epoch 90 - iter 8/47 - loss 1.90425913\n",
      "2019-02-07 22:46:01,171 epoch 90 - iter 12/47 - loss 1.97656882\n",
      "2019-02-07 22:46:08,590 epoch 90 - iter 16/47 - loss 1.96056215\n",
      "2019-02-07 22:46:17,481 epoch 90 - iter 20/47 - loss 2.05337893\n",
      "2019-02-07 22:46:25,906 epoch 90 - iter 24/47 - loss 1.97178227\n",
      "2019-02-07 22:46:32,806 epoch 90 - iter 28/47 - loss 1.83907971\n",
      "2019-02-07 22:46:41,599 epoch 90 - iter 32/47 - loss 1.77290797\n",
      "2019-02-07 22:46:51,247 epoch 90 - iter 36/47 - loss 1.71131696\n",
      "2019-02-07 22:46:58,819 epoch 90 - iter 40/47 - loss 1.70130240\n",
      "2019-02-07 22:47:06,833 epoch 90 - iter 44/47 - loss 1.63578890\n",
      "2019-02-07 22:47:10,938 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:47:10,939 EPOCH 90 done: loss 1.6363 - lr 0.0004 - bad epochs 2\n",
      "2019-02-07 22:47:14,663 DEV  : loss 1.94110322 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:47:18,073 TEST : loss 1.27913737 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:47:18,075 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:47:19,562 epoch 91 - iter 0/47 - loss 0.74518323\n",
      "2019-02-07 22:47:27,206 epoch 91 - iter 4/47 - loss 1.37735896\n",
      "2019-02-07 22:47:35,391 epoch 91 - iter 8/47 - loss 1.43748283\n",
      "2019-02-07 22:47:44,830 epoch 91 - iter 12/47 - loss 1.43378589\n",
      "2019-02-07 22:47:52,897 epoch 91 - iter 16/47 - loss 1.47559942\n",
      "2019-02-07 22:48:01,158 epoch 91 - iter 20/47 - loss 1.51675410\n",
      "2019-02-07 22:48:09,839 epoch 91 - iter 24/47 - loss 1.51970986\n",
      "2019-02-07 22:48:18,351 epoch 91 - iter 28/47 - loss 1.55955314\n",
      "2019-02-07 22:48:26,540 epoch 91 - iter 32/47 - loss 1.59224260\n",
      "2019-02-07 22:48:34,489 epoch 91 - iter 36/47 - loss 1.59046360\n",
      "2019-02-07 22:48:42,292 epoch 91 - iter 40/47 - loss 1.57047667\n",
      "2019-02-07 22:48:50,190 epoch 91 - iter 44/47 - loss 1.60652571\n",
      "2019-02-07 22:48:54,873 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:48:54,874 EPOCH 91 done: loss 1.5969 - lr 0.0004 - bad epochs 3\n",
      "2019-02-07 22:48:58,596 DEV  : loss 1.94057500 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:49:02,043 TEST : loss 1.27930725 - f-score 0.8732 - acc 0.8732\n",
      "Epoch    90: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2019-02-07 22:49:02,045 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:49:04,220 epoch 92 - iter 0/47 - loss 1.16369832\n",
      "2019-02-07 22:49:11,717 epoch 92 - iter 4/47 - loss 1.68157835\n",
      "2019-02-07 22:49:20,140 epoch 92 - iter 8/47 - loss 1.46379584\n",
      "2019-02-07 22:49:27,297 epoch 92 - iter 12/47 - loss 1.62398933\n",
      "2019-02-07 22:49:35,525 epoch 92 - iter 16/47 - loss 1.77139487\n",
      "2019-02-07 22:49:43,887 epoch 92 - iter 20/47 - loss 1.73491890\n",
      "2019-02-07 22:49:53,423 epoch 92 - iter 24/47 - loss 1.86692037\n",
      "2019-02-07 22:50:01,705 epoch 92 - iter 28/47 - loss 1.79916839\n",
      "2019-02-07 22:50:10,123 epoch 92 - iter 32/47 - loss 1.79892785\n",
      "2019-02-07 22:50:18,214 epoch 92 - iter 36/47 - loss 1.79275770\n",
      "2019-02-07 22:50:26,267 epoch 92 - iter 40/47 - loss 1.77878537\n",
      "2019-02-07 22:50:34,810 epoch 92 - iter 44/47 - loss 1.78526671\n",
      "2019-02-07 22:50:39,522 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:50:39,523 EPOCH 92 done: loss 1.7693 - lr 0.0002 - bad epochs 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 22:50:43,213 DEV  : loss 1.94058466 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:50:46,552 TEST : loss 1.27926564 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:50:46,554 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:50:48,148 epoch 93 - iter 0/47 - loss 0.69335365\n",
      "2019-02-07 22:50:57,067 epoch 93 - iter 4/47 - loss 1.70402660\n",
      "2019-02-07 22:51:05,856 epoch 93 - iter 8/47 - loss 1.67303728\n",
      "2019-02-07 22:51:13,739 epoch 93 - iter 12/47 - loss 1.73072323\n",
      "2019-02-07 22:51:20,593 epoch 93 - iter 16/47 - loss 1.78888653\n",
      "2019-02-07 22:51:28,447 epoch 93 - iter 20/47 - loss 1.86571233\n",
      "2019-02-07 22:51:37,488 epoch 93 - iter 24/47 - loss 1.92574945\n",
      "2019-02-07 22:51:45,995 epoch 93 - iter 28/47 - loss 1.81761552\n",
      "2019-02-07 22:51:54,174 epoch 93 - iter 32/47 - loss 1.84709382\n",
      "2019-02-07 22:52:01,897 epoch 93 - iter 36/47 - loss 1.88082523\n",
      "2019-02-07 22:52:11,125 epoch 93 - iter 40/47 - loss 1.86270967\n",
      "2019-02-07 22:52:19,950 epoch 93 - iter 44/47 - loss 1.81697320\n",
      "2019-02-07 22:52:23,791 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:52:23,793 EPOCH 93 done: loss 1.7753 - lr 0.0002 - bad epochs 1\n",
      "2019-02-07 22:52:28,070 DEV  : loss 1.94063866 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:52:31,530 TEST : loss 1.27917087 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:52:31,532 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:52:33,923 epoch 94 - iter 0/47 - loss 1.96239913\n",
      "2019-02-07 22:52:42,374 epoch 94 - iter 4/47 - loss 1.37297616\n",
      "2019-02-07 22:52:51,022 epoch 94 - iter 8/47 - loss 1.49490135\n",
      "2019-02-07 22:53:00,065 epoch 94 - iter 12/47 - loss 1.39255423\n",
      "2019-02-07 22:53:07,978 epoch 94 - iter 16/47 - loss 1.48873096\n",
      "2019-02-07 22:53:16,403 epoch 94 - iter 20/47 - loss 1.53009876\n",
      "2019-02-07 22:53:24,730 epoch 94 - iter 24/47 - loss 1.49352427\n",
      "2019-02-07 22:53:32,546 epoch 94 - iter 28/47 - loss 1.49421844\n",
      "2019-02-07 22:53:40,840 epoch 94 - iter 32/47 - loss 1.52249396\n",
      "2019-02-07 22:53:49,879 epoch 94 - iter 36/47 - loss 1.52369424\n",
      "2019-02-07 22:53:58,016 epoch 94 - iter 40/47 - loss 1.52057485\n",
      "2019-02-07 22:54:06,707 epoch 94 - iter 44/47 - loss 1.56895281\n",
      "2019-02-07 22:54:10,605 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:54:10,606 EPOCH 94 done: loss 1.5755 - lr 0.0002 - bad epochs 2\n",
      "2019-02-07 22:54:14,362 DEV  : loss 1.94044924 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:54:17,783 TEST : loss 1.27919567 - f-score 0.8732 - acc 0.8732\n",
      "2019-02-07 22:54:17,785 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:54:19,979 epoch 95 - iter 0/47 - loss 2.48901129\n",
      "2019-02-07 22:54:28,163 epoch 95 - iter 4/47 - loss 1.52834425\n",
      "2019-02-07 22:54:37,405 epoch 95 - iter 8/47 - loss 1.58828545\n",
      "2019-02-07 22:54:46,858 epoch 95 - iter 12/47 - loss 1.59161777\n",
      "2019-02-07 22:54:55,250 epoch 95 - iter 16/47 - loss 1.61284612\n",
      "2019-02-07 22:55:02,649 epoch 95 - iter 20/47 - loss 1.60190260\n",
      "2019-02-07 22:55:12,876 epoch 95 - iter 24/47 - loss 1.65800763\n",
      "2019-02-07 22:55:21,194 epoch 95 - iter 28/47 - loss 1.57481198\n",
      "2019-02-07 22:55:29,554 epoch 95 - iter 32/47 - loss 1.55507728\n",
      "2019-02-07 22:55:37,373 epoch 95 - iter 36/47 - loss 1.56456382\n",
      "2019-02-07 22:55:45,553 epoch 95 - iter 40/47 - loss 1.61076927\n",
      "2019-02-07 22:55:54,136 epoch 95 - iter 44/47 - loss 1.62535093\n",
      "2019-02-07 22:55:58,007 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:55:58,008 EPOCH 95 done: loss 1.6526 - lr 0.0002 - bad epochs 3\n",
      "2019-02-07 22:56:01,888 DEV  : loss 1.94038963 - f-score 0.8612 - acc 0.8612\n",
      "2019-02-07 22:56:05,315 TEST : loss 1.27922034 - f-score 0.8732 - acc 0.8732\n",
      "Epoch    94: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2019-02-07 22:56:05,318 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:56:05,319 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:56:05,319 learning rate too small - quitting training!\n",
      "2019-02-07 22:56:05,320 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:56:05,803 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 22:56:05,804 Testing using best model ...\n",
      "2019-02-07 22:56:10,125 MICRO_AVG: acc 0.8732 - f1-score 0.8732\n",
      "2019-02-07 22:56:10,126 MARCO_AVG: acc 0.863 - f1-score 0.8535\n",
      "2019-02-07 22:56:10,127 LOC        tp: 141 - fp: 17 - fn: 15 - tn: 141 - precision: 0.8924 - recall: 0.9038 - accuracy: 0.8981 - f1-score: 0.8981\n",
      "2019-02-07 22:56:10,127 MISC       tp: 50 - fp: 13 - fn: 13 - tn: 50 - precision: 0.7937 - recall: 0.7937 - accuracy: 0.7937 - f1-score: 0.7937\n",
      "2019-02-07 22:56:10,128 ORG        tp: 139 - fp: 44 - fn: 25 - tn: 139 - precision: 0.7596 - recall: 0.8476 - accuracy: 0.8012 - f1-score: 0.8012\n",
      "2019-02-07 22:56:10,129 PER        tp: 152 - fp: 5 - fn: 8 - tn: 152 - precision: 0.9682 - recall: 0.9500 - accuracy: 0.9590 - f1-score: 0.9590\n",
      "2019-02-07 22:56:10,130 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8732,\n",
       " 'dev_score_history': [0.0,\n",
       "  0.0301,\n",
       "  0.0823,\n",
       "  0.3142,\n",
       "  0.4032,\n",
       "  0.4513,\n",
       "  0.4931,\n",
       "  0.5316,\n",
       "  0.5664,\n",
       "  0.5899,\n",
       "  0.6063,\n",
       "  0.6422,\n",
       "  0.6575,\n",
       "  0.6662,\n",
       "  0.6667,\n",
       "  0.7016,\n",
       "  0.6871,\n",
       "  0.7341,\n",
       "  0.7502,\n",
       "  0.7517,\n",
       "  0.763,\n",
       "  0.7738,\n",
       "  0.7837,\n",
       "  0.8006,\n",
       "  0.8009,\n",
       "  0.8056,\n",
       "  0.8098,\n",
       "  0.812,\n",
       "  0.8142,\n",
       "  0.8207,\n",
       "  0.8237,\n",
       "  0.8243,\n",
       "  0.8328,\n",
       "  0.8295,\n",
       "  0.8285,\n",
       "  0.8382,\n",
       "  0.8448,\n",
       "  0.8442,\n",
       "  0.8426,\n",
       "  0.8472,\n",
       "  0.8544,\n",
       "  0.8553,\n",
       "  0.8524,\n",
       "  0.8578,\n",
       "  0.8565,\n",
       "  0.8513,\n",
       "  0.8558,\n",
       "  0.8549,\n",
       "  0.8619,\n",
       "  0.8585,\n",
       "  0.8567,\n",
       "  0.8546,\n",
       "  0.856,\n",
       "  0.8556,\n",
       "  0.8549,\n",
       "  0.8558,\n",
       "  0.8603,\n",
       "  0.8597,\n",
       "  0.8581,\n",
       "  0.8558,\n",
       "  0.8551,\n",
       "  0.859,\n",
       "  0.8542,\n",
       "  0.8565,\n",
       "  0.8565,\n",
       "  0.8587,\n",
       "  0.8628,\n",
       "  0.8581,\n",
       "  0.859,\n",
       "  0.8606,\n",
       "  0.8583,\n",
       "  0.859,\n",
       "  0.8612,\n",
       "  0.8583,\n",
       "  0.8635,\n",
       "  0.8635,\n",
       "  0.8635,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612,\n",
       "  0.8612],\n",
       " 'train_loss_history': [19.282065138966342,\n",
       "  12.436092526853841,\n",
       "  10.127114161719792,\n",
       "  8.71958517185285,\n",
       "  7.893121170949904,\n",
       "  7.238084687480455,\n",
       "  6.83833318586903,\n",
       "  6.248010076786217,\n",
       "  5.826831499523445,\n",
       "  5.57317185354201,\n",
       "  5.097731017048475,\n",
       "  4.88671119695031,\n",
       "  4.771219799405658,\n",
       "  4.601388779857144,\n",
       "  4.518804294415678,\n",
       "  4.193194012072501,\n",
       "  4.096574150935422,\n",
       "  3.8678447425643787,\n",
       "  3.8149483230926737,\n",
       "  3.416072219431281,\n",
       "  3.442634002298733,\n",
       "  3.310354832095095,\n",
       "  3.119005858540296,\n",
       "  3.1839610195859738,\n",
       "  3.094566233242409,\n",
       "  2.954466554464858,\n",
       "  2.8528729541211066,\n",
       "  2.946529235738051,\n",
       "  2.8646161344705066,\n",
       "  2.6351091360711827,\n",
       "  2.680110356265342,\n",
       "  2.5814243746726335,\n",
       "  2.2823515708164983,\n",
       "  2.3154367557599436,\n",
       "  2.32702131697621,\n",
       "  2.1634615897496117,\n",
       "  2.1619370914125855,\n",
       "  2.394802943478432,\n",
       "  2.2846983539970656,\n",
       "  1.9596933386499202,\n",
       "  2.112793711839794,\n",
       "  2.1660350967519197,\n",
       "  1.992366984178417,\n",
       "  2.1052133217901288,\n",
       "  1.9625371560166087,\n",
       "  1.9407943142820312,\n",
       "  1.860979064931227,\n",
       "  1.8632822819277792,\n",
       "  1.9176636378394516,\n",
       "  1.8572207330623574,\n",
       "  1.7752963632961525,\n",
       "  1.6580731561774011,\n",
       "  1.7271633071848518,\n",
       "  1.8280832253749406,\n",
       "  1.7086224177426064,\n",
       "  1.733023259860822,\n",
       "  1.802282964491383,\n",
       "  1.6875171203307902,\n",
       "  1.7064444158298322,\n",
       "  1.8276663908090012,\n",
       "  1.7810317873557144,\n",
       "  1.7155287566385402,\n",
       "  1.6808471577894377,\n",
       "  1.7068470216258675,\n",
       "  1.659280902946528,\n",
       "  1.5854402781328096,\n",
       "  1.5402250919761937,\n",
       "  1.7017035659270894,\n",
       "  1.5452029436250143,\n",
       "  1.6292784832731098,\n",
       "  1.677028762888638,\n",
       "  1.570672436663912,\n",
       "  1.5619962843678012,\n",
       "  1.6745632596617146,\n",
       "  1.562207706138402,\n",
       "  1.5645525196220496,\n",
       "  1.5561060526913368,\n",
       "  1.644562544386891,\n",
       "  1.5762669001522662,\n",
       "  1.6029740359641615,\n",
       "  1.6282732316539477,\n",
       "  1.6829238990849857,\n",
       "  1.7573386657389105,\n",
       "  1.708678952370428,\n",
       "  1.655462982656162,\n",
       "  1.6628904565323823,\n",
       "  1.4767749180707874,\n",
       "  1.5050266665407146,\n",
       "  1.5207017869294048,\n",
       "  1.6362621340455812,\n",
       "  1.5968520728805369,\n",
       "  1.7693157126062151,\n",
       "  1.7752902328053501,\n",
       "  1.5755087818759055,\n",
       "  1.652629044312012],\n",
       " 'dev_loss_history': [15.523669242858887,\n",
       "  11.827692985534668,\n",
       "  9.772640228271484,\n",
       "  8.69266128540039,\n",
       "  7.929448127746582,\n",
       "  7.223570346832275,\n",
       "  6.590437412261963,\n",
       "  6.044938564300537,\n",
       "  5.571813583374023,\n",
       "  5.224013328552246,\n",
       "  4.906778812408447,\n",
       "  4.672459602355957,\n",
       "  4.4167399406433105,\n",
       "  4.231295108795166,\n",
       "  4.014710903167725,\n",
       "  3.855642080307007,\n",
       "  3.6828079223632812,\n",
       "  3.533104181289673,\n",
       "  3.406381130218506,\n",
       "  3.2893474102020264,\n",
       "  3.188311815261841,\n",
       "  3.1584665775299072,\n",
       "  3.012023448944092,\n",
       "  2.9672815799713135,\n",
       "  2.844665765762329,\n",
       "  2.7482845783233643,\n",
       "  2.709282398223877,\n",
       "  2.6349215507507324,\n",
       "  2.5771145820617676,\n",
       "  2.559013605117798,\n",
       "  2.457022190093994,\n",
       "  2.4337379932403564,\n",
       "  2.3597517013549805,\n",
       "  2.3531253337860107,\n",
       "  2.3048784732818604,\n",
       "  2.3316245079040527,\n",
       "  2.240103244781494,\n",
       "  2.215573310852051,\n",
       "  2.2208282947540283,\n",
       "  2.134641408920288,\n",
       "  2.1817166805267334,\n",
       "  2.1224148273468018,\n",
       "  2.085193157196045,\n",
       "  2.064817428588867,\n",
       "  2.0510456562042236,\n",
       "  2.0482375621795654,\n",
       "  2.0531108379364014,\n",
       "  2.0425713062286377,\n",
       "  2.0784921646118164,\n",
       "  2.014554262161255,\n",
       "  1.9972139596939087,\n",
       "  1.9860966205596924,\n",
       "  1.9983453750610352,\n",
       "  1.9782167673110962,\n",
       "  1.9573726654052734,\n",
       "  1.9724767208099365,\n",
       "  1.9788603782653809,\n",
       "  1.9643625020980835,\n",
       "  1.9704896211624146,\n",
       "  1.9511641263961792,\n",
       "  1.9430582523345947,\n",
       "  1.9500046968460083,\n",
       "  1.9586139917373657,\n",
       "  1.9559038877487183,\n",
       "  1.9555165767669678,\n",
       "  1.9540801048278809,\n",
       "  1.9404433965682983,\n",
       "  1.9467884302139282,\n",
       "  1.9470149278640747,\n",
       "  1.9393744468688965,\n",
       "  1.9419574737548828,\n",
       "  1.944309949874878,\n",
       "  1.9419759511947632,\n",
       "  1.9405988454818726,\n",
       "  1.9407767057418823,\n",
       "  1.939853310585022,\n",
       "  1.9407274723052979,\n",
       "  1.9424452781677246,\n",
       "  1.9436161518096924,\n",
       "  1.942739725112915,\n",
       "  1.9425396919250488,\n",
       "  1.9418517351150513,\n",
       "  1.9417890310287476,\n",
       "  1.9415981769561768,\n",
       "  1.9417812824249268,\n",
       "  1.9416606426239014,\n",
       "  1.941294550895691,\n",
       "  1.940948247909546,\n",
       "  1.9408975839614868,\n",
       "  1.941103219985962,\n",
       "  1.9405750036239624,\n",
       "  1.940584659576416,\n",
       "  1.9406386613845825,\n",
       "  1.9404492378234863,\n",
       "  1.940389633178711]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. start training\n",
    "trainer.train(FOLDER,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. plot training curves (optional)\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_training_curves(FOLDER + '/loss.tsv')\n",
    "plotter.plot_weights(FOLDER + '/weights.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Training Curves](resources/taggers/bert_downsampled/training.png \"Training Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the GloVe test\n",
    "![Training Curves](resources/taggers/example-ner/training.png \"Training Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe Weights\n",
    "![Weights](resources/taggers/example-ner/weights.png \"Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Weights\n",
    "![Weights](resources/taggers/bert_downsampled/weights.png \"Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model you trained\n",
    "model = SequenceTagger.load_from_file(FOLDER + '/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IU <S-LOC> is a great place to study NLP. <S-ORG>\n",
      "Damir <B-PER> Cavar <E-PER> is on the faculty\n",
      "Bertolt <S-PER> is a student.\n",
      "He was named after the playwright Bertolt <B-PER> Brecht. <E-PER>\n"
     ]
    }
   ],
   "source": [
    "# create example sentence\n",
    "sentences = [Sentence('IU is a great place to study NLP.'),\n",
    "             Sentence('Damir Cavar is on the faculty'),\n",
    "             Sentence('Bertolt is a student.'),\n",
    "             Sentence('He was named after the playwright Bertolt Brecht.')]\n",
    "\n",
    "# predict tags and print\n",
    "for sentence in sentences:\n",
    "    model.predict(sentence)\n",
    "    print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
