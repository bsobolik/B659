{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe in [flair](https://github.com/zalandoresearch/flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "from typing import List\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to download the corpus from [here](https://github.com/Franck-Dernoncourt/NeuroNER/tree/master/data/conll2003/en). Move the files train.txt, test.txt, and valid.txt to ~/.flair/datasets/conll_03/ and rename valid.txt to dev.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 17:51:53,148 Reading data from /Users/bsobolik/.flair/datasets/conll_03\n",
      "2019-02-07 17:51:53,148 Train: /Users/bsobolik/.flair/datasets/conll_03/train.txt\n",
      "2019-02-07 17:51:53,150 Dev: /Users/bsobolik/.flair/datasets/conll_03/dev.txt\n",
      "2019-02-07 17:51:53,150 Test: /Users/bsobolik/.flair/datasets/conll_03/test.txt\n",
      "TaggedCorpus: 1499 train + 347 dev + 369 test sentences\n"
     ]
    }
   ],
   "source": [
    "# 1. get the corpus\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_corpus(NLPTask.CONLL_03).downsample(0.1)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'<unk>', b'O', b'S-PER', b'S-ORG', b'S-LOC', b'S-MISC', b'B-ORG', b'E-ORG', b'I-ORG', b'B-LOC', b'E-LOC', b'B-PER', b'E-PER', b'B-MISC', b'E-MISC', b'I-PER', b'I-MISC', b'I-LOC', b'<START>', b'<STOP>']\n"
     ]
    }
   ],
   "source": [
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    # FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. initialize sequence tagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. initialize trainer\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 17:54:20,968 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:54:20,969 Evaluation method: MICRO_F1_SCORE\n",
      "2019-02-07 17:54:20,973 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:54:21,249 epoch 1 - iter 0/47 - loss 57.04051590\n",
      "2019-02-07 17:54:22,240 epoch 1 - iter 4/47 - loss 36.19428024\n",
      "2019-02-07 17:54:23,152 epoch 1 - iter 8/47 - loss 25.74501197\n",
      "2019-02-07 17:54:24,138 epoch 1 - iter 12/47 - loss 22.00824400\n",
      "2019-02-07 17:54:24,959 epoch 1 - iter 16/47 - loss 19.63252634\n",
      "2019-02-07 17:54:25,862 epoch 1 - iter 20/47 - loss 18.11842246\n",
      "2019-02-07 17:54:26,873 epoch 1 - iter 24/47 - loss 17.24353764\n",
      "2019-02-07 17:54:27,824 epoch 1 - iter 28/47 - loss 16.43055913\n",
      "2019-02-07 17:54:28,771 epoch 1 - iter 32/47 - loss 15.92842694\n",
      "2019-02-07 17:54:29,774 epoch 1 - iter 36/47 - loss 15.34815407\n",
      "2019-02-07 17:54:30,808 epoch 1 - iter 40/47 - loss 15.02319615\n",
      "2019-02-07 17:54:31,890 epoch 1 - iter 44/47 - loss 14.56152081\n",
      "2019-02-07 17:54:32,436 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:54:32,437 EPOCH 1 done: loss 14.3994 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:54:33,530 DEV  : loss 11.48465157 - f-score 0.0151 - acc 0.0152\n",
      "2019-02-07 17:54:34,523 TEST : loss 8.82620811 - f-score 0.0120 - acc 0.0120\n",
      "2019-02-07 17:54:37,223 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:54:37,511 epoch 2 - iter 0/47 - loss 11.41870689\n",
      "2019-02-07 17:54:38,686 epoch 2 - iter 4/47 - loss 10.88355865\n",
      "2019-02-07 17:54:39,720 epoch 2 - iter 8/47 - loss 11.15103277\n",
      "2019-02-07 17:54:40,891 epoch 2 - iter 12/47 - loss 10.94101587\n",
      "2019-02-07 17:54:41,781 epoch 2 - iter 16/47 - loss 10.48973894\n",
      "2019-02-07 17:54:42,684 epoch 2 - iter 20/47 - loss 10.19462533\n",
      "2019-02-07 17:54:43,590 epoch 2 - iter 24/47 - loss 10.21583597\n",
      "2019-02-07 17:54:44,643 epoch 2 - iter 28/47 - loss 10.02233408\n",
      "2019-02-07 17:54:45,479 epoch 2 - iter 32/47 - loss 9.86981951\n",
      "2019-02-07 17:54:46,736 epoch 2 - iter 36/47 - loss 9.70748716\n",
      "2019-02-07 17:54:47,715 epoch 2 - iter 40/47 - loss 9.59231807\n",
      "2019-02-07 17:54:48,708 epoch 2 - iter 44/47 - loss 9.38355645\n",
      "2019-02-07 17:54:49,098 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:54:49,099 EPOCH 2 done: loss 9.3294 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:54:50,130 DEV  : loss 8.00063419 - f-score 0.4041 - acc 0.4041\n",
      "2019-02-07 17:54:51,075 TEST : loss 5.87901497 - f-score 0.3829 - acc 0.3829\n",
      "2019-02-07 17:54:53,652 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:54:53,898 epoch 3 - iter 0/47 - loss 8.48832703\n",
      "2019-02-07 17:54:55,120 epoch 3 - iter 4/47 - loss 7.77558298\n",
      "2019-02-07 17:54:56,047 epoch 3 - iter 8/47 - loss 7.75663233\n",
      "2019-02-07 17:54:56,974 epoch 3 - iter 12/47 - loss 7.63446980\n",
      "2019-02-07 17:54:57,984 epoch 3 - iter 16/47 - loss 7.69443391\n",
      "2019-02-07 17:54:58,963 epoch 3 - iter 20/47 - loss 7.60742987\n",
      "2019-02-07 17:55:00,169 epoch 3 - iter 24/47 - loss 7.63742142\n",
      "2019-02-07 17:55:01,292 epoch 3 - iter 28/47 - loss 7.46032975\n",
      "2019-02-07 17:55:02,397 epoch 3 - iter 32/47 - loss 7.47346320\n",
      "2019-02-07 17:55:03,323 epoch 3 - iter 36/47 - loss 7.45020464\n",
      "2019-02-07 17:55:04,284 epoch 3 - iter 40/47 - loss 7.43064193\n",
      "2019-02-07 17:55:05,195 epoch 3 - iter 44/47 - loss 7.43998799\n",
      "2019-02-07 17:55:05,583 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:55:05,584 EPOCH 3 done: loss 7.3897 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:55:06,625 DEV  : loss 6.86526871 - f-score 0.4304 - acc 0.4304\n",
      "2019-02-07 17:55:07,579 TEST : loss 4.92942572 - f-score 0.4102 - acc 0.4102\n",
      "2019-02-07 17:55:10,361 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:55:10,630 epoch 4 - iter 0/47 - loss 6.52635145\n",
      "2019-02-07 17:55:11,592 epoch 4 - iter 4/47 - loss 7.53985386\n",
      "2019-02-07 17:55:12,597 epoch 4 - iter 8/47 - loss 7.42288680\n",
      "2019-02-07 17:55:13,669 epoch 4 - iter 12/47 - loss 7.21152874\n",
      "2019-02-07 17:55:14,769 epoch 4 - iter 16/47 - loss 6.89125715\n",
      "2019-02-07 17:55:15,926 epoch 4 - iter 20/47 - loss 6.79574008\n",
      "2019-02-07 17:55:17,010 epoch 4 - iter 24/47 - loss 6.82801786\n",
      "2019-02-07 17:55:18,023 epoch 4 - iter 28/47 - loss 6.74778664\n",
      "2019-02-07 17:55:18,943 epoch 4 - iter 32/47 - loss 6.74896587\n",
      "2019-02-07 17:55:19,934 epoch 4 - iter 36/47 - loss 6.63555263\n",
      "2019-02-07 17:55:20,958 epoch 4 - iter 40/47 - loss 6.58282552\n",
      "2019-02-07 17:55:21,952 epoch 4 - iter 44/47 - loss 6.56088627\n",
      "2019-02-07 17:55:22,327 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:55:22,328 EPOCH 4 done: loss 6.5595 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:55:23,966 DEV  : loss 6.16120481 - f-score 0.4596 - acc 0.4596\n",
      "2019-02-07 17:55:25,071 TEST : loss 4.32063770 - f-score 0.4531 - acc 0.4531\n",
      "2019-02-07 17:55:27,973 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:55:28,230 epoch 5 - iter 0/47 - loss 4.44930410\n",
      "2019-02-07 17:55:29,499 epoch 5 - iter 4/47 - loss 6.53399763\n",
      "2019-02-07 17:55:30,536 epoch 5 - iter 8/47 - loss 6.29766358\n",
      "2019-02-07 17:55:32,072 epoch 5 - iter 12/47 - loss 5.93714520\n",
      "2019-02-07 17:55:33,411 epoch 5 - iter 16/47 - loss 6.16630947\n",
      "2019-02-07 17:55:34,505 epoch 5 - iter 20/47 - loss 6.25484394\n",
      "2019-02-07 17:55:35,532 epoch 5 - iter 24/47 - loss 6.22538813\n",
      "2019-02-07 17:55:36,407 epoch 5 - iter 28/47 - loss 6.10231954\n",
      "2019-02-07 17:55:37,320 epoch 5 - iter 32/47 - loss 5.96220873\n",
      "2019-02-07 17:55:38,241 epoch 5 - iter 36/47 - loss 5.91246999\n",
      "2019-02-07 17:55:39,303 epoch 5 - iter 40/47 - loss 5.98596729\n",
      "2019-02-07 17:55:40,174 epoch 5 - iter 44/47 - loss 5.88155820\n",
      "2019-02-07 17:55:40,744 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:55:40,747 EPOCH 5 done: loss 5.9063 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:55:41,845 DEV  : loss 5.04851770 - f-score 0.6164 - acc 0.6164\n",
      "2019-02-07 17:55:42,818 TEST : loss 3.47671199 - f-score 0.6490 - acc 0.6489\n",
      "2019-02-07 17:55:45,465 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:55:45,701 epoch 6 - iter 0/47 - loss 4.46904850\n",
      "2019-02-07 17:55:46,810 epoch 6 - iter 4/47 - loss 5.48148966\n",
      "2019-02-07 17:55:47,822 epoch 6 - iter 8/47 - loss 5.63767815\n",
      "2019-02-07 17:55:48,718 epoch 6 - iter 12/47 - loss 5.63749842\n",
      "2019-02-07 17:55:49,760 epoch 6 - iter 16/47 - loss 5.65997794\n",
      "2019-02-07 17:55:50,689 epoch 6 - iter 20/47 - loss 5.65734539\n",
      "2019-02-07 17:55:51,609 epoch 6 - iter 24/47 - loss 5.66112292\n",
      "2019-02-07 17:55:52,510 epoch 6 - iter 28/47 - loss 5.61194816\n",
      "2019-02-07 17:55:53,371 epoch 6 - iter 32/47 - loss 5.50515767\n",
      "2019-02-07 17:55:54,210 epoch 6 - iter 36/47 - loss 5.40767251\n",
      "2019-02-07 17:55:55,276 epoch 6 - iter 40/47 - loss 5.37592954\n",
      "2019-02-07 17:55:56,312 epoch 6 - iter 44/47 - loss 5.38364130\n",
      "2019-02-07 17:55:56,754 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:55:56,755 EPOCH 6 done: loss 5.3933 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:55:57,783 DEV  : loss 4.80242252 - f-score 0.6085 - acc 0.6084\n",
      "2019-02-07 17:55:58,732 TEST : loss 3.23825145 - f-score 0.6350 - acc 0.6349\n",
      "2019-02-07 17:56:01,384 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:56:01,770 epoch 7 - iter 0/47 - loss 2.85304070\n",
      "2019-02-07 17:56:02,754 epoch 7 - iter 4/47 - loss 4.55952168\n",
      "2019-02-07 17:56:03,901 epoch 7 - iter 8/47 - loss 5.25081947\n",
      "2019-02-07 17:56:04,852 epoch 7 - iter 12/47 - loss 5.13106361\n",
      "2019-02-07 17:56:05,848 epoch 7 - iter 16/47 - loss 5.01170554\n",
      "2019-02-07 17:56:06,793 epoch 7 - iter 20/47 - loss 5.00623207\n",
      "2019-02-07 17:56:07,747 epoch 7 - iter 24/47 - loss 4.99526708\n",
      "2019-02-07 17:56:08,783 epoch 7 - iter 28/47 - loss 5.11081718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 17:56:09,915 epoch 7 - iter 32/47 - loss 5.11517895\n",
      "2019-02-07 17:56:10,882 epoch 7 - iter 36/47 - loss 5.00320625\n",
      "2019-02-07 17:56:11,894 epoch 7 - iter 40/47 - loss 4.94634803\n",
      "2019-02-07 17:56:12,861 epoch 7 - iter 44/47 - loss 4.99222038\n",
      "2019-02-07 17:56:13,276 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:56:13,276 EPOCH 7 done: loss 4.9521 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:56:14,414 DEV  : loss 4.70813227 - f-score 0.6385 - acc 0.6386\n",
      "2019-02-07 17:56:15,408 TEST : loss 3.10126185 - f-score 0.6555 - acc 0.6555\n",
      "2019-02-07 17:56:18,246 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:56:18,556 epoch 8 - iter 0/47 - loss 5.44628572\n",
      "2019-02-07 17:56:19,523 epoch 8 - iter 4/47 - loss 5.10818763\n",
      "2019-02-07 17:56:20,464 epoch 8 - iter 8/47 - loss 4.57984606\n",
      "2019-02-07 17:56:21,513 epoch 8 - iter 12/47 - loss 4.64454414\n",
      "2019-02-07 17:56:22,478 epoch 8 - iter 16/47 - loss 4.52962226\n",
      "2019-02-07 17:56:23,760 epoch 8 - iter 20/47 - loss 4.57419994\n",
      "2019-02-07 17:56:24,717 epoch 8 - iter 24/47 - loss 4.65890037\n",
      "2019-02-07 17:56:25,846 epoch 8 - iter 28/47 - loss 4.60594901\n",
      "2019-02-07 17:56:26,930 epoch 8 - iter 32/47 - loss 4.63660078\n",
      "2019-02-07 17:56:27,903 epoch 8 - iter 36/47 - loss 4.58284848\n",
      "2019-02-07 17:56:28,811 epoch 8 - iter 40/47 - loss 4.57459058\n",
      "2019-02-07 17:56:29,898 epoch 8 - iter 44/47 - loss 4.62250744\n",
      "2019-02-07 17:56:30,338 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:56:30,339 EPOCH 8 done: loss 4.6663 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:56:31,392 DEV  : loss 4.26963615 - f-score 0.6302 - acc 0.6302\n",
      "2019-02-07 17:56:32,330 TEST : loss 2.85166478 - f-score 0.6555 - acc 0.6554\n",
      "2019-02-07 17:56:34,985 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:56:35,245 epoch 9 - iter 0/47 - loss 3.27415776\n",
      "2019-02-07 17:56:36,258 epoch 9 - iter 4/47 - loss 4.29513073\n",
      "2019-02-07 17:56:37,210 epoch 9 - iter 8/47 - loss 4.12918517\n",
      "2019-02-07 17:56:38,116 epoch 9 - iter 12/47 - loss 4.20890450\n",
      "2019-02-07 17:56:39,173 epoch 9 - iter 16/47 - loss 4.54901904\n",
      "2019-02-07 17:56:40,199 epoch 9 - iter 20/47 - loss 4.48589666\n",
      "2019-02-07 17:56:41,238 epoch 9 - iter 24/47 - loss 4.53379141\n",
      "2019-02-07 17:56:42,128 epoch 9 - iter 28/47 - loss 4.31468624\n",
      "2019-02-07 17:56:43,073 epoch 9 - iter 32/47 - loss 4.34612687\n",
      "2019-02-07 17:56:44,124 epoch 9 - iter 36/47 - loss 4.39325866\n",
      "2019-02-07 17:56:45,106 epoch 9 - iter 40/47 - loss 4.38819474\n",
      "2019-02-07 17:56:46,167 epoch 9 - iter 44/47 - loss 4.35334082\n",
      "2019-02-07 17:56:46,594 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:56:46,595 EPOCH 9 done: loss 4.3744 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:56:47,653 DEV  : loss 3.77524638 - f-score 0.6570 - acc 0.6569\n",
      "2019-02-07 17:56:48,620 TEST : loss 2.46669793 - f-score 0.7041 - acc 0.7041\n",
      "2019-02-07 17:56:51,432 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:56:51,658 epoch 10 - iter 0/47 - loss 4.34843922\n",
      "2019-02-07 17:56:52,476 epoch 10 - iter 4/47 - loss 3.82096467\n",
      "2019-02-07 17:56:53,592 epoch 10 - iter 8/47 - loss 4.10650296\n",
      "2019-02-07 17:56:54,563 epoch 10 - iter 12/47 - loss 4.13653201\n",
      "2019-02-07 17:56:55,542 epoch 10 - iter 16/47 - loss 4.13468549\n",
      "2019-02-07 17:56:56,557 epoch 10 - iter 20/47 - loss 4.26898383\n",
      "2019-02-07 17:56:57,424 epoch 10 - iter 24/47 - loss 4.16052397\n",
      "2019-02-07 17:56:58,539 epoch 10 - iter 28/47 - loss 4.16815860\n",
      "2019-02-07 17:56:59,602 epoch 10 - iter 32/47 - loss 4.31006231\n",
      "2019-02-07 17:57:00,515 epoch 10 - iter 36/47 - loss 4.18356533\n",
      "2019-02-07 17:57:01,461 epoch 10 - iter 40/47 - loss 4.16483404\n",
      "2019-02-07 17:57:02,350 epoch 10 - iter 44/47 - loss 4.15886473\n",
      "2019-02-07 17:57:02,867 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:57:02,868 EPOCH 10 done: loss 4.2128 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:57:03,913 DEV  : loss 3.42138386 - f-score 0.7299 - acc 0.7300\n",
      "2019-02-07 17:57:04,856 TEST : loss 2.27934194 - f-score 0.7412 - acc 0.7412\n",
      "2019-02-07 17:57:07,773 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:57:08,082 epoch 11 - iter 0/47 - loss 4.23645592\n",
      "2019-02-07 17:57:09,136 epoch 11 - iter 4/47 - loss 3.58983836\n",
      "2019-02-07 17:57:10,070 epoch 11 - iter 8/47 - loss 3.73646731\n",
      "2019-02-07 17:57:10,984 epoch 11 - iter 12/47 - loss 3.74624694\n",
      "2019-02-07 17:57:12,156 epoch 11 - iter 16/47 - loss 3.79460946\n",
      "2019-02-07 17:57:13,159 epoch 11 - iter 20/47 - loss 3.80701802\n",
      "2019-02-07 17:57:14,209 epoch 11 - iter 24/47 - loss 3.86432277\n",
      "2019-02-07 17:57:16,140 epoch 11 - iter 28/47 - loss 3.86512674\n",
      "2019-02-07 17:57:17,280 epoch 11 - iter 32/47 - loss 3.88784180\n",
      "2019-02-07 17:57:18,241 epoch 11 - iter 36/47 - loss 3.92842118\n",
      "2019-02-07 17:57:19,365 epoch 11 - iter 40/47 - loss 3.98970296\n",
      "2019-02-07 17:57:20,525 epoch 11 - iter 44/47 - loss 4.03381544\n",
      "2019-02-07 17:57:20,948 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:57:20,949 EPOCH 11 done: loss 4.0176 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:57:22,121 DEV  : loss 3.28704929 - f-score 0.7282 - acc 0.7283\n",
      "2019-02-07 17:57:23,148 TEST : loss 2.21457911 - f-score 0.7440 - acc 0.7440\n",
      "2019-02-07 17:57:26,057 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:57:26,289 epoch 12 - iter 0/47 - loss 3.22120380\n",
      "2019-02-07 17:57:27,471 epoch 12 - iter 4/47 - loss 3.80788679\n",
      "2019-02-07 17:57:28,406 epoch 12 - iter 8/47 - loss 3.86516680\n",
      "2019-02-07 17:57:29,577 epoch 12 - iter 12/47 - loss 3.62319475\n",
      "2019-02-07 17:57:30,573 epoch 12 - iter 16/47 - loss 3.61053247\n",
      "2019-02-07 17:57:31,549 epoch 12 - iter 20/47 - loss 3.61264799\n",
      "2019-02-07 17:57:32,637 epoch 12 - iter 24/47 - loss 3.66217489\n",
      "2019-02-07 17:57:33,674 epoch 12 - iter 28/47 - loss 3.78367202\n",
      "2019-02-07 17:57:34,570 epoch 12 - iter 32/47 - loss 3.72549542\n",
      "2019-02-07 17:57:35,792 epoch 12 - iter 36/47 - loss 3.78569270\n",
      "2019-02-07 17:57:37,341 epoch 12 - iter 40/47 - loss 3.86728421\n",
      "2019-02-07 17:57:38,377 epoch 12 - iter 44/47 - loss 3.88105919\n",
      "2019-02-07 17:57:39,260 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:57:39,262 EPOCH 12 done: loss 3.8865 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:57:40,420 DEV  : loss 3.15545344 - f-score 0.7382 - acc 0.7382\n",
      "2019-02-07 17:57:41,491 TEST : loss 2.07294154 - f-score 0.7665 - acc 0.7665\n",
      "2019-02-07 17:57:44,236 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:57:44,517 epoch 13 - iter 0/47 - loss 4.46259689\n",
      "2019-02-07 17:57:45,485 epoch 13 - iter 4/47 - loss 4.36999202\n",
      "2019-02-07 17:57:46,510 epoch 13 - iter 8/47 - loss 3.88047422\n",
      "2019-02-07 17:57:47,578 epoch 13 - iter 12/47 - loss 3.72798437\n",
      "2019-02-07 17:57:48,789 epoch 13 - iter 16/47 - loss 3.84706172\n",
      "2019-02-07 17:57:49,835 epoch 13 - iter 20/47 - loss 3.89596650\n",
      "2019-02-07 17:57:51,093 epoch 13 - iter 24/47 - loss 3.85023628\n",
      "2019-02-07 17:57:52,051 epoch 13 - iter 28/47 - loss 3.74442456\n",
      "2019-02-07 17:57:52,999 epoch 13 - iter 32/47 - loss 3.71606605\n",
      "2019-02-07 17:57:53,974 epoch 13 - iter 36/47 - loss 3.69594077\n",
      "2019-02-07 17:57:54,962 epoch 13 - iter 40/47 - loss 3.72206201\n",
      "2019-02-07 17:57:56,076 epoch 13 - iter 44/47 - loss 3.68998387\n",
      "2019-02-07 17:57:56,791 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:57:56,792 EPOCH 13 done: loss 3.6961 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:57:57,969 DEV  : loss 3.08058786 - f-score 0.7521 - acc 0.7520\n",
      "2019-02-07 17:57:58,954 TEST : loss 2.04136658 - f-score 0.7533 - acc 0.7533\n",
      "2019-02-07 17:58:01,872 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:58:02,132 epoch 14 - iter 0/47 - loss 4.65495157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 17:58:03,235 epoch 14 - iter 4/47 - loss 3.49291863\n",
      "2019-02-07 17:58:04,314 epoch 14 - iter 8/47 - loss 3.58345530\n",
      "2019-02-07 17:58:05,280 epoch 14 - iter 12/47 - loss 3.47737199\n",
      "2019-02-07 17:58:06,245 epoch 14 - iter 16/47 - loss 3.55881976\n",
      "2019-02-07 17:58:07,294 epoch 14 - iter 20/47 - loss 3.41653785\n",
      "2019-02-07 17:58:08,259 epoch 14 - iter 24/47 - loss 3.38720593\n",
      "2019-02-07 17:58:09,146 epoch 14 - iter 28/47 - loss 3.42549070\n",
      "2019-02-07 17:58:10,119 epoch 14 - iter 32/47 - loss 3.40775223\n",
      "2019-02-07 17:58:11,128 epoch 14 - iter 36/47 - loss 3.54370695\n",
      "2019-02-07 17:58:12,038 epoch 14 - iter 40/47 - loss 3.57702483\n",
      "2019-02-07 17:58:12,973 epoch 14 - iter 44/47 - loss 3.56835503\n",
      "2019-02-07 17:58:13,362 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:58:13,363 EPOCH 14 done: loss 3.5553 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:58:14,369 DEV  : loss 3.33609080 - f-score 0.7273 - acc 0.7273\n",
      "2019-02-07 17:58:15,305 TEST : loss 2.18762779 - f-score 0.7487 - acc 0.7487\n",
      "2019-02-07 17:58:17,809 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:58:18,117 epoch 15 - iter 0/47 - loss 4.37103748\n",
      "2019-02-07 17:58:19,029 epoch 15 - iter 4/47 - loss 3.37306349\n",
      "2019-02-07 17:58:19,943 epoch 15 - iter 8/47 - loss 3.90131957\n",
      "2019-02-07 17:58:20,928 epoch 15 - iter 12/47 - loss 3.81121057\n",
      "2019-02-07 17:58:21,822 epoch 15 - iter 16/47 - loss 3.65451167\n",
      "2019-02-07 17:58:22,747 epoch 15 - iter 20/47 - loss 3.63283156\n",
      "2019-02-07 17:58:23,621 epoch 15 - iter 24/47 - loss 3.53277619\n",
      "2019-02-07 17:58:24,528 epoch 15 - iter 28/47 - loss 3.62622153\n",
      "2019-02-07 17:58:25,460 epoch 15 - iter 32/47 - loss 3.59511510\n",
      "2019-02-07 17:58:26,480 epoch 15 - iter 36/47 - loss 3.54567673\n",
      "2019-02-07 17:58:27,550 epoch 15 - iter 40/47 - loss 3.63302174\n",
      "2019-02-07 17:58:28,530 epoch 15 - iter 44/47 - loss 3.60432808\n",
      "2019-02-07 17:58:28,890 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:58:28,891 EPOCH 15 done: loss 3.5917 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:58:29,934 DEV  : loss 3.12793136 - f-score 0.7453 - acc 0.7452\n",
      "2019-02-07 17:58:30,882 TEST : loss 2.01701641 - f-score 0.7577 - acc 0.7577\n",
      "2019-02-07 17:58:30,883 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:58:31,176 epoch 16 - iter 0/47 - loss 2.69039941\n",
      "2019-02-07 17:58:32,187 epoch 16 - iter 4/47 - loss 3.30669389\n",
      "2019-02-07 17:58:33,132 epoch 16 - iter 8/47 - loss 3.64486962\n",
      "2019-02-07 17:58:34,094 epoch 16 - iter 12/47 - loss 3.60735371\n",
      "2019-02-07 17:58:35,074 epoch 16 - iter 16/47 - loss 3.55386353\n",
      "2019-02-07 17:58:36,157 epoch 16 - iter 20/47 - loss 3.39048629\n",
      "2019-02-07 17:58:37,244 epoch 16 - iter 24/47 - loss 3.52180486\n",
      "2019-02-07 17:58:38,144 epoch 16 - iter 28/47 - loss 3.37318544\n",
      "2019-02-07 17:58:39,378 epoch 16 - iter 32/47 - loss 3.31190365\n",
      "2019-02-07 17:58:40,327 epoch 16 - iter 36/47 - loss 3.34356660\n",
      "2019-02-07 17:58:41,515 epoch 16 - iter 40/47 - loss 3.33937100\n",
      "2019-02-07 17:58:42,551 epoch 16 - iter 44/47 - loss 3.34206580\n",
      "2019-02-07 17:58:43,137 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:58:43,138 EPOCH 16 done: loss 3.3428 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 17:58:44,292 DEV  : loss 2.67705441 - f-score 0.7644 - acc 0.7644\n",
      "2019-02-07 17:58:45,419 TEST : loss 1.80716336 - f-score 0.7705 - acc 0.7705\n",
      "2019-02-07 17:58:48,383 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:58:48,610 epoch 17 - iter 0/47 - loss 2.47651005\n",
      "2019-02-07 17:58:49,947 epoch 17 - iter 4/47 - loss 3.25819640\n",
      "2019-02-07 17:58:51,195 epoch 17 - iter 8/47 - loss 3.58235473\n",
      "2019-02-07 17:58:52,343 epoch 17 - iter 12/47 - loss 3.59467415\n",
      "2019-02-07 17:58:53,391 epoch 17 - iter 16/47 - loss 3.67072556\n",
      "2019-02-07 17:58:54,258 epoch 17 - iter 20/47 - loss 3.70559535\n",
      "2019-02-07 17:58:55,249 epoch 17 - iter 24/47 - loss 3.57172682\n",
      "2019-02-07 17:58:56,228 epoch 17 - iter 28/47 - loss 3.54725968\n",
      "2019-02-07 17:58:57,070 epoch 17 - iter 32/47 - loss 3.47677800\n",
      "2019-02-07 17:58:58,076 epoch 17 - iter 36/47 - loss 3.52721695\n",
      "2019-02-07 17:58:58,921 epoch 17 - iter 40/47 - loss 3.47080820\n",
      "2019-02-07 17:58:59,920 epoch 17 - iter 44/47 - loss 3.42755267\n",
      "2019-02-07 17:59:00,304 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:59:00,305 EPOCH 17 done: loss 3.4096 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:59:01,368 DEV  : loss 2.79065704 - f-score 0.7629 - acc 0.7629\n",
      "2019-02-07 17:59:02,574 TEST : loss 1.86918795 - f-score 0.7827 - acc 0.7827\n",
      "2019-02-07 17:59:02,576 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:59:02,997 epoch 18 - iter 0/47 - loss 3.78764844\n",
      "2019-02-07 17:59:03,967 epoch 18 - iter 4/47 - loss 3.20833349\n",
      "2019-02-07 17:59:05,155 epoch 18 - iter 8/47 - loss 3.12786161\n",
      "2019-02-07 17:59:06,116 epoch 18 - iter 12/47 - loss 3.10033565\n",
      "2019-02-07 17:59:07,602 epoch 18 - iter 16/47 - loss 3.25952054\n",
      "2019-02-07 17:59:09,128 epoch 18 - iter 20/47 - loss 3.35524300\n",
      "2019-02-07 17:59:10,237 epoch 18 - iter 24/47 - loss 3.39382524\n",
      "2019-02-07 17:59:11,131 epoch 18 - iter 28/47 - loss 3.39742571\n",
      "2019-02-07 17:59:12,131 epoch 18 - iter 32/47 - loss 3.37541842\n",
      "2019-02-07 17:59:13,079 epoch 18 - iter 36/47 - loss 3.38869598\n",
      "2019-02-07 17:59:14,149 epoch 18 - iter 40/47 - loss 3.40830630\n",
      "2019-02-07 17:59:15,525 epoch 18 - iter 44/47 - loss 3.39404354\n",
      "2019-02-07 17:59:15,939 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:59:15,940 EPOCH 18 done: loss 3.3963 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 17:59:17,127 DEV  : loss 2.56043625 - f-score 0.7841 - acc 0.7841\n",
      "2019-02-07 17:59:18,180 TEST : loss 1.68570876 - f-score 0.7945 - acc 0.7945\n",
      "2019-02-07 17:59:18,182 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:59:18,503 epoch 19 - iter 0/47 - loss 2.50105715\n",
      "2019-02-07 17:59:19,719 epoch 19 - iter 4/47 - loss 2.95530653\n",
      "2019-02-07 17:59:20,748 epoch 19 - iter 8/47 - loss 2.75226690\n",
      "2019-02-07 17:59:21,863 epoch 19 - iter 12/47 - loss 3.01745531\n",
      "2019-02-07 17:59:22,773 epoch 19 - iter 16/47 - loss 3.21138538\n",
      "2019-02-07 17:59:23,739 epoch 19 - iter 20/47 - loss 3.19499712\n",
      "2019-02-07 17:59:24,686 epoch 19 - iter 24/47 - loss 3.21814267\n",
      "2019-02-07 17:59:25,670 epoch 19 - iter 28/47 - loss 3.20801910\n",
      "2019-02-07 17:59:26,749 epoch 19 - iter 32/47 - loss 3.27024403\n",
      "2019-02-07 17:59:27,966 epoch 19 - iter 36/47 - loss 3.26078474\n",
      "2019-02-07 17:59:28,943 epoch 19 - iter 40/47 - loss 3.23103819\n",
      "2019-02-07 17:59:30,005 epoch 19 - iter 44/47 - loss 3.16071974\n",
      "2019-02-07 17:59:30,480 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:59:30,481 EPOCH 19 done: loss 3.1839 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 17:59:31,542 DEV  : loss 2.47488666 - f-score 0.7846 - acc 0.7846\n",
      "2019-02-07 17:59:32,498 TEST : loss 1.71765482 - f-score 0.7850 - acc 0.7851\n",
      "2019-02-07 17:59:35,181 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:59:35,395 epoch 20 - iter 0/47 - loss 3.00299025\n",
      "2019-02-07 17:59:36,382 epoch 20 - iter 4/47 - loss 3.07528825\n",
      "2019-02-07 17:59:37,318 epoch 20 - iter 8/47 - loss 3.03419514\n",
      "2019-02-07 17:59:38,331 epoch 20 - iter 12/47 - loss 3.03829896\n",
      "2019-02-07 17:59:39,403 epoch 20 - iter 16/47 - loss 2.97553059\n",
      "2019-02-07 17:59:40,360 epoch 20 - iter 20/47 - loss 3.05689766\n",
      "2019-02-07 17:59:41,313 epoch 20 - iter 24/47 - loss 3.02357785\n",
      "2019-02-07 17:59:42,278 epoch 20 - iter 28/47 - loss 3.02168395\n",
      "2019-02-07 17:59:43,382 epoch 20 - iter 32/47 - loss 3.13044172\n",
      "2019-02-07 17:59:44,356 epoch 20 - iter 36/47 - loss 3.08808129\n",
      "2019-02-07 17:59:45,639 epoch 20 - iter 40/47 - loss 3.07768228\n",
      "2019-02-07 17:59:46,701 epoch 20 - iter 44/47 - loss 3.11616900\n",
      "2019-02-07 17:59:47,278 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 17:59:47,279 EPOCH 20 done: loss 3.0840 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 17:59:48,306 DEV  : loss 2.59452295 - f-score 0.7826 - acc 0.7827\n",
      "2019-02-07 17:59:49,240 TEST : loss 1.72778821 - f-score 0.7803 - acc 0.7803\n",
      "2019-02-07 17:59:51,922 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 17:59:52,167 epoch 21 - iter 0/47 - loss 2.43239379\n",
      "2019-02-07 17:59:53,132 epoch 21 - iter 4/47 - loss 3.15068288\n",
      "2019-02-07 17:59:54,078 epoch 21 - iter 8/47 - loss 3.10304144\n",
      "2019-02-07 17:59:55,070 epoch 21 - iter 12/47 - loss 3.15652600\n",
      "2019-02-07 17:59:56,053 epoch 21 - iter 16/47 - loss 3.22437714\n",
      "2019-02-07 17:59:57,632 epoch 21 - iter 20/47 - loss 3.11827383\n",
      "2019-02-07 17:59:58,742 epoch 21 - iter 24/47 - loss 3.17851247\n",
      "2019-02-07 17:59:59,721 epoch 21 - iter 28/47 - loss 3.08678627\n",
      "2019-02-07 18:00:00,607 epoch 21 - iter 32/47 - loss 3.04199838\n",
      "2019-02-07 18:00:01,600 epoch 21 - iter 36/47 - loss 3.07525407\n",
      "2019-02-07 18:00:02,722 epoch 21 - iter 40/47 - loss 3.06113352\n",
      "2019-02-07 18:00:03,671 epoch 21 - iter 44/47 - loss 3.08772526\n",
      "2019-02-07 18:00:04,066 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:00:04,067 EPOCH 21 done: loss 3.0840 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:00:05,107 DEV  : loss 2.42755127 - f-score 0.7866 - acc 0.7865\n",
      "2019-02-07 18:00:06,057 TEST : loss 1.63931119 - f-score 0.7952 - acc 0.7953\n",
      "2019-02-07 18:00:06,059 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:00:06,390 epoch 22 - iter 0/47 - loss 3.02880073\n",
      "2019-02-07 18:00:07,316 epoch 22 - iter 4/47 - loss 3.30713258\n",
      "2019-02-07 18:00:08,275 epoch 22 - iter 8/47 - loss 3.11991919\n",
      "2019-02-07 18:00:09,287 epoch 22 - iter 12/47 - loss 2.93211230\n",
      "2019-02-07 18:00:10,235 epoch 22 - iter 16/47 - loss 2.85823908\n",
      "2019-02-07 18:00:11,135 epoch 22 - iter 20/47 - loss 2.82145946\n",
      "2019-02-07 18:00:12,497 epoch 22 - iter 24/47 - loss 2.80593987\n",
      "2019-02-07 18:00:13,610 epoch 22 - iter 28/47 - loss 2.82225283\n",
      "2019-02-07 18:00:14,534 epoch 22 - iter 32/47 - loss 2.88576704\n",
      "2019-02-07 18:00:15,448 epoch 22 - iter 36/47 - loss 2.90690640\n",
      "2019-02-07 18:00:16,513 epoch 22 - iter 40/47 - loss 2.89360874\n",
      "2019-02-07 18:00:17,489 epoch 22 - iter 44/47 - loss 2.90175958\n",
      "2019-02-07 18:00:17,917 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:00:17,918 EPOCH 22 done: loss 2.9322 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:00:18,940 DEV  : loss 2.29115891 - f-score 0.8079 - acc 0.8079\n",
      "2019-02-07 18:00:19,986 TEST : loss 1.57252014 - f-score 0.8047 - acc 0.8047\n",
      "2019-02-07 18:00:22,962 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:00:23,180 epoch 23 - iter 0/47 - loss 2.87481117\n",
      "2019-02-07 18:00:24,206 epoch 23 - iter 4/47 - loss 2.82869220\n",
      "2019-02-07 18:00:25,088 epoch 23 - iter 8/47 - loss 2.62489364\n",
      "2019-02-07 18:00:26,097 epoch 23 - iter 12/47 - loss 2.57156561\n",
      "2019-02-07 18:00:27,451 epoch 23 - iter 16/47 - loss 2.68608569\n",
      "2019-02-07 18:00:28,938 epoch 23 - iter 20/47 - loss 2.64680495\n",
      "2019-02-07 18:00:30,359 epoch 23 - iter 24/47 - loss 2.59983730\n",
      "2019-02-07 18:00:31,543 epoch 23 - iter 28/47 - loss 2.68669253\n",
      "2019-02-07 18:00:32,759 epoch 23 - iter 32/47 - loss 2.74044006\n",
      "2019-02-07 18:00:33,888 epoch 23 - iter 36/47 - loss 2.80623287\n",
      "2019-02-07 18:00:34,823 epoch 23 - iter 40/47 - loss 2.81602155\n",
      "2019-02-07 18:00:35,752 epoch 23 - iter 44/47 - loss 2.79531196\n",
      "2019-02-07 18:00:36,204 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:00:36,205 EPOCH 23 done: loss 2.8087 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:00:37,423 DEV  : loss 2.28699160 - f-score 0.7973 - acc 0.7973\n",
      "2019-02-07 18:00:38,557 TEST : loss 1.55979168 - f-score 0.8072 - acc 0.8073\n",
      "2019-02-07 18:00:41,662 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:00:41,953 epoch 24 - iter 0/47 - loss 3.91547871\n",
      "2019-02-07 18:00:42,875 epoch 24 - iter 4/47 - loss 2.84705338\n",
      "2019-02-07 18:00:44,049 epoch 24 - iter 8/47 - loss 2.67297820\n",
      "2019-02-07 18:00:45,155 epoch 24 - iter 12/47 - loss 2.64824058\n",
      "2019-02-07 18:00:46,240 epoch 24 - iter 16/47 - loss 2.71593761\n",
      "2019-02-07 18:00:47,127 epoch 24 - iter 20/47 - loss 2.61520474\n",
      "2019-02-07 18:00:48,480 epoch 24 - iter 24/47 - loss 2.71079395\n",
      "2019-02-07 18:00:50,115 epoch 24 - iter 28/47 - loss 2.80676860\n",
      "2019-02-07 18:00:51,295 epoch 24 - iter 32/47 - loss 2.80014579\n",
      "2019-02-07 18:00:52,237 epoch 24 - iter 36/47 - loss 2.83081572\n",
      "2019-02-07 18:00:53,251 epoch 24 - iter 40/47 - loss 2.85238546\n",
      "2019-02-07 18:00:54,242 epoch 24 - iter 44/47 - loss 2.83813648\n",
      "2019-02-07 18:00:54,672 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:00:54,673 EPOCH 24 done: loss 2.8287 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:00:55,769 DEV  : loss 2.59093380 - f-score 0.7835 - acc 0.7835\n",
      "2019-02-07 18:00:56,767 TEST : loss 1.71448851 - f-score 0.7935 - acc 0.7935\n",
      "2019-02-07 18:00:56,769 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:00:57,008 epoch 25 - iter 0/47 - loss 2.75025463\n",
      "2019-02-07 18:00:58,125 epoch 25 - iter 4/47 - loss 3.12554541\n",
      "2019-02-07 18:00:59,112 epoch 25 - iter 8/47 - loss 3.07684252\n",
      "2019-02-07 18:01:00,092 epoch 25 - iter 12/47 - loss 2.88509507\n",
      "2019-02-07 18:01:01,182 epoch 25 - iter 16/47 - loss 2.93578910\n",
      "2019-02-07 18:01:02,194 epoch 25 - iter 20/47 - loss 2.97976303\n",
      "2019-02-07 18:01:03,354 epoch 25 - iter 24/47 - loss 2.96826862\n",
      "2019-02-07 18:01:04,358 epoch 25 - iter 28/47 - loss 2.99143847\n",
      "2019-02-07 18:01:05,455 epoch 25 - iter 32/47 - loss 2.99813618\n",
      "2019-02-07 18:01:06,404 epoch 25 - iter 36/47 - loss 2.93941338\n",
      "2019-02-07 18:01:07,353 epoch 25 - iter 40/47 - loss 2.86929567\n",
      "2019-02-07 18:01:08,256 epoch 25 - iter 44/47 - loss 2.82162212\n",
      "2019-02-07 18:01:08,639 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:01:08,640 EPOCH 25 done: loss 2.8198 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:01:09,980 DEV  : loss 2.35061979 - f-score 0.7925 - acc 0.7925\n",
      "2019-02-07 18:01:10,867 TEST : loss 1.59433460 - f-score 0.7965 - acc 0.7965\n",
      "2019-02-07 18:01:10,869 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:01:11,101 epoch 26 - iter 0/47 - loss 2.95963049\n",
      "2019-02-07 18:01:12,358 epoch 26 - iter 4/47 - loss 2.46483150\n",
      "2019-02-07 18:01:13,771 epoch 26 - iter 8/47 - loss 2.68179006\n",
      "2019-02-07 18:01:15,042 epoch 26 - iter 12/47 - loss 2.75642034\n",
      "2019-02-07 18:01:16,431 epoch 26 - iter 16/47 - loss 2.70192061\n",
      "2019-02-07 18:01:17,803 epoch 26 - iter 20/47 - loss 2.78551948\n",
      "2019-02-07 18:01:18,896 epoch 26 - iter 24/47 - loss 2.76254803\n",
      "2019-02-07 18:01:20,194 epoch 26 - iter 28/47 - loss 2.70876129\n",
      "2019-02-07 18:01:21,667 epoch 26 - iter 32/47 - loss 2.69309883\n",
      "2019-02-07 18:01:22,961 epoch 26 - iter 36/47 - loss 2.71720282\n",
      "2019-02-07 18:01:23,940 epoch 26 - iter 40/47 - loss 2.77951288\n",
      "2019-02-07 18:01:24,851 epoch 26 - iter 44/47 - loss 2.75200762\n",
      "2019-02-07 18:01:25,359 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:01:25,361 EPOCH 26 done: loss 2.7328 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 18:01:26,409 DEV  : loss 2.33700705 - f-score 0.8076 - acc 0.8076\n",
      "2019-02-07 18:01:27,497 TEST : loss 1.57794046 - f-score 0.8044 - acc 0.8044\n",
      "2019-02-07 18:01:31,082 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:01:31,540 epoch 27 - iter 0/47 - loss 1.81435049\n",
      "2019-02-07 18:01:32,696 epoch 27 - iter 4/47 - loss 2.16615105\n",
      "2019-02-07 18:01:33,795 epoch 27 - iter 8/47 - loss 2.44776985\n",
      "2019-02-07 18:01:34,887 epoch 27 - iter 12/47 - loss 2.64636173\n",
      "2019-02-07 18:01:35,946 epoch 27 - iter 16/47 - loss 2.64984324\n",
      "2019-02-07 18:01:37,138 epoch 27 - iter 20/47 - loss 2.63759907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:01:38,180 epoch 27 - iter 24/47 - loss 2.62933292\n",
      "2019-02-07 18:01:39,299 epoch 27 - iter 28/47 - loss 2.68984808\n",
      "2019-02-07 18:01:40,304 epoch 27 - iter 32/47 - loss 2.64062975\n",
      "2019-02-07 18:01:41,268 epoch 27 - iter 36/47 - loss 2.64555496\n",
      "2019-02-07 18:01:42,324 epoch 27 - iter 40/47 - loss 2.66124802\n",
      "2019-02-07 18:01:43,322 epoch 27 - iter 44/47 - loss 2.67392338\n",
      "2019-02-07 18:01:43,854 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:01:43,855 EPOCH 27 done: loss 2.6629 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:01:45,046 DEV  : loss 2.25730944 - f-score 0.8135 - acc 0.8135\n",
      "2019-02-07 18:01:46,049 TEST : loss 1.55337155 - f-score 0.8040 - acc 0.8040\n",
      "2019-02-07 18:01:49,133 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:01:49,341 epoch 28 - iter 0/47 - loss 2.65004826\n",
      "2019-02-07 18:01:50,522 epoch 28 - iter 4/47 - loss 2.95818005\n",
      "2019-02-07 18:01:51,780 epoch 28 - iter 8/47 - loss 3.19483455\n",
      "2019-02-07 18:01:53,123 epoch 28 - iter 12/47 - loss 3.06408213\n",
      "2019-02-07 18:01:54,529 epoch 28 - iter 16/47 - loss 2.92962881\n",
      "2019-02-07 18:01:55,879 epoch 28 - iter 20/47 - loss 2.88902571\n",
      "2019-02-07 18:01:57,177 epoch 28 - iter 24/47 - loss 2.81482399\n",
      "2019-02-07 18:01:58,197 epoch 28 - iter 28/47 - loss 2.75412742\n",
      "2019-02-07 18:01:59,248 epoch 28 - iter 32/47 - loss 2.70800121\n",
      "2019-02-07 18:02:00,171 epoch 28 - iter 36/47 - loss 2.61298621\n",
      "2019-02-07 18:02:01,164 epoch 28 - iter 40/47 - loss 2.59014262\n",
      "2019-02-07 18:02:02,336 epoch 28 - iter 44/47 - loss 2.59149653\n",
      "2019-02-07 18:02:02,801 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:02:02,802 EPOCH 28 done: loss 2.5985 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:02:03,950 DEV  : loss 2.28328514 - f-score 0.8071 - acc 0.8072\n",
      "2019-02-07 18:02:05,052 TEST : loss 1.50051379 - f-score 0.8074 - acc 0.8074\n",
      "2019-02-07 18:02:08,205 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:02:08,506 epoch 29 - iter 0/47 - loss 2.02641582\n",
      "2019-02-07 18:02:09,849 epoch 29 - iter 4/47 - loss 2.82187219\n",
      "2019-02-07 18:02:10,974 epoch 29 - iter 8/47 - loss 2.78146882\n",
      "2019-02-07 18:02:12,197 epoch 29 - iter 12/47 - loss 2.68039955\n",
      "2019-02-07 18:02:13,250 epoch 29 - iter 16/47 - loss 2.57326825\n",
      "2019-02-07 18:02:14,370 epoch 29 - iter 20/47 - loss 2.54096988\n",
      "2019-02-07 18:02:15,441 epoch 29 - iter 24/47 - loss 2.69128712\n",
      "2019-02-07 18:02:16,378 epoch 29 - iter 28/47 - loss 2.62988104\n",
      "2019-02-07 18:02:17,344 epoch 29 - iter 32/47 - loss 2.61023987\n",
      "2019-02-07 18:02:18,306 epoch 29 - iter 36/47 - loss 2.59383197\n",
      "2019-02-07 18:02:19,277 epoch 29 - iter 40/47 - loss 2.55427398\n",
      "2019-02-07 18:02:20,248 epoch 29 - iter 44/47 - loss 2.55047338\n",
      "2019-02-07 18:02:20,724 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:02:20,725 EPOCH 29 done: loss 2.5697 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:02:21,772 DEV  : loss 2.08533621 - f-score 0.8126 - acc 0.8126\n",
      "2019-02-07 18:02:22,733 TEST : loss 1.40411305 - f-score 0.8097 - acc 0.8097\n",
      "2019-02-07 18:02:25,364 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:02:25,592 epoch 30 - iter 0/47 - loss 3.37729073\n",
      "2019-02-07 18:02:26,481 epoch 30 - iter 4/47 - loss 2.24830532\n",
      "2019-02-07 18:02:27,450 epoch 30 - iter 8/47 - loss 2.29509109\n",
      "2019-02-07 18:02:28,448 epoch 30 - iter 12/47 - loss 2.38798566\n",
      "2019-02-07 18:02:29,444 epoch 30 - iter 16/47 - loss 2.55354111\n",
      "2019-02-07 18:02:30,456 epoch 30 - iter 20/47 - loss 2.59720818\n",
      "2019-02-07 18:02:31,473 epoch 30 - iter 24/47 - loss 2.62631280\n",
      "2019-02-07 18:02:32,594 epoch 30 - iter 28/47 - loss 2.69840798\n",
      "2019-02-07 18:02:33,515 epoch 30 - iter 32/47 - loss 2.63101152\n",
      "2019-02-07 18:02:34,557 epoch 30 - iter 36/47 - loss 2.65873322\n",
      "2019-02-07 18:02:35,484 epoch 30 - iter 40/47 - loss 2.60319265\n",
      "2019-02-07 18:02:36,544 epoch 30 - iter 44/47 - loss 2.59599761\n",
      "2019-02-07 18:02:37,096 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:02:37,097 EPOCH 30 done: loss 2.6155 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:02:38,147 DEV  : loss 2.12217736 - f-score 0.8220 - acc 0.8220\n",
      "2019-02-07 18:02:39,094 TEST : loss 1.45495379 - f-score 0.8134 - acc 0.8134\n",
      "2019-02-07 18:02:39,097 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:02:39,405 epoch 31 - iter 0/47 - loss 2.25239944\n",
      "2019-02-07 18:02:40,367 epoch 31 - iter 4/47 - loss 2.35224056\n",
      "2019-02-07 18:02:41,364 epoch 31 - iter 8/47 - loss 2.36792192\n",
      "2019-02-07 18:02:42,361 epoch 31 - iter 12/47 - loss 2.37727062\n",
      "2019-02-07 18:02:43,355 epoch 31 - iter 16/47 - loss 2.29690444\n",
      "2019-02-07 18:02:44,260 epoch 31 - iter 20/47 - loss 2.34731304\n",
      "2019-02-07 18:02:45,223 epoch 31 - iter 24/47 - loss 2.49137373\n",
      "2019-02-07 18:02:46,149 epoch 31 - iter 28/47 - loss 2.48622637\n",
      "2019-02-07 18:02:47,203 epoch 31 - iter 32/47 - loss 2.62059177\n",
      "2019-02-07 18:02:48,158 epoch 31 - iter 36/47 - loss 2.57565541\n",
      "2019-02-07 18:02:49,013 epoch 31 - iter 40/47 - loss 2.56726247\n",
      "2019-02-07 18:02:49,952 epoch 31 - iter 44/47 - loss 2.56535504\n",
      "2019-02-07 18:02:50,348 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:02:50,349 EPOCH 31 done: loss 2.5819 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:02:51,371 DEV  : loss 2.03741264 - f-score 0.8283 - acc 0.8284\n",
      "2019-02-07 18:02:52,322 TEST : loss 1.42085564 - f-score 0.8210 - acc 0.8210\n",
      "2019-02-07 18:02:52,324 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:02:52,570 epoch 32 - iter 0/47 - loss 2.53927708\n",
      "2019-02-07 18:02:53,585 epoch 32 - iter 4/47 - loss 2.83374820\n",
      "2019-02-07 18:02:54,579 epoch 32 - iter 8/47 - loss 2.76168678\n",
      "2019-02-07 18:02:55,524 epoch 32 - iter 12/47 - loss 2.70676827\n",
      "2019-02-07 18:02:56,477 epoch 32 - iter 16/47 - loss 2.52433850\n",
      "2019-02-07 18:02:57,417 epoch 32 - iter 20/47 - loss 2.53891571\n",
      "2019-02-07 18:02:58,530 epoch 32 - iter 24/47 - loss 2.47677557\n",
      "2019-02-07 18:02:59,590 epoch 32 - iter 28/47 - loss 2.55579890\n",
      "2019-02-07 18:03:00,482 epoch 32 - iter 32/47 - loss 2.54511771\n",
      "2019-02-07 18:03:01,429 epoch 32 - iter 36/47 - loss 2.53720779\n",
      "2019-02-07 18:03:02,317 epoch 32 - iter 40/47 - loss 2.51051853\n",
      "2019-02-07 18:03:03,229 epoch 32 - iter 44/47 - loss 2.50344571\n",
      "2019-02-07 18:03:03,639 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:03:03,640 EPOCH 32 done: loss 2.5016 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 18:03:04,659 DEV  : loss 2.03286195 - f-score 0.8320 - acc 0.8319\n",
      "2019-02-07 18:03:05,636 TEST : loss 1.40802526 - f-score 0.8210 - acc 0.8210\n",
      "2019-02-07 18:03:08,302 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:03:08,499 epoch 33 - iter 0/47 - loss 1.40502119\n",
      "2019-02-07 18:03:09,589 epoch 33 - iter 4/47 - loss 2.08174360\n",
      "2019-02-07 18:03:10,593 epoch 33 - iter 8/47 - loss 2.24972750\n",
      "2019-02-07 18:03:11,499 epoch 33 - iter 12/47 - loss 2.34826804\n",
      "2019-02-07 18:03:12,450 epoch 33 - iter 16/47 - loss 2.37679006\n",
      "2019-02-07 18:03:13,461 epoch 33 - iter 20/47 - loss 2.39187101\n",
      "2019-02-07 18:03:14,445 epoch 33 - iter 24/47 - loss 2.35886432\n",
      "2019-02-07 18:03:15,366 epoch 33 - iter 28/47 - loss 2.35203267\n",
      "2019-02-07 18:03:16,255 epoch 33 - iter 32/47 - loss 2.32530418\n",
      "2019-02-07 18:03:17,281 epoch 33 - iter 36/47 - loss 2.35398828\n",
      "2019-02-07 18:03:18,297 epoch 33 - iter 40/47 - loss 2.39136923\n",
      "2019-02-07 18:03:19,218 epoch 33 - iter 44/47 - loss 2.36434776\n",
      "2019-02-07 18:03:19,668 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:03:19,668 EPOCH 33 done: loss 2.3500 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:03:20,705 DEV  : loss 2.18915725 - f-score 0.8242 - acc 0.8242\n",
      "2019-02-07 18:03:21,681 TEST : loss 1.46330333 - f-score 0.8122 - acc 0.8122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:03:24,349 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:03:24,646 epoch 34 - iter 0/47 - loss 2.55736136\n",
      "2019-02-07 18:03:25,630 epoch 34 - iter 4/47 - loss 2.47420731\n",
      "2019-02-07 18:03:26,565 epoch 34 - iter 8/47 - loss 2.47813503\n",
      "2019-02-07 18:03:27,587 epoch 34 - iter 12/47 - loss 2.50607727\n",
      "2019-02-07 18:03:28,596 epoch 34 - iter 16/47 - loss 2.44344105\n",
      "2019-02-07 18:03:29,530 epoch 34 - iter 20/47 - loss 2.44633769\n",
      "2019-02-07 18:03:30,425 epoch 34 - iter 24/47 - loss 2.40045547\n",
      "2019-02-07 18:03:31,353 epoch 34 - iter 28/47 - loss 2.36133761\n",
      "2019-02-07 18:03:32,617 epoch 34 - iter 32/47 - loss 2.36493084\n",
      "2019-02-07 18:03:33,592 epoch 34 - iter 36/47 - loss 2.37076580\n",
      "2019-02-07 18:03:34,556 epoch 34 - iter 40/47 - loss 2.33306151\n",
      "2019-02-07 18:03:35,563 epoch 34 - iter 44/47 - loss 2.35827585\n",
      "2019-02-07 18:03:35,953 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:03:35,954 EPOCH 34 done: loss 2.3463 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:03:37,043 DEV  : loss 2.05001497 - f-score 0.8207 - acc 0.8207\n",
      "2019-02-07 18:03:38,010 TEST : loss 1.38799834 - f-score 0.8280 - acc 0.8280\n",
      "2019-02-07 18:03:40,670 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:03:40,864 epoch 35 - iter 0/47 - loss 2.07032037\n",
      "2019-02-07 18:03:41,860 epoch 35 - iter 4/47 - loss 2.15070205\n",
      "2019-02-07 18:03:42,879 epoch 35 - iter 8/47 - loss 2.32263817\n",
      "2019-02-07 18:03:43,858 epoch 35 - iter 12/47 - loss 2.20222646\n",
      "2019-02-07 18:03:44,850 epoch 35 - iter 16/47 - loss 2.28926974\n",
      "2019-02-07 18:03:45,965 epoch 35 - iter 20/47 - loss 2.42436230\n",
      "2019-02-07 18:03:46,919 epoch 35 - iter 24/47 - loss 2.43875181\n",
      "2019-02-07 18:03:47,867 epoch 35 - iter 28/47 - loss 2.34042270\n",
      "2019-02-07 18:03:48,783 epoch 35 - iter 32/47 - loss 2.30650711\n",
      "2019-02-07 18:03:49,776 epoch 35 - iter 36/47 - loss 2.36008369\n",
      "2019-02-07 18:03:50,703 epoch 35 - iter 40/47 - loss 2.39405671\n",
      "2019-02-07 18:03:51,689 epoch 35 - iter 44/47 - loss 2.39209312\n",
      "2019-02-07 18:03:52,088 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:03:52,089 EPOCH 35 done: loss 2.4048 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:03:53,125 DEV  : loss 2.25267172 - f-score 0.8152 - acc 0.8152\n",
      "2019-02-07 18:03:54,062 TEST : loss 1.50139713 - f-score 0.8134 - acc 0.8134\n",
      "2019-02-07 18:03:54,065 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:03:54,266 epoch 36 - iter 0/47 - loss 1.58865857\n",
      "2019-02-07 18:03:55,179 epoch 36 - iter 4/47 - loss 2.02482266\n",
      "2019-02-07 18:03:56,123 epoch 36 - iter 8/47 - loss 2.29992151\n",
      "2019-02-07 18:03:57,063 epoch 36 - iter 12/47 - loss 2.40183469\n",
      "2019-02-07 18:03:57,968 epoch 36 - iter 16/47 - loss 2.33786688\n",
      "2019-02-07 18:03:59,076 epoch 36 - iter 20/47 - loss 2.32857462\n",
      "2019-02-07 18:04:00,295 epoch 36 - iter 24/47 - loss 2.33606117\n",
      "2019-02-07 18:04:01,247 epoch 36 - iter 28/47 - loss 2.32725377\n",
      "2019-02-07 18:04:02,202 epoch 36 - iter 32/47 - loss 2.28280160\n",
      "2019-02-07 18:04:03,287 epoch 36 - iter 36/47 - loss 2.33856785\n",
      "2019-02-07 18:04:04,229 epoch 36 - iter 40/47 - loss 2.29899091\n",
      "2019-02-07 18:04:05,353 epoch 36 - iter 44/47 - loss 2.32592226\n",
      "2019-02-07 18:04:05,766 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:04:05,766 EPOCH 36 done: loss 2.3164 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:04:06,813 DEV  : loss 1.93073225 - f-score 0.8322 - acc 0.8322\n",
      "2019-02-07 18:04:07,811 TEST : loss 1.34121048 - f-score 0.8324 - acc 0.8324\n",
      "2019-02-07 18:04:10,419 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:04:10,631 epoch 37 - iter 0/47 - loss 1.96684730\n",
      "2019-02-07 18:04:11,742 epoch 37 - iter 4/47 - loss 2.02861934\n",
      "2019-02-07 18:04:12,669 epoch 37 - iter 8/47 - loss 2.44521470\n",
      "2019-02-07 18:04:13,669 epoch 37 - iter 12/47 - loss 2.67752287\n",
      "2019-02-07 18:04:14,671 epoch 37 - iter 16/47 - loss 2.69883727\n",
      "2019-02-07 18:04:15,640 epoch 37 - iter 20/47 - loss 2.62421846\n",
      "2019-02-07 18:04:16,604 epoch 37 - iter 24/47 - loss 2.64329807\n",
      "2019-02-07 18:04:17,692 epoch 37 - iter 28/47 - loss 2.61042803\n",
      "2019-02-07 18:04:18,603 epoch 37 - iter 32/47 - loss 2.54275105\n",
      "2019-02-07 18:04:19,520 epoch 37 - iter 36/47 - loss 2.49830358\n",
      "2019-02-07 18:04:20,561 epoch 37 - iter 40/47 - loss 2.52608966\n",
      "2019-02-07 18:04:21,542 epoch 37 - iter 44/47 - loss 2.49990817\n",
      "2019-02-07 18:04:21,968 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:04:21,969 EPOCH 37 done: loss 2.5050 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:04:23,015 DEV  : loss 1.95549238 - f-score 0.8359 - acc 0.8359\n",
      "2019-02-07 18:04:23,937 TEST : loss 1.34738147 - f-score 0.8364 - acc 0.8364\n",
      "2019-02-07 18:04:23,939 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:04:24,150 epoch 38 - iter 0/47 - loss 2.31529093\n",
      "2019-02-07 18:04:25,156 epoch 38 - iter 4/47 - loss 2.24460154\n",
      "2019-02-07 18:04:26,133 epoch 38 - iter 8/47 - loss 2.82206824\n",
      "2019-02-07 18:04:27,244 epoch 38 - iter 12/47 - loss 2.68835928\n",
      "2019-02-07 18:04:28,220 epoch 38 - iter 16/47 - loss 2.68394078\n",
      "2019-02-07 18:04:29,308 epoch 38 - iter 20/47 - loss 2.71075274\n",
      "2019-02-07 18:04:30,210 epoch 38 - iter 24/47 - loss 2.65397303\n",
      "2019-02-07 18:04:31,164 epoch 38 - iter 28/47 - loss 2.62235101\n",
      "2019-02-07 18:04:32,114 epoch 38 - iter 32/47 - loss 2.54570133\n",
      "2019-02-07 18:04:33,020 epoch 38 - iter 36/47 - loss 2.48492353\n",
      "2019-02-07 18:04:33,973 epoch 38 - iter 40/47 - loss 2.51215346\n",
      "2019-02-07 18:04:34,901 epoch 38 - iter 44/47 - loss 2.42327886\n",
      "2019-02-07 18:04:35,343 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:04:35,344 EPOCH 38 done: loss 2.4319 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:04:36,366 DEV  : loss 1.91769946 - f-score 0.8371 - acc 0.8371\n",
      "2019-02-07 18:04:37,319 TEST : loss 1.33818519 - f-score 0.8288 - acc 0.8288\n",
      "2019-02-07 18:04:37,321 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:04:37,548 epoch 39 - iter 0/47 - loss 2.32230473\n",
      "2019-02-07 18:04:38,583 epoch 39 - iter 4/47 - loss 3.01782475\n",
      "2019-02-07 18:04:39,394 epoch 39 - iter 8/47 - loss 2.45784952\n",
      "2019-02-07 18:04:40,286 epoch 39 - iter 12/47 - loss 2.43828333\n",
      "2019-02-07 18:04:41,203 epoch 39 - iter 16/47 - loss 2.40614275\n",
      "2019-02-07 18:04:42,248 epoch 39 - iter 20/47 - loss 2.41880799\n",
      "2019-02-07 18:04:43,146 epoch 39 - iter 24/47 - loss 2.36554945\n",
      "2019-02-07 18:04:44,080 epoch 39 - iter 28/47 - loss 2.32105921\n",
      "2019-02-07 18:04:45,093 epoch 39 - iter 32/47 - loss 2.33838349\n",
      "2019-02-07 18:04:46,071 epoch 39 - iter 36/47 - loss 2.30216632\n",
      "2019-02-07 18:04:47,041 epoch 39 - iter 40/47 - loss 2.32463615\n",
      "2019-02-07 18:04:48,038 epoch 39 - iter 44/47 - loss 2.29994159\n",
      "2019-02-07 18:04:48,536 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:04:48,537 EPOCH 39 done: loss 2.2888 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 18:04:49,585 DEV  : loss 1.97684109 - f-score 0.8328 - acc 0.8328\n",
      "2019-02-07 18:04:50,543 TEST : loss 1.31336415 - f-score 0.8363 - acc 0.8362\n",
      "2019-02-07 18:04:53,188 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:04:53,470 epoch 40 - iter 0/47 - loss 3.91584206\n",
      "2019-02-07 18:04:54,389 epoch 40 - iter 4/47 - loss 2.13418300\n",
      "2019-02-07 18:04:55,411 epoch 40 - iter 8/47 - loss 2.15061698\n",
      "2019-02-07 18:04:56,371 epoch 40 - iter 12/47 - loss 2.13770080\n",
      "2019-02-07 18:04:57,405 epoch 40 - iter 16/47 - loss 2.06715683\n",
      "2019-02-07 18:04:58,503 epoch 40 - iter 20/47 - loss 2.09989497\n",
      "2019-02-07 18:04:59,547 epoch 40 - iter 24/47 - loss 2.15240946\n",
      "2019-02-07 18:05:00,517 epoch 40 - iter 28/47 - loss 2.21264969\n",
      "2019-02-07 18:05:01,406 epoch 40 - iter 32/47 - loss 2.17582309\n",
      "2019-02-07 18:05:02,340 epoch 40 - iter 36/47 - loss 2.19391146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:05:03,296 epoch 40 - iter 40/47 - loss 2.28954689\n",
      "2019-02-07 18:05:04,223 epoch 40 - iter 44/47 - loss 2.27035600\n",
      "2019-02-07 18:05:04,642 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:05:04,643 EPOCH 40 done: loss 2.2804 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:05:05,706 DEV  : loss 1.89049888 - f-score 0.8383 - acc 0.8383\n",
      "2019-02-07 18:05:06,659 TEST : loss 1.32122827 - f-score 0.8357 - acc 0.8357\n",
      "2019-02-07 18:05:09,338 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:05:09,525 epoch 41 - iter 0/47 - loss 1.72098136\n",
      "2019-02-07 18:05:10,573 epoch 41 - iter 4/47 - loss 2.17887483\n",
      "2019-02-07 18:05:11,491 epoch 41 - iter 8/47 - loss 2.08712898\n",
      "2019-02-07 18:05:12,415 epoch 41 - iter 12/47 - loss 2.18261000\n",
      "2019-02-07 18:05:13,407 epoch 41 - iter 16/47 - loss 2.25240965\n",
      "2019-02-07 18:05:14,319 epoch 41 - iter 20/47 - loss 2.28197548\n",
      "2019-02-07 18:05:15,253 epoch 41 - iter 24/47 - loss 2.24809298\n",
      "2019-02-07 18:05:16,282 epoch 41 - iter 28/47 - loss 2.26224799\n",
      "2019-02-07 18:05:17,218 epoch 41 - iter 32/47 - loss 2.24899660\n",
      "2019-02-07 18:05:18,268 epoch 41 - iter 36/47 - loss 2.33879914\n",
      "2019-02-07 18:05:19,269 epoch 41 - iter 40/47 - loss 2.37971955\n",
      "2019-02-07 18:05:20,203 epoch 41 - iter 44/47 - loss 2.37348445\n",
      "2019-02-07 18:05:20,766 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:05:20,767 EPOCH 41 done: loss 2.3801 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:05:21,819 DEV  : loss 1.91481566 - f-score 0.8391 - acc 0.8390\n",
      "2019-02-07 18:05:22,781 TEST : loss 1.37440813 - f-score 0.8341 - acc 0.8341\n",
      "2019-02-07 18:05:22,783 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:05:23,012 epoch 42 - iter 0/47 - loss 2.57000780\n",
      "2019-02-07 18:05:23,974 epoch 42 - iter 4/47 - loss 1.78584039\n",
      "2019-02-07 18:05:24,899 epoch 42 - iter 8/47 - loss 2.06166286\n",
      "2019-02-07 18:05:26,007 epoch 42 - iter 12/47 - loss 2.17563020\n",
      "2019-02-07 18:05:26,965 epoch 42 - iter 16/47 - loss 2.17649367\n",
      "2019-02-07 18:05:27,941 epoch 42 - iter 20/47 - loss 2.20722792\n",
      "2019-02-07 18:05:28,905 epoch 42 - iter 24/47 - loss 2.27591835\n",
      "2019-02-07 18:05:29,875 epoch 42 - iter 28/47 - loss 2.29286326\n",
      "2019-02-07 18:05:30,870 epoch 42 - iter 32/47 - loss 2.24858080\n",
      "2019-02-07 18:05:31,808 epoch 42 - iter 36/47 - loss 2.24845919\n",
      "2019-02-07 18:05:32,813 epoch 42 - iter 40/47 - loss 2.22155484\n",
      "2019-02-07 18:05:33,730 epoch 42 - iter 44/47 - loss 2.21442450\n",
      "2019-02-07 18:05:34,190 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:05:34,191 EPOCH 42 done: loss 2.2259 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:05:35,234 DEV  : loss 1.92722285 - f-score 0.8359 - acc 0.8359\n",
      "2019-02-07 18:05:36,194 TEST : loss 1.27731335 - f-score 0.8366 - acc 0.8365\n",
      "2019-02-07 18:05:38,814 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:05:39,041 epoch 43 - iter 0/47 - loss 2.15338612\n",
      "2019-02-07 18:05:39,997 epoch 43 - iter 4/47 - loss 2.20658891\n",
      "2019-02-07 18:05:41,035 epoch 43 - iter 8/47 - loss 2.17223010\n",
      "2019-02-07 18:05:42,070 epoch 43 - iter 12/47 - loss 2.24087560\n",
      "2019-02-07 18:05:43,051 epoch 43 - iter 16/47 - loss 2.13251717\n",
      "2019-02-07 18:05:44,160 epoch 43 - iter 20/47 - loss 2.25985290\n",
      "2019-02-07 18:05:45,043 epoch 43 - iter 24/47 - loss 2.16007601\n",
      "2019-02-07 18:05:45,973 epoch 43 - iter 28/47 - loss 2.10943746\n",
      "2019-02-07 18:05:46,994 epoch 43 - iter 32/47 - loss 2.14963993\n",
      "2019-02-07 18:05:47,958 epoch 43 - iter 36/47 - loss 2.13504860\n",
      "2019-02-07 18:05:48,902 epoch 43 - iter 40/47 - loss 2.18087545\n",
      "2019-02-07 18:05:49,920 epoch 43 - iter 44/47 - loss 2.20233868\n",
      "2019-02-07 18:05:50,287 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:05:50,288 EPOCH 43 done: loss 2.1900 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:05:51,314 DEV  : loss 1.89996350 - f-score 0.8448 - acc 0.8448\n",
      "2019-02-07 18:05:52,268 TEST : loss 1.30948138 - f-score 0.8409 - acc 0.8409\n",
      "2019-02-07 18:05:55,385 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:05:55,866 epoch 44 - iter 0/47 - loss 1.18445778\n",
      "2019-02-07 18:05:57,206 epoch 44 - iter 4/47 - loss 2.34405890\n",
      "2019-02-07 18:05:58,340 epoch 44 - iter 8/47 - loss 2.21305009\n",
      "2019-02-07 18:05:59,446 epoch 44 - iter 12/47 - loss 2.14682662\n",
      "2019-02-07 18:06:00,590 epoch 44 - iter 16/47 - loss 2.11216920\n",
      "2019-02-07 18:06:01,664 epoch 44 - iter 20/47 - loss 2.06427514\n",
      "2019-02-07 18:06:02,878 epoch 44 - iter 24/47 - loss 2.12807583\n",
      "2019-02-07 18:06:04,038 epoch 44 - iter 28/47 - loss 2.11675930\n",
      "2019-02-07 18:06:05,071 epoch 44 - iter 32/47 - loss 2.13785277\n",
      "2019-02-07 18:06:06,285 epoch 44 - iter 36/47 - loss 2.16875892\n",
      "2019-02-07 18:06:07,286 epoch 44 - iter 40/47 - loss 2.13421486\n",
      "2019-02-07 18:06:08,242 epoch 44 - iter 44/47 - loss 2.15780981\n",
      "2019-02-07 18:06:08,751 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:06:08,753 EPOCH 44 done: loss 2.1456 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:06:09,858 DEV  : loss 2.10899091 - f-score 0.8319 - acc 0.8319\n",
      "2019-02-07 18:06:10,836 TEST : loss 1.38968515 - f-score 0.8376 - acc 0.8376\n",
      "2019-02-07 18:06:13,631 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:06:13,887 epoch 45 - iter 0/47 - loss 2.21719909\n",
      "2019-02-07 18:06:14,853 epoch 45 - iter 4/47 - loss 2.16344533\n",
      "2019-02-07 18:06:15,857 epoch 45 - iter 8/47 - loss 2.14548430\n",
      "2019-02-07 18:06:16,840 epoch 45 - iter 12/47 - loss 2.25400232\n",
      "2019-02-07 18:06:17,775 epoch 45 - iter 16/47 - loss 2.10459413\n",
      "2019-02-07 18:06:18,719 epoch 45 - iter 20/47 - loss 2.18184111\n",
      "2019-02-07 18:06:19,778 epoch 45 - iter 24/47 - loss 2.18393943\n",
      "2019-02-07 18:06:20,748 epoch 45 - iter 28/47 - loss 2.15387917\n",
      "2019-02-07 18:06:21,702 epoch 45 - iter 32/47 - loss 2.17679919\n",
      "2019-02-07 18:06:22,598 epoch 45 - iter 36/47 - loss 2.21594473\n",
      "2019-02-07 18:06:23,534 epoch 45 - iter 40/47 - loss 2.21853636\n",
      "2019-02-07 18:06:24,471 epoch 45 - iter 44/47 - loss 2.20997956\n",
      "2019-02-07 18:06:24,942 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:06:24,943 EPOCH 45 done: loss 2.1880 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:06:25,962 DEV  : loss 2.01947522 - f-score 0.8329 - acc 0.8329\n",
      "2019-02-07 18:06:26,853 TEST : loss 1.35365510 - f-score 0.8375 - acc 0.8375\n",
      "2019-02-07 18:06:26,855 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:06:27,116 epoch 46 - iter 0/47 - loss 1.76795638\n",
      "2019-02-07 18:06:28,077 epoch 46 - iter 4/47 - loss 2.05633614\n",
      "2019-02-07 18:06:29,118 epoch 46 - iter 8/47 - loss 2.23252063\n",
      "2019-02-07 18:06:29,997 epoch 46 - iter 12/47 - loss 2.33110969\n",
      "2019-02-07 18:06:31,014 epoch 46 - iter 16/47 - loss 2.35714652\n",
      "2019-02-07 18:06:32,048 epoch 46 - iter 20/47 - loss 2.33502303\n",
      "2019-02-07 18:06:32,939 epoch 46 - iter 24/47 - loss 2.28181655\n",
      "2019-02-07 18:06:33,826 epoch 46 - iter 28/47 - loss 2.15340612\n",
      "2019-02-07 18:06:34,782 epoch 46 - iter 32/47 - loss 2.19531866\n",
      "2019-02-07 18:06:35,765 epoch 46 - iter 36/47 - loss 2.24513919\n",
      "2019-02-07 18:06:36,755 epoch 46 - iter 40/47 - loss 2.21594471\n",
      "2019-02-07 18:06:37,707 epoch 46 - iter 44/47 - loss 2.15849242\n",
      "2019-02-07 18:06:38,080 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:06:38,081 EPOCH 46 done: loss 2.1396 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:06:39,402 DEV  : loss 1.80857754 - f-score 0.8454 - acc 0.8454\n",
      "2019-02-07 18:06:40,342 TEST : loss 1.25994301 - f-score 0.8391 - acc 0.8391\n",
      "2019-02-07 18:06:42,988 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:06:43,220 epoch 47 - iter 0/47 - loss 1.79435015\n",
      "2019-02-07 18:06:44,159 epoch 47 - iter 4/47 - loss 2.12404828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:06:45,135 epoch 47 - iter 8/47 - loss 1.89774424\n",
      "2019-02-07 18:06:46,123 epoch 47 - iter 12/47 - loss 1.81239878\n",
      "2019-02-07 18:06:47,294 epoch 47 - iter 16/47 - loss 2.03695179\n",
      "2019-02-07 18:06:48,510 epoch 47 - iter 20/47 - loss 2.06058835\n",
      "2019-02-07 18:06:49,929 epoch 47 - iter 24/47 - loss 2.09583815\n",
      "2019-02-07 18:06:51,432 epoch 47 - iter 28/47 - loss 2.09344468\n",
      "2019-02-07 18:06:52,740 epoch 47 - iter 32/47 - loss 2.09738144\n",
      "2019-02-07 18:06:54,606 epoch 47 - iter 36/47 - loss 2.12040402\n",
      "2019-02-07 18:06:55,542 epoch 47 - iter 40/47 - loss 2.10345585\n",
      "2019-02-07 18:06:56,556 epoch 47 - iter 44/47 - loss 2.07970367\n",
      "2019-02-07 18:06:56,987 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:06:56,988 EPOCH 47 done: loss 2.1148 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:06:57,969 DEV  : loss 1.78963256 - f-score 0.8516 - acc 0.8516\n",
      "2019-02-07 18:06:58,845 TEST : loss 1.24037540 - f-score 0.8457 - acc 0.8456\n",
      "2019-02-07 18:07:01,588 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:07:01,789 epoch 48 - iter 0/47 - loss 1.26337540\n",
      "2019-02-07 18:07:02,600 epoch 48 - iter 4/47 - loss 1.82054465\n",
      "2019-02-07 18:07:03,652 epoch 48 - iter 8/47 - loss 1.95946895\n",
      "2019-02-07 18:07:04,575 epoch 48 - iter 12/47 - loss 2.07278465\n",
      "2019-02-07 18:07:05,365 epoch 48 - iter 16/47 - loss 2.06794834\n",
      "2019-02-07 18:07:06,411 epoch 48 - iter 20/47 - loss 2.13404650\n",
      "2019-02-07 18:07:07,287 epoch 48 - iter 24/47 - loss 2.14592782\n",
      "2019-02-07 18:07:08,131 epoch 48 - iter 28/47 - loss 2.12750457\n",
      "2019-02-07 18:07:08,955 epoch 48 - iter 32/47 - loss 2.13260691\n",
      "2019-02-07 18:07:09,941 epoch 48 - iter 36/47 - loss 2.15673961\n",
      "2019-02-07 18:07:10,798 epoch 48 - iter 40/47 - loss 2.18323416\n",
      "2019-02-07 18:07:11,546 epoch 48 - iter 44/47 - loss 2.21773513\n",
      "2019-02-07 18:07:11,920 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:07:11,921 EPOCH 48 done: loss 2.2010 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:07:12,888 DEV  : loss 1.77352118 - f-score 0.8492 - acc 0.8492\n",
      "2019-02-07 18:07:13,751 TEST : loss 1.22329438 - f-score 0.8469 - acc 0.8469\n",
      "2019-02-07 18:07:13,753 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:07:13,980 epoch 49 - iter 0/47 - loss 3.47331595\n",
      "2019-02-07 18:07:14,847 epoch 49 - iter 4/47 - loss 2.59248831\n",
      "2019-02-07 18:07:15,756 epoch 49 - iter 8/47 - loss 2.31238712\n",
      "2019-02-07 18:07:16,620 epoch 49 - iter 12/47 - loss 2.29799184\n",
      "2019-02-07 18:07:17,464 epoch 49 - iter 16/47 - loss 2.18063289\n",
      "2019-02-07 18:07:18,275 epoch 49 - iter 20/47 - loss 2.26538239\n",
      "2019-02-07 18:07:19,239 epoch 49 - iter 24/47 - loss 2.29981787\n",
      "2019-02-07 18:07:20,057 epoch 49 - iter 28/47 - loss 2.23039605\n",
      "2019-02-07 18:07:20,875 epoch 49 - iter 32/47 - loss 2.15763174\n",
      "2019-02-07 18:07:21,798 epoch 49 - iter 36/47 - loss 2.13144862\n",
      "2019-02-07 18:07:22,641 epoch 49 - iter 40/47 - loss 2.12280520\n",
      "2019-02-07 18:07:23,517 epoch 49 - iter 44/47 - loss 2.12220282\n",
      "2019-02-07 18:07:23,875 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:07:23,876 EPOCH 49 done: loss 2.1062 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:07:24,826 DEV  : loss 1.88095331 - f-score 0.8444 - acc 0.8443\n",
      "2019-02-07 18:07:25,709 TEST : loss 1.25978792 - f-score 0.8425 - acc 0.8425\n",
      "2019-02-07 18:07:28,479 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:07:28,708 epoch 50 - iter 0/47 - loss 1.31491375\n",
      "2019-02-07 18:07:29,635 epoch 50 - iter 4/47 - loss 1.89351478\n",
      "2019-02-07 18:07:30,533 epoch 50 - iter 8/47 - loss 1.73661404\n",
      "2019-02-07 18:07:31,456 epoch 50 - iter 12/47 - loss 1.88274432\n",
      "2019-02-07 18:07:32,675 epoch 50 - iter 16/47 - loss 1.94975000\n",
      "2019-02-07 18:07:33,626 epoch 50 - iter 20/47 - loss 1.95786272\n",
      "2019-02-07 18:07:34,456 epoch 50 - iter 24/47 - loss 1.97273662\n",
      "2019-02-07 18:07:35,350 epoch 50 - iter 28/47 - loss 1.89415946\n",
      "2019-02-07 18:07:36,178 epoch 50 - iter 32/47 - loss 1.93010892\n",
      "2019-02-07 18:07:37,034 epoch 50 - iter 36/47 - loss 1.93410903\n",
      "2019-02-07 18:07:37,999 epoch 50 - iter 40/47 - loss 1.89904502\n",
      "2019-02-07 18:07:38,906 epoch 50 - iter 44/47 - loss 1.95903873\n",
      "2019-02-07 18:07:39,260 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:07:39,261 EPOCH 50 done: loss 1.9766 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:07:40,201 DEV  : loss 1.93210566 - f-score 0.8461 - acc 0.8460\n",
      "2019-02-07 18:07:41,082 TEST : loss 1.34138882 - f-score 0.8453 - acc 0.8453\n",
      "2019-02-07 18:07:43,739 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:07:43,988 epoch 51 - iter 0/47 - loss 2.09483433\n",
      "2019-02-07 18:07:44,940 epoch 51 - iter 4/47 - loss 2.03119886\n",
      "2019-02-07 18:07:45,945 epoch 51 - iter 8/47 - loss 2.03949383\n",
      "2019-02-07 18:07:46,959 epoch 51 - iter 12/47 - loss 1.97075902\n",
      "2019-02-07 18:07:47,828 epoch 51 - iter 16/47 - loss 1.97811020\n",
      "2019-02-07 18:07:48,820 epoch 51 - iter 20/47 - loss 1.94584292\n",
      "2019-02-07 18:07:49,626 epoch 51 - iter 24/47 - loss 1.88568419\n",
      "2019-02-07 18:07:50,577 epoch 51 - iter 28/47 - loss 1.91094610\n",
      "2019-02-07 18:07:51,505 epoch 51 - iter 32/47 - loss 1.91965212\n",
      "2019-02-07 18:07:52,385 epoch 51 - iter 36/47 - loss 1.90301033\n",
      "2019-02-07 18:07:53,278 epoch 51 - iter 40/47 - loss 1.93855562\n",
      "2019-02-07 18:07:54,122 epoch 51 - iter 44/47 - loss 1.92767858\n",
      "2019-02-07 18:07:54,663 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:07:54,665 EPOCH 51 done: loss 1.9498 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:07:55,737 DEV  : loss 1.81697249 - f-score 0.8545 - acc 0.8545\n",
      "2019-02-07 18:07:56,910 TEST : loss 1.29546225 - f-score 0.8403 - acc 0.8403\n",
      "2019-02-07 18:07:59,984 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:08:00,228 epoch 52 - iter 0/47 - loss 1.63417733\n",
      "2019-02-07 18:08:01,163 epoch 52 - iter 4/47 - loss 1.31259911\n",
      "2019-02-07 18:08:01,979 epoch 52 - iter 8/47 - loss 1.50027039\n",
      "2019-02-07 18:08:03,060 epoch 52 - iter 12/47 - loss 1.60421984\n",
      "2019-02-07 18:08:03,902 epoch 52 - iter 16/47 - loss 1.64808779\n",
      "2019-02-07 18:08:04,754 epoch 52 - iter 20/47 - loss 1.72390352\n",
      "2019-02-07 18:08:05,719 epoch 52 - iter 24/47 - loss 1.81743455\n",
      "2019-02-07 18:08:06,707 epoch 52 - iter 28/47 - loss 1.78681941\n",
      "2019-02-07 18:08:07,640 epoch 52 - iter 32/47 - loss 1.83534041\n",
      "2019-02-07 18:08:08,537 epoch 52 - iter 36/47 - loss 1.91987340\n",
      "2019-02-07 18:08:09,379 epoch 52 - iter 40/47 - loss 1.91907298\n",
      "2019-02-07 18:08:10,338 epoch 52 - iter 44/47 - loss 1.95983922\n",
      "2019-02-07 18:08:10,728 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:08:10,729 EPOCH 52 done: loss 1.9590 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:08:11,711 DEV  : loss 1.77508497 - f-score 0.8552 - acc 0.8552\n",
      "2019-02-07 18:08:12,602 TEST : loss 1.29041481 - f-score 0.8451 - acc 0.8450\n",
      "2019-02-07 18:08:12,605 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:08:12,880 epoch 53 - iter 0/47 - loss 2.00148225\n",
      "2019-02-07 18:08:13,640 epoch 53 - iter 4/47 - loss 1.55175741\n",
      "2019-02-07 18:08:14,605 epoch 53 - iter 8/47 - loss 1.76844524\n",
      "2019-02-07 18:08:15,450 epoch 53 - iter 12/47 - loss 1.68049848\n",
      "2019-02-07 18:08:16,489 epoch 53 - iter 16/47 - loss 1.91727430\n",
      "2019-02-07 18:08:17,327 epoch 53 - iter 20/47 - loss 1.91134007\n",
      "2019-02-07 18:08:18,304 epoch 53 - iter 24/47 - loss 1.98803983\n",
      "2019-02-07 18:08:19,129 epoch 53 - iter 28/47 - loss 1.98771510\n",
      "2019-02-07 18:08:19,953 epoch 53 - iter 32/47 - loss 2.00467557\n",
      "2019-02-07 18:08:20,797 epoch 53 - iter 36/47 - loss 1.95583184\n",
      "2019-02-07 18:08:21,608 epoch 53 - iter 40/47 - loss 1.92684629\n",
      "2019-02-07 18:08:22,504 epoch 53 - iter 44/47 - loss 1.96888475\n",
      "2019-02-07 18:08:22,924 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:08:22,925 EPOCH 53 done: loss 1.9728 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:08:23,894 DEV  : loss 1.81306016 - f-score 0.8521 - acc 0.8521\n",
      "2019-02-07 18:08:24,789 TEST : loss 1.28313160 - f-score 0.8344 - acc 0.8344\n",
      "2019-02-07 18:08:24,791 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:08:25,007 epoch 54 - iter 0/47 - loss 2.17334557\n",
      "2019-02-07 18:08:26,087 epoch 54 - iter 4/47 - loss 2.43015037\n",
      "2019-02-07 18:08:26,888 epoch 54 - iter 8/47 - loss 2.11371313\n",
      "2019-02-07 18:08:27,644 epoch 54 - iter 12/47 - loss 2.11985243\n",
      "2019-02-07 18:08:28,551 epoch 54 - iter 16/47 - loss 1.99950953\n",
      "2019-02-07 18:08:29,466 epoch 54 - iter 20/47 - loss 1.98781780\n",
      "2019-02-07 18:08:30,309 epoch 54 - iter 24/47 - loss 1.98865152\n",
      "2019-02-07 18:08:31,117 epoch 54 - iter 28/47 - loss 1.96059499\n",
      "2019-02-07 18:08:31,916 epoch 54 - iter 32/47 - loss 1.89729027\n",
      "2019-02-07 18:08:32,809 epoch 54 - iter 36/47 - loss 1.86656934\n",
      "2019-02-07 18:08:33,737 epoch 54 - iter 40/47 - loss 1.85902326\n",
      "2019-02-07 18:08:34,682 epoch 54 - iter 44/47 - loss 1.88230151\n",
      "2019-02-07 18:08:35,106 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:08:35,107 EPOCH 54 done: loss 1.9209 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 18:08:36,129 DEV  : loss 1.66079319 - f-score 0.8574 - acc 0.8574\n",
      "2019-02-07 18:08:37,024 TEST : loss 1.23900700 - f-score 0.8437 - acc 0.8437\n",
      "2019-02-07 18:08:39,701 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:08:39,959 epoch 55 - iter 0/47 - loss 2.25246024\n",
      "2019-02-07 18:08:40,907 epoch 55 - iter 4/47 - loss 2.01313930\n",
      "2019-02-07 18:08:41,786 epoch 55 - iter 8/47 - loss 1.86772079\n",
      "2019-02-07 18:08:42,510 epoch 55 - iter 12/47 - loss 1.89821698\n",
      "2019-02-07 18:08:43,421 epoch 55 - iter 16/47 - loss 1.92745756\n",
      "2019-02-07 18:08:44,219 epoch 55 - iter 20/47 - loss 1.81934056\n",
      "2019-02-07 18:08:44,977 epoch 55 - iter 24/47 - loss 1.83521875\n",
      "2019-02-07 18:08:45,950 epoch 55 - iter 28/47 - loss 1.85539582\n",
      "2019-02-07 18:08:46,873 epoch 55 - iter 32/47 - loss 1.84216856\n",
      "2019-02-07 18:08:47,923 epoch 55 - iter 36/47 - loss 1.85197705\n",
      "2019-02-07 18:08:48,777 epoch 55 - iter 40/47 - loss 1.84645477\n",
      "2019-02-07 18:08:49,648 epoch 55 - iter 44/47 - loss 1.89789303\n",
      "2019-02-07 18:08:50,065 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:08:50,066 EPOCH 55 done: loss 1.8852 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:08:51,072 DEV  : loss 1.86767542 - f-score 0.8441 - acc 0.8441\n",
      "2019-02-07 18:08:52,011 TEST : loss 1.30541730 - f-score 0.8415 - acc 0.8415\n",
      "2019-02-07 18:08:54,688 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:08:54,950 epoch 56 - iter 0/47 - loss 2.73655701\n",
      "2019-02-07 18:08:55,819 epoch 56 - iter 4/47 - loss 2.24374058\n",
      "2019-02-07 18:08:56,880 epoch 56 - iter 8/47 - loss 2.24232719\n",
      "2019-02-07 18:08:57,711 epoch 56 - iter 12/47 - loss 2.09277260\n",
      "2019-02-07 18:08:58,591 epoch 56 - iter 16/47 - loss 2.06990221\n",
      "2019-02-07 18:08:59,398 epoch 56 - iter 20/47 - loss 1.93405802\n",
      "2019-02-07 18:09:00,159 epoch 56 - iter 24/47 - loss 1.88642787\n",
      "2019-02-07 18:09:00,946 epoch 56 - iter 28/47 - loss 1.85256599\n",
      "2019-02-07 18:09:01,713 epoch 56 - iter 32/47 - loss 1.86612271\n",
      "2019-02-07 18:09:02,656 epoch 56 - iter 36/47 - loss 1.84235504\n",
      "2019-02-07 18:09:03,492 epoch 56 - iter 40/47 - loss 1.84685540\n",
      "2019-02-07 18:09:04,470 epoch 56 - iter 44/47 - loss 1.87249399\n",
      "2019-02-07 18:09:04,998 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:09:04,999 EPOCH 56 done: loss 1.8670 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:09:05,975 DEV  : loss 1.77110159 - f-score 0.8543 - acc 0.8542\n",
      "2019-02-07 18:09:06,852 TEST : loss 1.26297629 - f-score 0.8547 - acc 0.8547\n",
      "2019-02-07 18:09:09,465 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:09:09,698 epoch 57 - iter 0/47 - loss 1.75569761\n",
      "2019-02-07 18:09:10,565 epoch 57 - iter 4/47 - loss 2.01115682\n",
      "2019-02-07 18:09:11,406 epoch 57 - iter 8/47 - loss 1.78060873\n",
      "2019-02-07 18:09:12,356 epoch 57 - iter 12/47 - loss 1.89009937\n",
      "2019-02-07 18:09:13,236 epoch 57 - iter 16/47 - loss 1.97456168\n",
      "2019-02-07 18:09:14,096 epoch 57 - iter 20/47 - loss 1.99662811\n",
      "2019-02-07 18:09:15,165 epoch 57 - iter 24/47 - loss 2.04924644\n",
      "2019-02-07 18:09:15,983 epoch 57 - iter 28/47 - loss 2.06104016\n",
      "2019-02-07 18:09:16,848 epoch 57 - iter 32/47 - loss 1.97169186\n",
      "2019-02-07 18:09:17,738 epoch 57 - iter 36/47 - loss 1.96483108\n",
      "2019-02-07 18:09:18,758 epoch 57 - iter 40/47 - loss 1.99171201\n",
      "2019-02-07 18:09:19,596 epoch 57 - iter 44/47 - loss 1.96332195\n",
      "2019-02-07 18:09:19,978 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:09:19,979 EPOCH 57 done: loss 1.9629 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:09:20,995 DEV  : loss 1.69848847 - f-score 0.8557 - acc 0.8557\n",
      "2019-02-07 18:09:21,880 TEST : loss 1.25265968 - f-score 0.8263 - acc 0.8263\n",
      "2019-02-07 18:09:21,882 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:09:22,109 epoch 58 - iter 0/47 - loss 1.40690649\n",
      "2019-02-07 18:09:22,924 epoch 58 - iter 4/47 - loss 1.76136444\n",
      "2019-02-07 18:09:23,821 epoch 58 - iter 8/47 - loss 1.82378913\n",
      "2019-02-07 18:09:24,512 epoch 58 - iter 12/47 - loss 1.77376010\n",
      "2019-02-07 18:09:25,462 epoch 58 - iter 16/47 - loss 1.84972506\n",
      "2019-02-07 18:09:26,268 epoch 58 - iter 20/47 - loss 1.84999368\n",
      "2019-02-07 18:09:27,106 epoch 58 - iter 24/47 - loss 1.80856355\n",
      "2019-02-07 18:09:28,074 epoch 58 - iter 28/47 - loss 1.84300850\n",
      "2019-02-07 18:09:28,891 epoch 58 - iter 32/47 - loss 1.90454839\n",
      "2019-02-07 18:09:29,820 epoch 58 - iter 36/47 - loss 1.91246721\n",
      "2019-02-07 18:09:30,681 epoch 58 - iter 40/47 - loss 1.90559060\n",
      "2019-02-07 18:09:31,574 epoch 58 - iter 44/47 - loss 1.88150186\n",
      "2019-02-07 18:09:32,110 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:09:32,111 EPOCH 58 done: loss 1.8780 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:09:33,099 DEV  : loss 1.75137389 - f-score 0.8524 - acc 0.8523\n",
      "2019-02-07 18:09:33,977 TEST : loss 1.27589929 - f-score 0.8457 - acc 0.8456\n",
      "2019-02-07 18:09:33,979 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:09:34,218 epoch 59 - iter 0/47 - loss 2.38865662\n",
      "2019-02-07 18:09:35,069 epoch 59 - iter 4/47 - loss 1.73032024\n",
      "2019-02-07 18:09:35,917 epoch 59 - iter 8/47 - loss 1.72778391\n",
      "2019-02-07 18:09:36,790 epoch 59 - iter 12/47 - loss 1.83318891\n",
      "2019-02-07 18:09:37,587 epoch 59 - iter 16/47 - loss 1.91869872\n",
      "2019-02-07 18:09:38,444 epoch 59 - iter 20/47 - loss 1.91724425\n",
      "2019-02-07 18:09:39,294 epoch 59 - iter 24/47 - loss 1.92315169\n",
      "2019-02-07 18:09:40,283 epoch 59 - iter 28/47 - loss 1.95567567\n",
      "2019-02-07 18:09:41,185 epoch 59 - iter 32/47 - loss 1.94060743\n",
      "2019-02-07 18:09:41,945 epoch 59 - iter 36/47 - loss 1.87746638\n",
      "2019-02-07 18:09:42,829 epoch 59 - iter 40/47 - loss 1.86454953\n",
      "2019-02-07 18:09:43,792 epoch 59 - iter 44/47 - loss 1.87495737\n",
      "2019-02-07 18:09:44,252 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:09:44,253 EPOCH 59 done: loss 1.8620 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 18:09:45,194 DEV  : loss 1.68611920 - f-score 0.8591 - acc 0.8590\n",
      "2019-02-07 18:09:46,157 TEST : loss 1.26240027 - f-score 0.8370 - acc 0.8370\n",
      "2019-02-07 18:09:48,874 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:09:49,104 epoch 60 - iter 0/47 - loss 2.32658172\n",
      "2019-02-07 18:09:50,051 epoch 60 - iter 4/47 - loss 1.84038832\n",
      "2019-02-07 18:09:50,842 epoch 60 - iter 8/47 - loss 1.77841674\n",
      "2019-02-07 18:09:51,606 epoch 60 - iter 12/47 - loss 1.77700547\n",
      "2019-02-07 18:09:52,411 epoch 60 - iter 16/47 - loss 1.76389820\n",
      "2019-02-07 18:09:53,294 epoch 60 - iter 20/47 - loss 1.81520325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:09:54,258 epoch 60 - iter 24/47 - loss 1.80065503\n",
      "2019-02-07 18:09:55,207 epoch 60 - iter 28/47 - loss 1.83533724\n",
      "2019-02-07 18:09:56,049 epoch 60 - iter 32/47 - loss 1.84519063\n",
      "2019-02-07 18:09:56,849 epoch 60 - iter 36/47 - loss 1.83782636\n",
      "2019-02-07 18:09:57,732 epoch 60 - iter 40/47 - loss 1.87476318\n",
      "2019-02-07 18:09:58,693 epoch 60 - iter 44/47 - loss 1.90092859\n",
      "2019-02-07 18:09:59,214 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:09:59,215 EPOCH 60 done: loss 1.8907 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:10:00,191 DEV  : loss 1.86631501 - f-score 0.8562 - acc 0.8562\n",
      "2019-02-07 18:10:01,058 TEST : loss 1.32779205 - f-score 0.8413 - acc 0.8413\n",
      "2019-02-07 18:10:01,060 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:10:01,279 epoch 61 - iter 0/47 - loss 1.21922123\n",
      "2019-02-07 18:10:02,155 epoch 61 - iter 4/47 - loss 1.41375422\n",
      "2019-02-07 18:10:02,992 epoch 61 - iter 8/47 - loss 1.57435040\n",
      "2019-02-07 18:10:03,931 epoch 61 - iter 12/47 - loss 1.81196053\n",
      "2019-02-07 18:10:04,707 epoch 61 - iter 16/47 - loss 1.76536131\n",
      "2019-02-07 18:10:05,485 epoch 61 - iter 20/47 - loss 1.73860713\n",
      "2019-02-07 18:10:06,283 epoch 61 - iter 24/47 - loss 1.69864628\n",
      "2019-02-07 18:10:07,253 epoch 61 - iter 28/47 - loss 1.76569355\n",
      "2019-02-07 18:10:08,229 epoch 61 - iter 32/47 - loss 1.78309643\n",
      "2019-02-07 18:10:08,947 epoch 61 - iter 36/47 - loss 1.75628487\n",
      "2019-02-07 18:10:09,754 epoch 61 - iter 40/47 - loss 1.76667682\n",
      "2019-02-07 18:10:10,647 epoch 61 - iter 44/47 - loss 1.75497271\n",
      "2019-02-07 18:10:11,054 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:10:11,055 EPOCH 61 done: loss 1.7542 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:10:12,001 DEV  : loss 1.60082269 - f-score 0.8673 - acc 0.8673\n",
      "2019-02-07 18:10:12,868 TEST : loss 1.17149043 - f-score 0.8465 - acc 0.8465\n",
      "2019-02-07 18:10:15,492 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:10:15,732 epoch 62 - iter 0/47 - loss 1.36457074\n",
      "2019-02-07 18:10:16,580 epoch 62 - iter 4/47 - loss 1.78106754\n",
      "2019-02-07 18:10:17,347 epoch 62 - iter 8/47 - loss 1.69230574\n",
      "2019-02-07 18:10:18,189 epoch 62 - iter 12/47 - loss 1.80385867\n",
      "2019-02-07 18:10:19,098 epoch 62 - iter 16/47 - loss 1.81834183\n",
      "2019-02-07 18:10:19,942 epoch 62 - iter 20/47 - loss 1.86999750\n",
      "2019-02-07 18:10:21,072 epoch 62 - iter 24/47 - loss 1.92330279\n",
      "2019-02-07 18:10:21,977 epoch 62 - iter 28/47 - loss 1.91342143\n",
      "2019-02-07 18:10:22,780 epoch 62 - iter 32/47 - loss 1.91545213\n",
      "2019-02-07 18:10:23,699 epoch 62 - iter 36/47 - loss 1.85012105\n",
      "2019-02-07 18:10:24,486 epoch 62 - iter 40/47 - loss 1.87491519\n",
      "2019-02-07 18:10:25,319 epoch 62 - iter 44/47 - loss 1.85390203\n",
      "2019-02-07 18:10:25,796 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:10:25,797 EPOCH 62 done: loss 1.8385 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:10:26,748 DEV  : loss 1.69460189 - f-score 0.8598 - acc 0.8598\n",
      "2019-02-07 18:10:27,618 TEST : loss 1.24584985 - f-score 0.8490 - acc 0.8489\n",
      "2019-02-07 18:10:27,620 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:10:27,795 epoch 63 - iter 0/47 - loss 0.95929670\n",
      "2019-02-07 18:10:28,560 epoch 63 - iter 4/47 - loss 1.54968665\n",
      "2019-02-07 18:10:29,482 epoch 63 - iter 8/47 - loss 1.60049734\n",
      "2019-02-07 18:10:30,327 epoch 63 - iter 12/47 - loss 1.61667842\n",
      "2019-02-07 18:10:31,189 epoch 63 - iter 16/47 - loss 1.69759475\n",
      "2019-02-07 18:10:32,019 epoch 63 - iter 20/47 - loss 1.70222616\n",
      "2019-02-07 18:10:32,853 epoch 63 - iter 24/47 - loss 1.71251148\n",
      "2019-02-07 18:10:33,675 epoch 63 - iter 28/47 - loss 1.70375096\n",
      "2019-02-07 18:10:34,720 epoch 63 - iter 32/47 - loss 1.71120456\n",
      "2019-02-07 18:10:35,599 epoch 63 - iter 36/47 - loss 1.79090517\n",
      "2019-02-07 18:10:36,362 epoch 63 - iter 40/47 - loss 1.79200410\n",
      "2019-02-07 18:10:37,250 epoch 63 - iter 44/47 - loss 1.78342905\n",
      "2019-02-07 18:10:37,746 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:10:37,747 EPOCH 63 done: loss 1.8155 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:10:38,708 DEV  : loss 1.62297392 - f-score 0.8618 - acc 0.8618\n",
      "2019-02-07 18:10:39,583 TEST : loss 1.24116063 - f-score 0.8380 - acc 0.8380\n",
      "2019-02-07 18:10:39,585 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:10:39,811 epoch 64 - iter 0/47 - loss 1.61226785\n",
      "2019-02-07 18:10:40,596 epoch 64 - iter 4/47 - loss 1.72289860\n",
      "2019-02-07 18:10:41,379 epoch 64 - iter 8/47 - loss 1.76190713\n",
      "2019-02-07 18:10:42,419 epoch 64 - iter 12/47 - loss 1.78185478\n",
      "2019-02-07 18:10:43,351 epoch 64 - iter 16/47 - loss 1.69613231\n",
      "2019-02-07 18:10:44,178 epoch 64 - iter 20/47 - loss 1.64945429\n",
      "2019-02-07 18:10:45,046 epoch 64 - iter 24/47 - loss 1.71732561\n",
      "2019-02-07 18:10:45,904 epoch 64 - iter 28/47 - loss 1.70276327\n",
      "2019-02-07 18:10:46,713 epoch 64 - iter 32/47 - loss 1.73655563\n",
      "2019-02-07 18:10:47,700 epoch 64 - iter 36/47 - loss 1.71999276\n",
      "2019-02-07 18:10:48,546 epoch 64 - iter 40/47 - loss 1.71504544\n",
      "2019-02-07 18:10:49,421 epoch 64 - iter 44/47 - loss 1.71518135\n",
      "2019-02-07 18:10:49,865 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:10:49,866 EPOCH 64 done: loss 1.7333 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 18:10:50,824 DEV  : loss 1.84975624 - f-score 0.8579 - acc 0.8579\n",
      "2019-02-07 18:10:51,670 TEST : loss 1.30874217 - f-score 0.8489 - acc 0.8489\n",
      "2019-02-07 18:10:54,207 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:10:54,444 epoch 65 - iter 0/47 - loss 2.85223866\n",
      "2019-02-07 18:10:55,448 epoch 65 - iter 4/47 - loss 2.22644744\n",
      "2019-02-07 18:10:56,351 epoch 65 - iter 8/47 - loss 1.93511330\n",
      "2019-02-07 18:10:57,144 epoch 65 - iter 12/47 - loss 1.95303032\n",
      "2019-02-07 18:10:58,070 epoch 65 - iter 16/47 - loss 2.03750684\n",
      "2019-02-07 18:10:58,911 epoch 65 - iter 20/47 - loss 1.99666156\n",
      "2019-02-07 18:10:59,697 epoch 65 - iter 24/47 - loss 2.01136350\n",
      "2019-02-07 18:11:00,502 epoch 65 - iter 28/47 - loss 1.98579078\n",
      "2019-02-07 18:11:01,301 epoch 65 - iter 32/47 - loss 1.93579136\n",
      "2019-02-07 18:11:02,354 epoch 65 - iter 36/47 - loss 1.93834648\n",
      "2019-02-07 18:11:03,383 epoch 65 - iter 40/47 - loss 1.92115485\n",
      "2019-02-07 18:11:04,297 epoch 65 - iter 44/47 - loss 1.87123306\n",
      "2019-02-07 18:11:04,724 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:04,725 EPOCH 65 done: loss 1.8556 - lr 0.1000 - bad epochs 0\n",
      "2019-02-07 18:11:05,667 DEV  : loss 1.76094258 - f-score 0.8619 - acc 0.8620\n",
      "2019-02-07 18:11:06,548 TEST : loss 1.26476789 - f-score 0.8351 - acc 0.8351\n",
      "2019-02-07 18:11:06,549 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:06,788 epoch 66 - iter 0/47 - loss 1.20458651\n",
      "2019-02-07 18:11:07,619 epoch 66 - iter 4/47 - loss 1.38591421\n",
      "2019-02-07 18:11:08,454 epoch 66 - iter 8/47 - loss 1.62413422\n",
      "2019-02-07 18:11:09,334 epoch 66 - iter 12/47 - loss 1.71293284\n",
      "2019-02-07 18:11:10,099 epoch 66 - iter 16/47 - loss 1.76391215\n",
      "2019-02-07 18:11:10,981 epoch 66 - iter 20/47 - loss 1.70231821\n",
      "2019-02-07 18:11:11,865 epoch 66 - iter 24/47 - loss 1.74614939\n",
      "2019-02-07 18:11:12,697 epoch 66 - iter 28/47 - loss 1.72754386\n",
      "2019-02-07 18:11:13,614 epoch 66 - iter 32/47 - loss 1.71025768\n",
      "2019-02-07 18:11:14,755 epoch 66 - iter 36/47 - loss 1.74623297\n",
      "2019-02-07 18:11:15,593 epoch 66 - iter 40/47 - loss 1.79940546\n",
      "2019-02-07 18:11:16,320 epoch 66 - iter 44/47 - loss 1.79363637\n",
      "2019-02-07 18:11:16,772 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:16,773 EPOCH 66 done: loss 1.8029 - lr 0.1000 - bad epochs 1\n",
      "2019-02-07 18:11:17,726 DEV  : loss 1.87757909 - f-score 0.8504 - acc 0.8504\n",
      "2019-02-07 18:11:18,602 TEST : loss 1.30632448 - f-score 0.8423 - acc 0.8423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:11:18,604 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:18,802 epoch 67 - iter 0/47 - loss 2.40571332\n",
      "2019-02-07 18:11:19,676 epoch 67 - iter 4/47 - loss 1.72162542\n",
      "2019-02-07 18:11:20,447 epoch 67 - iter 8/47 - loss 2.02625941\n",
      "2019-02-07 18:11:21,381 epoch 67 - iter 12/47 - loss 2.01259913\n",
      "2019-02-07 18:11:22,281 epoch 67 - iter 16/47 - loss 1.87600682\n",
      "2019-02-07 18:11:23,202 epoch 67 - iter 20/47 - loss 1.81539220\n",
      "2019-02-07 18:11:24,116 epoch 67 - iter 24/47 - loss 1.78866117\n",
      "2019-02-07 18:11:25,049 epoch 67 - iter 28/47 - loss 1.78010840\n",
      "2019-02-07 18:11:25,952 epoch 67 - iter 32/47 - loss 1.78462064\n",
      "2019-02-07 18:11:26,791 epoch 67 - iter 36/47 - loss 1.80839417\n",
      "2019-02-07 18:11:27,662 epoch 67 - iter 40/47 - loss 1.76769101\n",
      "2019-02-07 18:11:28,486 epoch 67 - iter 44/47 - loss 1.73439728\n",
      "2019-02-07 18:11:28,859 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:28,860 EPOCH 67 done: loss 1.7340 - lr 0.1000 - bad epochs 2\n",
      "2019-02-07 18:11:30,105 DEV  : loss 1.76459694 - f-score 0.8576 - acc 0.8576\n",
      "2019-02-07 18:11:30,967 TEST : loss 1.22173452 - f-score 0.8443 - acc 0.8443\n",
      "2019-02-07 18:11:30,969 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:31,200 epoch 68 - iter 0/47 - loss 1.30064893\n",
      "2019-02-07 18:11:32,156 epoch 68 - iter 4/47 - loss 1.80556953\n",
      "2019-02-07 18:11:32,959 epoch 68 - iter 8/47 - loss 1.76124251\n",
      "2019-02-07 18:11:33,754 epoch 68 - iter 12/47 - loss 1.67061352\n",
      "2019-02-07 18:11:34,654 epoch 68 - iter 16/47 - loss 1.59008802\n",
      "2019-02-07 18:11:35,500 epoch 68 - iter 20/47 - loss 1.57190327\n",
      "2019-02-07 18:11:36,342 epoch 68 - iter 24/47 - loss 1.63147235\n",
      "2019-02-07 18:11:37,311 epoch 68 - iter 28/47 - loss 1.70189969\n",
      "2019-02-07 18:11:38,100 epoch 68 - iter 32/47 - loss 1.73134517\n",
      "2019-02-07 18:11:38,986 epoch 68 - iter 36/47 - loss 1.76701788\n",
      "2019-02-07 18:11:39,927 epoch 68 - iter 40/47 - loss 1.78043821\n",
      "2019-02-07 18:11:40,806 epoch 68 - iter 44/47 - loss 1.80280443\n",
      "2019-02-07 18:11:41,149 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:41,150 EPOCH 68 done: loss 1.7885 - lr 0.1000 - bad epochs 3\n",
      "2019-02-07 18:11:42,100 DEV  : loss 1.69249403 - f-score 0.8550 - acc 0.8550\n",
      "2019-02-07 18:11:42,967 TEST : loss 1.24016726 - f-score 0.8351 - acc 0.8351\n",
      "Epoch    67: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-02-07 18:11:42,969 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:43,189 epoch 69 - iter 0/47 - loss 2.73398066\n",
      "2019-02-07 18:11:43,988 epoch 69 - iter 4/47 - loss 1.78830175\n",
      "2019-02-07 18:11:44,807 epoch 69 - iter 8/47 - loss 1.54167880\n",
      "2019-02-07 18:11:45,708 epoch 69 - iter 12/47 - loss 1.75154616\n",
      "2019-02-07 18:11:46,528 epoch 69 - iter 16/47 - loss 1.79261919\n",
      "2019-02-07 18:11:47,473 epoch 69 - iter 20/47 - loss 1.78005955\n",
      "2019-02-07 18:11:48,398 epoch 69 - iter 24/47 - loss 1.76389718\n",
      "2019-02-07 18:11:49,353 epoch 69 - iter 28/47 - loss 1.72795196\n",
      "2019-02-07 18:11:50,137 epoch 69 - iter 32/47 - loss 1.66450546\n",
      "2019-02-07 18:11:51,001 epoch 69 - iter 36/47 - loss 1.66201542\n",
      "2019-02-07 18:11:51,897 epoch 69 - iter 40/47 - loss 1.65434887\n",
      "2019-02-07 18:11:52,683 epoch 69 - iter 44/47 - loss 1.65940768\n",
      "2019-02-07 18:11:53,181 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:53,182 EPOCH 69 done: loss 1.6680 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 18:11:54,122 DEV  : loss 1.70163751 - f-score 0.8717 - acc 0.8718\n",
      "2019-02-07 18:11:54,988 TEST : loss 1.21170461 - f-score 0.8459 - acc 0.8459\n",
      "2019-02-07 18:11:57,581 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:11:57,786 epoch 70 - iter 0/47 - loss 1.84862721\n",
      "2019-02-07 18:11:58,722 epoch 70 - iter 4/47 - loss 1.81729567\n",
      "2019-02-07 18:11:59,639 epoch 70 - iter 8/47 - loss 1.85368554\n",
      "2019-02-07 18:12:00,428 epoch 70 - iter 12/47 - loss 1.66286334\n",
      "2019-02-07 18:12:01,293 epoch 70 - iter 16/47 - loss 1.70979535\n",
      "2019-02-07 18:12:02,167 epoch 70 - iter 20/47 - loss 1.71133107\n",
      "2019-02-07 18:12:03,085 epoch 70 - iter 24/47 - loss 1.62715617\n",
      "2019-02-07 18:12:03,942 epoch 70 - iter 28/47 - loss 1.67200368\n",
      "2019-02-07 18:12:04,714 epoch 70 - iter 32/47 - loss 1.68662805\n",
      "2019-02-07 18:12:05,587 epoch 70 - iter 36/47 - loss 1.67139503\n",
      "2019-02-07 18:12:06,485 epoch 70 - iter 40/47 - loss 1.65796558\n",
      "2019-02-07 18:12:07,377 epoch 70 - iter 44/47 - loss 1.65142652\n",
      "2019-02-07 18:12:07,910 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:12:07,912 EPOCH 70 done: loss 1.6481 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 18:12:08,887 DEV  : loss 1.69794810 - f-score 0.8657 - acc 0.8657\n",
      "2019-02-07 18:12:09,768 TEST : loss 1.21303201 - f-score 0.8457 - acc 0.8457\n",
      "2019-02-07 18:12:12,382 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:12:12,607 epoch 71 - iter 0/47 - loss 1.06865656\n",
      "2019-02-07 18:12:13,654 epoch 71 - iter 4/47 - loss 1.51813215\n",
      "2019-02-07 18:12:14,658 epoch 71 - iter 8/47 - loss 1.60852392\n",
      "2019-02-07 18:12:15,625 epoch 71 - iter 12/47 - loss 1.58031630\n",
      "2019-02-07 18:12:16,484 epoch 71 - iter 16/47 - loss 1.61799328\n",
      "2019-02-07 18:12:17,317 epoch 71 - iter 20/47 - loss 1.54387009\n",
      "2019-02-07 18:12:18,281 epoch 71 - iter 24/47 - loss 1.59151278\n",
      "2019-02-07 18:12:19,096 epoch 71 - iter 28/47 - loss 1.53789313\n",
      "2019-02-07 18:12:19,869 epoch 71 - iter 32/47 - loss 1.48515281\n",
      "2019-02-07 18:12:20,757 epoch 71 - iter 36/47 - loss 1.49706047\n",
      "2019-02-07 18:12:21,604 epoch 71 - iter 40/47 - loss 1.47954094\n",
      "2019-02-07 18:12:22,374 epoch 71 - iter 44/47 - loss 1.50070630\n",
      "2019-02-07 18:12:22,757 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:12:22,758 EPOCH 71 done: loss 1.5283 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 18:12:23,728 DEV  : loss 1.65046203 - f-score 0.8685 - acc 0.8686\n",
      "2019-02-07 18:12:24,581 TEST : loss 1.21469223 - f-score 0.8549 - acc 0.8550\n",
      "2019-02-07 18:12:27,202 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:12:27,461 epoch 72 - iter 0/47 - loss 1.24567091\n",
      "2019-02-07 18:12:28,520 epoch 72 - iter 4/47 - loss 1.44041367\n",
      "2019-02-07 18:12:29,452 epoch 72 - iter 8/47 - loss 1.41930203\n",
      "2019-02-07 18:12:30,304 epoch 72 - iter 12/47 - loss 1.60680427\n",
      "2019-02-07 18:12:31,220 epoch 72 - iter 16/47 - loss 1.61401232\n",
      "2019-02-07 18:12:31,989 epoch 72 - iter 20/47 - loss 1.55443207\n",
      "2019-02-07 18:12:32,909 epoch 72 - iter 24/47 - loss 1.64068236\n",
      "2019-02-07 18:12:33,689 epoch 72 - iter 28/47 - loss 1.58329528\n",
      "2019-02-07 18:12:34,480 epoch 72 - iter 32/47 - loss 1.61126291\n",
      "2019-02-07 18:12:35,379 epoch 72 - iter 36/47 - loss 1.60311626\n",
      "2019-02-07 18:12:36,236 epoch 72 - iter 40/47 - loss 1.64823056\n",
      "2019-02-07 18:12:37,000 epoch 72 - iter 44/47 - loss 1.62658565\n",
      "2019-02-07 18:12:37,421 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:12:37,422 EPOCH 72 done: loss 1.6264 - lr 0.0500 - bad epochs 0\n",
      "2019-02-07 18:12:38,364 DEV  : loss 1.71041012 - f-score 0.8699 - acc 0.8699\n",
      "2019-02-07 18:12:39,206 TEST : loss 1.23532462 - f-score 0.8448 - acc 0.8448\n",
      "2019-02-07 18:12:39,208 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:12:39,500 epoch 73 - iter 0/47 - loss 1.04688644\n",
      "2019-02-07 18:12:40,339 epoch 73 - iter 4/47 - loss 1.67681510\n",
      "2019-02-07 18:12:41,325 epoch 73 - iter 8/47 - loss 1.62361691\n",
      "2019-02-07 18:12:42,347 epoch 73 - iter 12/47 - loss 1.59032655\n",
      "2019-02-07 18:12:43,178 epoch 73 - iter 16/47 - loss 1.53407393\n",
      "2019-02-07 18:12:44,026 epoch 73 - iter 20/47 - loss 1.60036426\n",
      "2019-02-07 18:12:44,861 epoch 73 - iter 24/47 - loss 1.60839252\n",
      "2019-02-07 18:12:45,702 epoch 73 - iter 28/47 - loss 1.62839796\n",
      "2019-02-07 18:12:46,532 epoch 73 - iter 32/47 - loss 1.59564340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:12:47,366 epoch 73 - iter 36/47 - loss 1.54507156\n",
      "2019-02-07 18:12:48,274 epoch 73 - iter 40/47 - loss 1.55780607\n",
      "2019-02-07 18:12:49,153 epoch 73 - iter 44/47 - loss 1.54830525\n",
      "2019-02-07 18:12:49,552 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:12:49,553 EPOCH 73 done: loss 1.5398 - lr 0.0500 - bad epochs 1\n",
      "2019-02-07 18:12:50,483 DEV  : loss 1.67860699 - f-score 0.8693 - acc 0.8693\n",
      "2019-02-07 18:12:51,353 TEST : loss 1.22177970 - f-score 0.8492 - acc 0.8492\n",
      "2019-02-07 18:12:51,354 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:12:51,592 epoch 74 - iter 0/47 - loss 1.12835395\n",
      "2019-02-07 18:12:52,445 epoch 74 - iter 4/47 - loss 1.62999880\n",
      "2019-02-07 18:12:53,303 epoch 74 - iter 8/47 - loss 1.57257858\n",
      "2019-02-07 18:12:54,201 epoch 74 - iter 12/47 - loss 1.73841658\n",
      "2019-02-07 18:12:55,257 epoch 74 - iter 16/47 - loss 1.70650476\n",
      "2019-02-07 18:12:56,128 epoch 74 - iter 20/47 - loss 1.63956609\n",
      "2019-02-07 18:12:56,940 epoch 74 - iter 24/47 - loss 1.54952832\n",
      "2019-02-07 18:12:57,741 epoch 74 - iter 28/47 - loss 1.58278483\n",
      "2019-02-07 18:12:58,558 epoch 74 - iter 32/47 - loss 1.58609326\n",
      "2019-02-07 18:12:59,470 epoch 74 - iter 36/47 - loss 1.58344932\n",
      "2019-02-07 18:13:00,275 epoch 74 - iter 40/47 - loss 1.59755224\n",
      "2019-02-07 18:13:01,040 epoch 74 - iter 44/47 - loss 1.58607363\n",
      "2019-02-07 18:13:01,519 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:01,520 EPOCH 74 done: loss 1.5857 - lr 0.0500 - bad epochs 2\n",
      "2019-02-07 18:13:02,449 DEV  : loss 1.69023943 - f-score 0.8677 - acc 0.8677\n",
      "2019-02-07 18:13:03,300 TEST : loss 1.22605324 - f-score 0.8503 - acc 0.8503\n",
      "2019-02-07 18:13:03,302 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:03,535 epoch 75 - iter 0/47 - loss 1.70247293\n",
      "2019-02-07 18:13:04,492 epoch 75 - iter 4/47 - loss 1.75138884\n",
      "2019-02-07 18:13:05,323 epoch 75 - iter 8/47 - loss 1.68830856\n",
      "2019-02-07 18:13:06,157 epoch 75 - iter 12/47 - loss 1.66705852\n",
      "2019-02-07 18:13:07,013 epoch 75 - iter 16/47 - loss 1.63778235\n",
      "2019-02-07 18:13:07,955 epoch 75 - iter 20/47 - loss 1.67662690\n",
      "2019-02-07 18:13:08,804 epoch 75 - iter 24/47 - loss 1.72994236\n",
      "2019-02-07 18:13:09,595 epoch 75 - iter 28/47 - loss 1.65855103\n",
      "2019-02-07 18:13:10,457 epoch 75 - iter 32/47 - loss 1.67698902\n",
      "2019-02-07 18:13:11,261 epoch 75 - iter 36/47 - loss 1.64559317\n",
      "2019-02-07 18:13:12,134 epoch 75 - iter 40/47 - loss 1.64225953\n",
      "2019-02-07 18:13:13,125 epoch 75 - iter 44/47 - loss 1.67683287\n",
      "2019-02-07 18:13:13,498 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:13,499 EPOCH 75 done: loss 1.6726 - lr 0.0500 - bad epochs 3\n",
      "2019-02-07 18:13:14,542 DEV  : loss 1.66577554 - f-score 0.8619 - acc 0.8619\n",
      "2019-02-07 18:13:15,512 TEST : loss 1.20040989 - f-score 0.8536 - acc 0.8536\n",
      "Epoch    74: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2019-02-07 18:13:15,513 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:15,736 epoch 76 - iter 0/47 - loss 1.71115530\n",
      "2019-02-07 18:13:16,646 epoch 76 - iter 4/47 - loss 1.59853660\n",
      "2019-02-07 18:13:17,432 epoch 76 - iter 8/47 - loss 1.57939263\n",
      "2019-02-07 18:13:18,442 epoch 76 - iter 12/47 - loss 1.53938579\n",
      "2019-02-07 18:13:19,365 epoch 76 - iter 16/47 - loss 1.57027929\n",
      "2019-02-07 18:13:20,187 epoch 76 - iter 20/47 - loss 1.48984474\n",
      "2019-02-07 18:13:21,036 epoch 76 - iter 24/47 - loss 1.47767214\n",
      "2019-02-07 18:13:21,815 epoch 76 - iter 28/47 - loss 1.49288645\n",
      "2019-02-07 18:13:22,753 epoch 76 - iter 32/47 - loss 1.54154841\n",
      "2019-02-07 18:13:23,601 epoch 76 - iter 36/47 - loss 1.55578918\n",
      "2019-02-07 18:13:24,454 epoch 76 - iter 40/47 - loss 1.57251699\n",
      "2019-02-07 18:13:25,263 epoch 76 - iter 44/47 - loss 1.56308400\n",
      "2019-02-07 18:13:25,679 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:25,680 EPOCH 76 done: loss 1.5468 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:13:26,633 DEV  : loss 1.65778041 - f-score 0.8672 - acc 0.8672\n",
      "2019-02-07 18:13:27,495 TEST : loss 1.19891477 - f-score 0.8621 - acc 0.8621\n",
      "2019-02-07 18:13:27,497 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:27,702 epoch 77 - iter 0/47 - loss 0.98153305\n",
      "2019-02-07 18:13:28,562 epoch 77 - iter 4/47 - loss 1.56265278\n",
      "2019-02-07 18:13:29,432 epoch 77 - iter 8/47 - loss 1.50385629\n",
      "2019-02-07 18:13:30,310 epoch 77 - iter 12/47 - loss 1.56275579\n",
      "2019-02-07 18:13:31,162 epoch 77 - iter 16/47 - loss 1.56691233\n",
      "2019-02-07 18:13:32,073 epoch 77 - iter 20/47 - loss 1.54340321\n",
      "2019-02-07 18:13:32,845 epoch 77 - iter 24/47 - loss 1.50638326\n",
      "2019-02-07 18:13:33,796 epoch 77 - iter 28/47 - loss 1.50556657\n",
      "2019-02-07 18:13:34,615 epoch 77 - iter 32/47 - loss 1.48010075\n",
      "2019-02-07 18:13:35,425 epoch 77 - iter 36/47 - loss 1.47176982\n",
      "2019-02-07 18:13:36,312 epoch 77 - iter 40/47 - loss 1.52299958\n",
      "2019-02-07 18:13:37,188 epoch 77 - iter 44/47 - loss 1.53657054\n",
      "2019-02-07 18:13:37,694 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:37,695 EPOCH 77 done: loss 1.5367 - lr 0.0250 - bad epochs 1\n",
      "2019-02-07 18:13:38,647 DEV  : loss 1.66239464 - f-score 0.8702 - acc 0.8702\n",
      "2019-02-07 18:13:39,505 TEST : loss 1.19521570 - f-score 0.8558 - acc 0.8558\n",
      "2019-02-07 18:13:39,509 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:39,796 epoch 78 - iter 0/47 - loss 1.46445882\n",
      "2019-02-07 18:13:40,696 epoch 78 - iter 4/47 - loss 1.41053798\n",
      "2019-02-07 18:13:41,537 epoch 78 - iter 8/47 - loss 1.57136724\n",
      "2019-02-07 18:13:42,442 epoch 78 - iter 12/47 - loss 1.53643017\n",
      "2019-02-07 18:13:43,352 epoch 78 - iter 16/47 - loss 1.63635701\n",
      "2019-02-07 18:13:44,135 epoch 78 - iter 20/47 - loss 1.62648072\n",
      "2019-02-07 18:13:44,997 epoch 78 - iter 24/47 - loss 1.65471084\n",
      "2019-02-07 18:13:45,847 epoch 78 - iter 28/47 - loss 1.67263467\n",
      "2019-02-07 18:13:46,668 epoch 78 - iter 32/47 - loss 1.65952537\n",
      "2019-02-07 18:13:47,430 epoch 78 - iter 36/47 - loss 1.61698717\n",
      "2019-02-07 18:13:48,445 epoch 78 - iter 40/47 - loss 1.60458972\n",
      "2019-02-07 18:13:49,226 epoch 78 - iter 44/47 - loss 1.57554129\n",
      "2019-02-07 18:13:49,590 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:49,591 EPOCH 78 done: loss 1.5729 - lr 0.0250 - bad epochs 2\n",
      "2019-02-07 18:13:50,526 DEV  : loss 1.61119819 - f-score 0.8661 - acc 0.8662\n",
      "2019-02-07 18:13:51,393 TEST : loss 1.18211579 - f-score 0.8488 - acc 0.8487\n",
      "2019-02-07 18:13:51,394 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:13:51,603 epoch 79 - iter 0/47 - loss 1.04864311\n",
      "2019-02-07 18:13:52,618 epoch 79 - iter 4/47 - loss 1.34820006\n",
      "2019-02-07 18:13:53,470 epoch 79 - iter 8/47 - loss 1.47879730\n",
      "2019-02-07 18:13:54,326 epoch 79 - iter 12/47 - loss 1.42657890\n",
      "2019-02-07 18:13:55,245 epoch 79 - iter 16/47 - loss 1.50830173\n",
      "2019-02-07 18:13:56,094 epoch 79 - iter 20/47 - loss 1.48500819\n",
      "2019-02-07 18:13:56,891 epoch 79 - iter 24/47 - loss 1.47083038\n",
      "2019-02-07 18:13:57,705 epoch 79 - iter 28/47 - loss 1.47666787\n",
      "2019-02-07 18:13:58,515 epoch 79 - iter 32/47 - loss 1.51837687\n",
      "2019-02-07 18:13:59,339 epoch 79 - iter 36/47 - loss 1.50704118\n",
      "2019-02-07 18:14:00,181 epoch 79 - iter 40/47 - loss 1.50174931\n",
      "2019-02-07 18:14:01,026 epoch 79 - iter 44/47 - loss 1.50241967\n",
      "2019-02-07 18:14:01,564 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:14:01,566 EPOCH 79 done: loss 1.5096 - lr 0.0250 - bad epochs 3\n",
      "2019-02-07 18:14:02,576 DEV  : loss 1.66152632 - f-score 0.8678 - acc 0.8678\n",
      "2019-02-07 18:14:03,484 TEST : loss 1.20891130 - f-score 0.8478 - acc 0.8478\n",
      "2019-02-07 18:14:06,175 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:14:06,403 epoch 80 - iter 0/47 - loss 1.33485067\n",
      "2019-02-07 18:14:07,237 epoch 80 - iter 4/47 - loss 2.20005553\n",
      "2019-02-07 18:14:08,113 epoch 80 - iter 8/47 - loss 1.94733912\n",
      "2019-02-07 18:14:09,115 epoch 80 - iter 12/47 - loss 1.91639804\n",
      "2019-02-07 18:14:09,843 epoch 80 - iter 16/47 - loss 1.88398071\n",
      "2019-02-07 18:14:10,678 epoch 80 - iter 20/47 - loss 1.86592042\n",
      "2019-02-07 18:14:11,520 epoch 80 - iter 24/47 - loss 1.81851496\n",
      "2019-02-07 18:14:12,361 epoch 80 - iter 28/47 - loss 1.73867988\n",
      "2019-02-07 18:14:13,286 epoch 80 - iter 32/47 - loss 1.69095733\n",
      "2019-02-07 18:14:14,243 epoch 80 - iter 36/47 - loss 1.69942261\n",
      "2019-02-07 18:14:15,115 epoch 80 - iter 40/47 - loss 1.67000270\n",
      "2019-02-07 18:14:16,015 epoch 80 - iter 44/47 - loss 1.66209740\n",
      "2019-02-07 18:14:16,466 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:14:16,467 EPOCH 80 done: loss 1.6794 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:14:17,414 DEV  : loss 1.65971172 - f-score 0.8702 - acc 0.8702\n",
      "2019-02-07 18:14:18,263 TEST : loss 1.21398103 - f-score 0.8525 - acc 0.8525\n",
      "2019-02-07 18:14:18,265 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:14:18,533 epoch 81 - iter 0/47 - loss 2.54444575\n",
      "2019-02-07 18:14:19,466 epoch 81 - iter 4/47 - loss 1.51110008\n",
      "2019-02-07 18:14:20,366 epoch 81 - iter 8/47 - loss 1.55054764\n",
      "2019-02-07 18:14:21,179 epoch 81 - iter 12/47 - loss 1.71787963\n",
      "2019-02-07 18:14:22,150 epoch 81 - iter 16/47 - loss 1.72885453\n",
      "2019-02-07 18:14:23,065 epoch 81 - iter 20/47 - loss 1.60669294\n",
      "2019-02-07 18:14:23,890 epoch 81 - iter 24/47 - loss 1.60210332\n",
      "2019-02-07 18:14:24,716 epoch 81 - iter 28/47 - loss 1.63812164\n",
      "2019-02-07 18:14:25,477 epoch 81 - iter 32/47 - loss 1.63470433\n",
      "2019-02-07 18:14:26,496 epoch 81 - iter 36/47 - loss 1.65806762\n",
      "2019-02-07 18:14:27,286 epoch 81 - iter 40/47 - loss 1.66002636\n",
      "2019-02-07 18:14:28,096 epoch 81 - iter 44/47 - loss 1.62573330\n",
      "2019-02-07 18:14:28,486 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:14:28,487 EPOCH 81 done: loss 1.6259 - lr 0.0250 - bad epochs 1\n",
      "2019-02-07 18:14:29,428 DEV  : loss 1.63019884 - f-score 0.8700 - acc 0.8700\n",
      "2019-02-07 18:14:30,292 TEST : loss 1.19415653 - f-score 0.8490 - acc 0.8489\n",
      "2019-02-07 18:14:30,294 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:14:30,548 epoch 82 - iter 0/47 - loss 0.99352217\n",
      "2019-02-07 18:14:31,428 epoch 82 - iter 4/47 - loss 1.32317653\n",
      "2019-02-07 18:14:32,338 epoch 82 - iter 8/47 - loss 1.51660238\n",
      "2019-02-07 18:14:33,141 epoch 82 - iter 12/47 - loss 1.52025501\n",
      "2019-02-07 18:14:33,954 epoch 82 - iter 16/47 - loss 1.56236332\n",
      "2019-02-07 18:14:34,946 epoch 82 - iter 20/47 - loss 1.54066049\n",
      "2019-02-07 18:14:35,753 epoch 82 - iter 24/47 - loss 1.47712694\n",
      "2019-02-07 18:14:36,624 epoch 82 - iter 28/47 - loss 1.49980209\n",
      "2019-02-07 18:14:37,380 epoch 82 - iter 32/47 - loss 1.51640181\n",
      "2019-02-07 18:14:38,247 epoch 82 - iter 36/47 - loss 1.47131575\n",
      "2019-02-07 18:14:39,194 epoch 82 - iter 40/47 - loss 1.50708335\n",
      "2019-02-07 18:14:39,986 epoch 82 - iter 44/47 - loss 1.48276962\n",
      "2019-02-07 18:14:40,396 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:14:40,397 EPOCH 82 done: loss 1.5009 - lr 0.0250 - bad epochs 2\n",
      "2019-02-07 18:14:41,357 DEV  : loss 1.63706970 - f-score 0.8728 - acc 0.8728\n",
      "2019-02-07 18:14:42,226 TEST : loss 1.19400299 - f-score 0.8547 - acc 0.8547\n",
      "2019-02-07 18:14:44,838 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:14:45,115 epoch 83 - iter 0/47 - loss 0.92245781\n",
      "2019-02-07 18:14:45,998 epoch 83 - iter 4/47 - loss 1.55240148\n",
      "2019-02-07 18:14:46,778 epoch 83 - iter 8/47 - loss 1.50157019\n",
      "2019-02-07 18:14:47,679 epoch 83 - iter 12/47 - loss 1.48188353\n",
      "2019-02-07 18:14:48,696 epoch 83 - iter 16/47 - loss 1.48065863\n",
      "2019-02-07 18:14:49,503 epoch 83 - iter 20/47 - loss 1.48383380\n",
      "2019-02-07 18:14:50,383 epoch 83 - iter 24/47 - loss 1.44470940\n",
      "2019-02-07 18:14:51,160 epoch 83 - iter 28/47 - loss 1.52599357\n",
      "2019-02-07 18:14:52,039 epoch 83 - iter 32/47 - loss 1.47868789\n",
      "2019-02-07 18:14:52,906 epoch 83 - iter 36/47 - loss 1.47589285\n",
      "2019-02-07 18:14:53,820 epoch 83 - iter 40/47 - loss 1.49931657\n",
      "2019-02-07 18:14:54,741 epoch 83 - iter 44/47 - loss 1.49328022\n",
      "2019-02-07 18:14:55,057 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:14:55,058 EPOCH 83 done: loss 1.4839 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:14:56,005 DEV  : loss 1.62530518 - f-score 0.8723 - acc 0.8723\n",
      "2019-02-07 18:14:56,868 TEST : loss 1.20151532 - f-score 0.8506 - acc 0.8506\n",
      "2019-02-07 18:14:59,574 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:14:59,796 epoch 84 - iter 0/47 - loss 1.32718158\n",
      "2019-02-07 18:15:00,765 epoch 84 - iter 4/47 - loss 1.70133333\n",
      "2019-02-07 18:15:01,698 epoch 84 - iter 8/47 - loss 1.66167924\n",
      "2019-02-07 18:15:02,517 epoch 84 - iter 12/47 - loss 1.51489441\n",
      "2019-02-07 18:15:03,422 epoch 84 - iter 16/47 - loss 1.51302178\n",
      "2019-02-07 18:15:04,205 epoch 84 - iter 20/47 - loss 1.59910641\n",
      "2019-02-07 18:15:05,226 epoch 84 - iter 24/47 - loss 1.66861984\n",
      "2019-02-07 18:15:06,069 epoch 84 - iter 28/47 - loss 1.60081303\n",
      "2019-02-07 18:15:06,962 epoch 84 - iter 32/47 - loss 1.59214116\n",
      "2019-02-07 18:15:07,757 epoch 84 - iter 36/47 - loss 1.58375907\n",
      "2019-02-07 18:15:08,580 epoch 84 - iter 40/47 - loss 1.55398413\n",
      "2019-02-07 18:15:09,392 epoch 84 - iter 44/47 - loss 1.58048045\n",
      "2019-02-07 18:15:09,780 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:15:09,781 EPOCH 84 done: loss 1.5568 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:15:10,723 DEV  : loss 1.64709580 - f-score 0.8700 - acc 0.8700\n",
      "2019-02-07 18:15:11,582 TEST : loss 1.20181286 - f-score 0.8503 - acc 0.8503\n",
      "2019-02-07 18:15:11,584 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:15:11,806 epoch 85 - iter 0/47 - loss 1.82861722\n",
      "2019-02-07 18:15:12,600 epoch 85 - iter 4/47 - loss 1.39309120\n",
      "2019-02-07 18:15:13,366 epoch 85 - iter 8/47 - loss 1.25033887\n",
      "2019-02-07 18:15:14,210 epoch 85 - iter 12/47 - loss 1.24803177\n",
      "2019-02-07 18:15:15,031 epoch 85 - iter 16/47 - loss 1.22411209\n",
      "2019-02-07 18:15:15,934 epoch 85 - iter 20/47 - loss 1.32702080\n",
      "2019-02-07 18:15:16,932 epoch 85 - iter 24/47 - loss 1.38649828\n",
      "2019-02-07 18:15:17,867 epoch 85 - iter 28/47 - loss 1.46337125\n",
      "2019-02-07 18:15:18,728 epoch 85 - iter 32/47 - loss 1.45659923\n",
      "2019-02-07 18:15:19,450 epoch 85 - iter 36/47 - loss 1.43328800\n",
      "2019-02-07 18:15:20,291 epoch 85 - iter 40/47 - loss 1.49066963\n",
      "2019-02-07 18:15:21,249 epoch 85 - iter 44/47 - loss 1.48607703\n",
      "2019-02-07 18:15:21,644 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:15:21,646 EPOCH 85 done: loss 1.4774 - lr 0.0250 - bad epochs 1\n",
      "2019-02-07 18:15:22,611 DEV  : loss 1.62216675 - f-score 0.8700 - acc 0.8700\n",
      "2019-02-07 18:15:23,476 TEST : loss 1.19608855 - f-score 0.8522 - acc 0.8522\n",
      "2019-02-07 18:15:26,169 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:15:26,441 epoch 86 - iter 0/47 - loss 2.61353564\n",
      "2019-02-07 18:15:27,465 epoch 86 - iter 4/47 - loss 1.66638386\n",
      "2019-02-07 18:15:28,302 epoch 86 - iter 8/47 - loss 1.54943706\n",
      "2019-02-07 18:15:29,152 epoch 86 - iter 12/47 - loss 1.49385852\n",
      "2019-02-07 18:15:29,981 epoch 86 - iter 16/47 - loss 1.43908279\n",
      "2019-02-07 18:15:30,774 epoch 86 - iter 20/47 - loss 1.42094391\n",
      "2019-02-07 18:15:31,651 epoch 86 - iter 24/47 - loss 1.43772741\n",
      "2019-02-07 18:15:32,507 epoch 86 - iter 28/47 - loss 1.43860105\n",
      "2019-02-07 18:15:33,458 epoch 86 - iter 32/47 - loss 1.52443541\n",
      "2019-02-07 18:15:34,402 epoch 86 - iter 36/47 - loss 1.50794703\n",
      "2019-02-07 18:15:35,243 epoch 86 - iter 40/47 - loss 1.50660206\n",
      "2019-02-07 18:15:36,069 epoch 86 - iter 44/47 - loss 1.49766250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:15:36,463 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:15:36,464 EPOCH 86 done: loss 1.5075 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:15:37,469 DEV  : loss 1.69688141 - f-score 0.8686 - acc 0.8686\n",
      "2019-02-07 18:15:38,319 TEST : loss 1.23345888 - f-score 0.8441 - acc 0.8440\n",
      "2019-02-07 18:15:38,321 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:15:38,556 epoch 87 - iter 0/47 - loss 1.71432376\n",
      "2019-02-07 18:15:39,445 epoch 87 - iter 4/47 - loss 1.94253807\n",
      "2019-02-07 18:15:40,336 epoch 87 - iter 8/47 - loss 1.68350857\n",
      "2019-02-07 18:15:41,249 epoch 87 - iter 12/47 - loss 1.71118505\n",
      "2019-02-07 18:15:42,145 epoch 87 - iter 16/47 - loss 1.66102994\n",
      "2019-02-07 18:15:43,110 epoch 87 - iter 20/47 - loss 1.69881351\n",
      "2019-02-07 18:15:43,877 epoch 87 - iter 24/47 - loss 1.58683001\n",
      "2019-02-07 18:15:44,664 epoch 87 - iter 28/47 - loss 1.59822750\n",
      "2019-02-07 18:15:45,456 epoch 87 - iter 32/47 - loss 1.59695767\n",
      "2019-02-07 18:15:46,271 epoch 87 - iter 36/47 - loss 1.55198636\n",
      "2019-02-07 18:15:47,145 epoch 87 - iter 40/47 - loss 1.53155438\n",
      "2019-02-07 18:15:48,099 epoch 87 - iter 44/47 - loss 1.53674151\n",
      "2019-02-07 18:15:48,492 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:15:48,493 EPOCH 87 done: loss 1.5367 - lr 0.0250 - bad epochs 1\n",
      "2019-02-07 18:15:49,437 DEV  : loss 1.64699066 - f-score 0.8677 - acc 0.8677\n",
      "2019-02-07 18:15:50,315 TEST : loss 1.18567133 - f-score 0.8451 - acc 0.8451\n",
      "2019-02-07 18:15:50,317 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:15:50,524 epoch 88 - iter 0/47 - loss 1.81671584\n",
      "2019-02-07 18:15:51,386 epoch 88 - iter 4/47 - loss 1.58814785\n",
      "2019-02-07 18:15:52,261 epoch 88 - iter 8/47 - loss 1.62250740\n",
      "2019-02-07 18:15:53,046 epoch 88 - iter 12/47 - loss 1.60533527\n",
      "2019-02-07 18:15:53,912 epoch 88 - iter 16/47 - loss 1.49582431\n",
      "2019-02-07 18:15:54,770 epoch 88 - iter 20/47 - loss 1.44696727\n",
      "2019-02-07 18:15:55,604 epoch 88 - iter 24/47 - loss 1.45577892\n",
      "2019-02-07 18:15:56,433 epoch 88 - iter 28/47 - loss 1.47059629\n",
      "2019-02-07 18:15:57,231 epoch 88 - iter 32/47 - loss 1.47588469\n",
      "2019-02-07 18:15:58,015 epoch 88 - iter 36/47 - loss 1.46683853\n",
      "2019-02-07 18:15:59,098 epoch 88 - iter 40/47 - loss 1.45253856\n",
      "2019-02-07 18:15:59,999 epoch 88 - iter 44/47 - loss 1.46164527\n",
      "2019-02-07 18:16:00,341 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:00,342 EPOCH 88 done: loss 1.4683 - lr 0.0250 - bad epochs 2\n",
      "2019-02-07 18:16:01,551 DEV  : loss 1.64722300 - f-score 0.8624 - acc 0.8624\n",
      "2019-02-07 18:16:02,414 TEST : loss 1.20528030 - f-score 0.8430 - acc 0.8430\n",
      "2019-02-07 18:16:05,072 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:05,293 epoch 89 - iter 0/47 - loss 1.27980387\n",
      "2019-02-07 18:16:06,211 epoch 89 - iter 4/47 - loss 1.47213547\n",
      "2019-02-07 18:16:07,242 epoch 89 - iter 8/47 - loss 1.41488854\n",
      "2019-02-07 18:16:08,084 epoch 89 - iter 12/47 - loss 1.41544621\n",
      "2019-02-07 18:16:09,004 epoch 89 - iter 16/47 - loss 1.47468252\n",
      "2019-02-07 18:16:09,849 epoch 89 - iter 20/47 - loss 1.58895819\n",
      "2019-02-07 18:16:10,682 epoch 89 - iter 24/47 - loss 1.56188410\n",
      "2019-02-07 18:16:11,594 epoch 89 - iter 28/47 - loss 1.55965231\n",
      "2019-02-07 18:16:12,558 epoch 89 - iter 32/47 - loss 1.55061198\n",
      "2019-02-07 18:16:13,414 epoch 89 - iter 36/47 - loss 1.55311421\n",
      "2019-02-07 18:16:14,194 epoch 89 - iter 40/47 - loss 1.51970241\n",
      "2019-02-07 18:16:15,058 epoch 89 - iter 44/47 - loss 1.48257587\n",
      "2019-02-07 18:16:15,441 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:15,442 EPOCH 89 done: loss 1.5009 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:16:16,384 DEV  : loss 1.63339508 - f-score 0.8717 - acc 0.8717\n",
      "2019-02-07 18:16:17,250 TEST : loss 1.20343018 - f-score 0.8500 - acc 0.8500\n",
      "2019-02-07 18:16:17,252 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:17,482 epoch 90 - iter 0/47 - loss 1.11515701\n",
      "2019-02-07 18:16:18,305 epoch 90 - iter 4/47 - loss 1.31308997\n",
      "2019-02-07 18:16:19,221 epoch 90 - iter 8/47 - loss 1.27663365\n",
      "2019-02-07 18:16:20,030 epoch 90 - iter 12/47 - loss 1.28279520\n",
      "2019-02-07 18:16:20,926 epoch 90 - iter 16/47 - loss 1.33122650\n",
      "2019-02-07 18:16:21,861 epoch 90 - iter 20/47 - loss 1.37828085\n",
      "2019-02-07 18:16:22,757 epoch 90 - iter 24/47 - loss 1.41469351\n",
      "2019-02-07 18:16:23,462 epoch 90 - iter 28/47 - loss 1.39406844\n",
      "2019-02-07 18:16:24,368 epoch 90 - iter 32/47 - loss 1.38715595\n",
      "2019-02-07 18:16:25,149 epoch 90 - iter 36/47 - loss 1.40049606\n",
      "2019-02-07 18:16:25,979 epoch 90 - iter 40/47 - loss 1.44103582\n",
      "2019-02-07 18:16:26,837 epoch 90 - iter 44/47 - loss 1.48071219\n",
      "2019-02-07 18:16:27,272 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:27,273 EPOCH 90 done: loss 1.4653 - lr 0.0250 - bad epochs 1\n",
      "2019-02-07 18:16:28,216 DEV  : loss 1.63901377 - f-score 0.8700 - acc 0.8700\n",
      "2019-02-07 18:16:29,068 TEST : loss 1.19389641 - f-score 0.8509 - acc 0.8509\n",
      "2019-02-07 18:16:31,734 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:32,105 epoch 91 - iter 0/47 - loss 1.90304434\n",
      "2019-02-07 18:16:33,026 epoch 91 - iter 4/47 - loss 2.12184827\n",
      "2019-02-07 18:16:33,877 epoch 91 - iter 8/47 - loss 1.87491808\n",
      "2019-02-07 18:16:34,787 epoch 91 - iter 12/47 - loss 1.74746308\n",
      "2019-02-07 18:16:35,701 epoch 91 - iter 16/47 - loss 1.69278000\n",
      "2019-02-07 18:16:36,491 epoch 91 - iter 20/47 - loss 1.62997875\n",
      "2019-02-07 18:16:37,324 epoch 91 - iter 24/47 - loss 1.53362528\n",
      "2019-02-07 18:16:38,273 epoch 91 - iter 28/47 - loss 1.50447580\n",
      "2019-02-07 18:16:39,081 epoch 91 - iter 32/47 - loss 1.48891634\n",
      "2019-02-07 18:16:39,848 epoch 91 - iter 36/47 - loss 1.50738249\n",
      "2019-02-07 18:16:40,702 epoch 91 - iter 40/47 - loss 1.45901744\n",
      "2019-02-07 18:16:41,535 epoch 91 - iter 44/47 - loss 1.42407979\n",
      "2019-02-07 18:16:41,970 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:41,971 EPOCH 91 done: loss 1.4215 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:16:42,921 DEV  : loss 1.60926211 - f-score 0.8664 - acc 0.8664\n",
      "2019-02-07 18:16:43,753 TEST : loss 1.19408703 - f-score 0.8547 - acc 0.8547\n",
      "2019-02-07 18:16:46,327 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:46,541 epoch 92 - iter 0/47 - loss 2.08835196\n",
      "2019-02-07 18:16:47,515 epoch 92 - iter 4/47 - loss 1.34006402\n",
      "2019-02-07 18:16:48,399 epoch 92 - iter 8/47 - loss 1.40707269\n",
      "2019-02-07 18:16:49,214 epoch 92 - iter 12/47 - loss 1.47935301\n",
      "2019-02-07 18:16:50,068 epoch 92 - iter 16/47 - loss 1.46507043\n",
      "2019-02-07 18:16:51,132 epoch 92 - iter 20/47 - loss 1.44771489\n",
      "2019-02-07 18:16:51,930 epoch 92 - iter 24/47 - loss 1.44789260\n",
      "2019-02-07 18:16:52,715 epoch 92 - iter 28/47 - loss 1.41664787\n",
      "2019-02-07 18:16:53,501 epoch 92 - iter 32/47 - loss 1.40632692\n",
      "2019-02-07 18:16:54,391 epoch 92 - iter 36/47 - loss 1.39719580\n",
      "2019-02-07 18:16:55,176 epoch 92 - iter 40/47 - loss 1.42825249\n",
      "2019-02-07 18:16:56,232 epoch 92 - iter 44/47 - loss 1.42599620\n",
      "2019-02-07 18:16:56,665 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:56,666 EPOCH 92 done: loss 1.4604 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:16:57,615 DEV  : loss 1.61381650 - f-score 0.8695 - acc 0.8695\n",
      "2019-02-07 18:16:58,473 TEST : loss 1.19220471 - f-score 0.8468 - acc 0.8468\n",
      "2019-02-07 18:16:58,475 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:16:58,691 epoch 93 - iter 0/47 - loss 1.26403761\n",
      "2019-02-07 18:16:59,882 epoch 93 - iter 4/47 - loss 1.62544708\n",
      "2019-02-07 18:17:00,750 epoch 93 - iter 8/47 - loss 1.55899535\n",
      "2019-02-07 18:17:01,661 epoch 93 - iter 12/47 - loss 1.54936553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:17:02,574 epoch 93 - iter 16/47 - loss 1.50272288\n",
      "2019-02-07 18:17:03,419 epoch 93 - iter 20/47 - loss 1.45421389\n",
      "2019-02-07 18:17:04,161 epoch 93 - iter 24/47 - loss 1.50465174\n",
      "2019-02-07 18:17:04,947 epoch 93 - iter 28/47 - loss 1.44134243\n",
      "2019-02-07 18:17:05,804 epoch 93 - iter 32/47 - loss 1.43209484\n",
      "2019-02-07 18:17:06,682 epoch 93 - iter 36/47 - loss 1.44835472\n",
      "2019-02-07 18:17:07,440 epoch 93 - iter 40/47 - loss 1.43666094\n",
      "2019-02-07 18:17:08,240 epoch 93 - iter 44/47 - loss 1.43055314\n",
      "2019-02-07 18:17:08,662 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:17:08,663 EPOCH 93 done: loss 1.4182 - lr 0.0250 - bad epochs 1\n",
      "2019-02-07 18:17:09,614 DEV  : loss 1.57732797 - f-score 0.8719 - acc 0.8719\n",
      "2019-02-07 18:17:10,492 TEST : loss 1.18407989 - f-score 0.8533 - acc 0.8533\n",
      "2019-02-07 18:17:13,103 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:17:13,324 epoch 94 - iter 0/47 - loss 1.01623178\n",
      "2019-02-07 18:17:14,256 epoch 94 - iter 4/47 - loss 1.24010209\n",
      "2019-02-07 18:17:15,057 epoch 94 - iter 8/47 - loss 1.07400682\n",
      "2019-02-07 18:17:15,813 epoch 94 - iter 12/47 - loss 1.04162920\n",
      "2019-02-07 18:17:16,650 epoch 94 - iter 16/47 - loss 1.13923610\n",
      "2019-02-07 18:17:17,513 epoch 94 - iter 20/47 - loss 1.17871266\n",
      "2019-02-07 18:17:18,522 epoch 94 - iter 24/47 - loss 1.21393507\n",
      "2019-02-07 18:17:19,374 epoch 94 - iter 28/47 - loss 1.30689909\n",
      "2019-02-07 18:17:20,288 epoch 94 - iter 32/47 - loss 1.28606558\n",
      "2019-02-07 18:17:21,267 epoch 94 - iter 36/47 - loss 1.31814268\n",
      "2019-02-07 18:17:22,116 epoch 94 - iter 40/47 - loss 1.31674731\n",
      "2019-02-07 18:17:23,098 epoch 94 - iter 44/47 - loss 1.34240462\n",
      "2019-02-07 18:17:23,458 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:17:23,459 EPOCH 94 done: loss 1.3570 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:17:24,415 DEV  : loss 1.68376017 - f-score 0.8734 - acc 0.8734\n",
      "2019-02-07 18:17:25,264 TEST : loss 1.21846509 - f-score 0.8517 - acc 0.8517\n",
      "2019-02-07 18:17:27,905 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:17:28,118 epoch 95 - iter 0/47 - loss 1.40538073\n",
      "2019-02-07 18:17:28,973 epoch 95 - iter 4/47 - loss 1.38278385\n",
      "2019-02-07 18:17:29,845 epoch 95 - iter 8/47 - loss 1.55702313\n",
      "2019-02-07 18:17:30,685 epoch 95 - iter 12/47 - loss 1.48234038\n",
      "2019-02-07 18:17:31,511 epoch 95 - iter 16/47 - loss 1.39820993\n",
      "2019-02-07 18:17:32,497 epoch 95 - iter 20/47 - loss 1.43709080\n",
      "2019-02-07 18:17:33,411 epoch 95 - iter 24/47 - loss 1.36118606\n",
      "2019-02-07 18:17:34,273 epoch 95 - iter 28/47 - loss 1.43210198\n",
      "2019-02-07 18:17:35,117 epoch 95 - iter 32/47 - loss 1.42190490\n",
      "2019-02-07 18:17:35,962 epoch 95 - iter 36/47 - loss 1.38946884\n",
      "2019-02-07 18:17:36,801 epoch 95 - iter 40/47 - loss 1.42287845\n",
      "2019-02-07 18:17:37,712 epoch 95 - iter 44/47 - loss 1.40826529\n",
      "2019-02-07 18:17:38,095 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:17:38,096 EPOCH 95 done: loss 1.4222 - lr 0.0250 - bad epochs 0\n",
      "2019-02-07 18:17:39,036 DEV  : loss 1.64023542 - f-score 0.8709 - acc 0.8709\n",
      "2019-02-07 18:17:39,911 TEST : loss 1.21320784 - f-score 0.8457 - acc 0.8457\n",
      "2019-02-07 18:17:39,913 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:17:40,177 epoch 96 - iter 0/47 - loss 1.78388739\n",
      "2019-02-07 18:17:41,131 epoch 96 - iter 4/47 - loss 1.59004072\n",
      "2019-02-07 18:17:41,931 epoch 96 - iter 8/47 - loss 1.37196222\n",
      "2019-02-07 18:17:42,707 epoch 96 - iter 12/47 - loss 1.32847986\n",
      "2019-02-07 18:17:43,514 epoch 96 - iter 16/47 - loss 1.30227564\n",
      "2019-02-07 18:17:44,518 epoch 96 - iter 20/47 - loss 1.37715392\n",
      "2019-02-07 18:17:45,454 epoch 96 - iter 24/47 - loss 1.35209206\n",
      "2019-02-07 18:17:46,325 epoch 96 - iter 28/47 - loss 1.36350979\n",
      "2019-02-07 18:17:47,119 epoch 96 - iter 32/47 - loss 1.38072280\n",
      "2019-02-07 18:17:47,958 epoch 96 - iter 36/47 - loss 1.38195636\n",
      "2019-02-07 18:17:48,884 epoch 96 - iter 40/47 - loss 1.40670210\n",
      "2019-02-07 18:17:49,682 epoch 96 - iter 44/47 - loss 1.39002131\n",
      "2019-02-07 18:17:50,043 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:17:50,044 EPOCH 96 done: loss 1.3793 - lr 0.0250 - bad epochs 1\n",
      "2019-02-07 18:17:51,002 DEV  : loss 1.61143386 - f-score 0.8711 - acc 0.8712\n",
      "2019-02-07 18:17:51,848 TEST : loss 1.20793402 - f-score 0.8549 - acc 0.8550\n",
      "2019-02-07 18:17:51,850 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:17:52,040 epoch 97 - iter 0/47 - loss 1.81734693\n",
      "2019-02-07 18:17:52,839 epoch 97 - iter 4/47 - loss 1.23894869\n",
      "2019-02-07 18:17:53,692 epoch 97 - iter 8/47 - loss 1.42384221\n",
      "2019-02-07 18:17:54,466 epoch 97 - iter 12/47 - loss 1.40729247\n",
      "2019-02-07 18:17:55,293 epoch 97 - iter 16/47 - loss 1.37082979\n",
      "2019-02-07 18:17:56,135 epoch 97 - iter 20/47 - loss 1.34737570\n",
      "2019-02-07 18:17:57,063 epoch 97 - iter 24/47 - loss 1.38241612\n",
      "2019-02-07 18:17:57,881 epoch 97 - iter 28/47 - loss 1.42141991\n",
      "2019-02-07 18:17:58,820 epoch 97 - iter 32/47 - loss 1.44328609\n",
      "2019-02-07 18:17:59,679 epoch 97 - iter 36/47 - loss 1.41861565\n",
      "2019-02-07 18:18:00,572 epoch 97 - iter 40/47 - loss 1.46160082\n",
      "2019-02-07 18:18:01,436 epoch 97 - iter 44/47 - loss 1.48371955\n",
      "2019-02-07 18:18:01,918 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:01,919 EPOCH 97 done: loss 1.4969 - lr 0.0250 - bad epochs 2\n",
      "2019-02-07 18:18:02,873 DEV  : loss 1.61926377 - f-score 0.8713 - acc 0.8714\n",
      "2019-02-07 18:18:03,749 TEST : loss 1.19830573 - f-score 0.8457 - acc 0.8457\n",
      "2019-02-07 18:18:03,751 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:03,933 epoch 98 - iter 0/47 - loss 1.86913025\n",
      "2019-02-07 18:18:04,833 epoch 98 - iter 4/47 - loss 1.58222799\n",
      "2019-02-07 18:18:05,604 epoch 98 - iter 8/47 - loss 1.36933419\n",
      "2019-02-07 18:18:06,366 epoch 98 - iter 12/47 - loss 1.39521044\n",
      "2019-02-07 18:18:07,393 epoch 98 - iter 16/47 - loss 1.41934318\n",
      "2019-02-07 18:18:08,336 epoch 98 - iter 20/47 - loss 1.41416423\n",
      "2019-02-07 18:18:09,173 epoch 98 - iter 24/47 - loss 1.42016612\n",
      "2019-02-07 18:18:10,139 epoch 98 - iter 28/47 - loss 1.41602901\n",
      "2019-02-07 18:18:10,997 epoch 98 - iter 32/47 - loss 1.41445466\n",
      "2019-02-07 18:18:11,826 epoch 98 - iter 36/47 - loss 1.38089648\n",
      "2019-02-07 18:18:12,699 epoch 98 - iter 40/47 - loss 1.41103322\n",
      "2019-02-07 18:18:13,499 epoch 98 - iter 44/47 - loss 1.42321557\n",
      "2019-02-07 18:18:13,955 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:13,956 EPOCH 98 done: loss 1.4298 - lr 0.0250 - bad epochs 3\n",
      "2019-02-07 18:18:14,907 DEV  : loss 1.65087140 - f-score 0.8685 - acc 0.8686\n",
      "2019-02-07 18:18:15,774 TEST : loss 1.21150017 - f-score 0.8424 - acc 0.8424\n",
      "Epoch    97: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2019-02-07 18:18:15,776 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:15,957 epoch 99 - iter 0/47 - loss 1.54437327\n",
      "2019-02-07 18:18:16,810 epoch 99 - iter 4/47 - loss 1.43604336\n",
      "2019-02-07 18:18:17,783 epoch 99 - iter 8/47 - loss 1.51207952\n",
      "2019-02-07 18:18:18,593 epoch 99 - iter 12/47 - loss 1.54360287\n",
      "2019-02-07 18:18:19,346 epoch 99 - iter 16/47 - loss 1.43043987\n",
      "2019-02-07 18:18:20,238 epoch 99 - iter 20/47 - loss 1.54333759\n",
      "2019-02-07 18:18:21,270 epoch 99 - iter 24/47 - loss 1.55637684\n",
      "2019-02-07 18:18:22,041 epoch 99 - iter 28/47 - loss 1.51819257\n",
      "2019-02-07 18:18:22,854 epoch 99 - iter 32/47 - loss 1.46235035\n",
      "2019-02-07 18:18:23,706 epoch 99 - iter 36/47 - loss 1.46690279\n",
      "2019-02-07 18:18:24,606 epoch 99 - iter 40/47 - loss 1.49478335\n",
      "2019-02-07 18:18:25,427 epoch 99 - iter 44/47 - loss 1.45534426\n",
      "2019-02-07 18:18:25,772 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:25,773 EPOCH 99 done: loss 1.4544 - lr 0.0125 - bad epochs 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:18:26,723 DEV  : loss 1.62396240 - f-score 0.8723 - acc 0.8723\n",
      "2019-02-07 18:18:27,585 TEST : loss 1.19425952 - f-score 0.8408 - acc 0.8408\n",
      "2019-02-07 18:18:27,586 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:27,805 epoch 100 - iter 0/47 - loss 1.32519197\n",
      "2019-02-07 18:18:28,611 epoch 100 - iter 4/47 - loss 1.29181585\n",
      "2019-02-07 18:18:29,544 epoch 100 - iter 8/47 - loss 1.34053961\n",
      "2019-02-07 18:18:30,384 epoch 100 - iter 12/47 - loss 1.52092397\n",
      "2019-02-07 18:18:31,130 epoch 100 - iter 16/47 - loss 1.59430264\n",
      "2019-02-07 18:18:31,914 epoch 100 - iter 20/47 - loss 1.49426194\n",
      "2019-02-07 18:18:32,921 epoch 100 - iter 24/47 - loss 1.59109713\n",
      "2019-02-07 18:18:33,892 epoch 100 - iter 28/47 - loss 1.60129259\n",
      "2019-02-07 18:18:34,740 epoch 100 - iter 32/47 - loss 1.54743255\n",
      "2019-02-07 18:18:35,548 epoch 100 - iter 36/47 - loss 1.51444044\n",
      "2019-02-07 18:18:36,371 epoch 100 - iter 40/47 - loss 1.48644779\n",
      "2019-02-07 18:18:37,121 epoch 100 - iter 44/47 - loss 1.47586597\n",
      "2019-02-07 18:18:37,613 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:37,614 EPOCH 100 done: loss 1.4738 - lr 0.0125 - bad epochs 1\n",
      "2019-02-07 18:18:38,565 DEV  : loss 1.63958418 - f-score 0.8735 - acc 0.8735\n",
      "2019-02-07 18:18:39,434 TEST : loss 1.21200466 - f-score 0.8470 - acc 0.8470\n",
      "2019-02-07 18:18:39,436 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:39,648 epoch 101 - iter 0/47 - loss 1.27256858\n",
      "2019-02-07 18:18:40,421 epoch 101 - iter 4/47 - loss 1.20826548\n",
      "2019-02-07 18:18:41,219 epoch 101 - iter 8/47 - loss 1.18042811\n",
      "2019-02-07 18:18:42,257 epoch 101 - iter 12/47 - loss 1.38954229\n",
      "2019-02-07 18:18:43,170 epoch 101 - iter 16/47 - loss 1.52555329\n",
      "2019-02-07 18:18:44,072 epoch 101 - iter 20/47 - loss 1.48713386\n",
      "2019-02-07 18:18:44,958 epoch 101 - iter 24/47 - loss 1.50337955\n",
      "2019-02-07 18:18:45,782 epoch 101 - iter 28/47 - loss 1.44438173\n",
      "2019-02-07 18:18:46,547 epoch 101 - iter 32/47 - loss 1.47125425\n",
      "2019-02-07 18:18:47,315 epoch 101 - iter 36/47 - loss 1.44720397\n",
      "2019-02-07 18:18:48,204 epoch 101 - iter 40/47 - loss 1.43607724\n",
      "2019-02-07 18:18:49,090 epoch 101 - iter 44/47 - loss 1.43789012\n",
      "2019-02-07 18:18:49,546 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:49,547 EPOCH 101 done: loss 1.4484 - lr 0.0125 - bad epochs 2\n",
      "2019-02-07 18:18:50,509 DEV  : loss 1.63672507 - f-score 0.8743 - acc 0.8743\n",
      "2019-02-07 18:18:51,398 TEST : loss 1.19637537 - f-score 0.8520 - acc 0.8520\n",
      "2019-02-07 18:18:51,399 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:18:51,652 epoch 102 - iter 0/47 - loss 0.88600647\n",
      "2019-02-07 18:18:52,527 epoch 102 - iter 4/47 - loss 1.22331851\n",
      "2019-02-07 18:18:53,303 epoch 102 - iter 8/47 - loss 1.40794216\n",
      "2019-02-07 18:18:54,200 epoch 102 - iter 12/47 - loss 1.36044701\n",
      "2019-02-07 18:18:55,130 epoch 102 - iter 16/47 - loss 1.37622618\n",
      "2019-02-07 18:18:56,043 epoch 102 - iter 20/47 - loss 1.34794639\n",
      "2019-02-07 18:18:56,833 epoch 102 - iter 24/47 - loss 1.34304640\n",
      "2019-02-07 18:18:57,685 epoch 102 - iter 28/47 - loss 1.33554997\n",
      "2019-02-07 18:18:58,439 epoch 102 - iter 32/47 - loss 1.32424411\n",
      "2019-02-07 18:18:59,191 epoch 102 - iter 36/47 - loss 1.33213483\n",
      "2019-02-07 18:19:00,239 epoch 102 - iter 40/47 - loss 1.37127683\n",
      "2019-02-07 18:19:00,989 epoch 102 - iter 44/47 - loss 1.33884545\n",
      "2019-02-07 18:19:01,385 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:01,386 EPOCH 102 done: loss 1.3534 - lr 0.0125 - bad epochs 3\n",
      "2019-02-07 18:19:02,323 DEV  : loss 1.62942302 - f-score 0.8721 - acc 0.8721\n",
      "2019-02-07 18:19:03,183 TEST : loss 1.18843627 - f-score 0.8465 - acc 0.8465\n",
      "2019-02-07 18:19:05,774 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:06,088 epoch 103 - iter 0/47 - loss 1.33603072\n",
      "2019-02-07 18:19:07,074 epoch 103 - iter 4/47 - loss 1.61167209\n",
      "2019-02-07 18:19:08,022 epoch 103 - iter 8/47 - loss 1.49181922\n",
      "2019-02-07 18:19:08,879 epoch 103 - iter 12/47 - loss 1.52164386\n",
      "2019-02-07 18:19:09,719 epoch 103 - iter 16/47 - loss 1.47177999\n",
      "2019-02-07 18:19:10,522 epoch 103 - iter 20/47 - loss 1.51720515\n",
      "2019-02-07 18:19:11,399 epoch 103 - iter 24/47 - loss 1.49556705\n",
      "2019-02-07 18:19:12,255 epoch 103 - iter 28/47 - loss 1.53391740\n",
      "2019-02-07 18:19:13,245 epoch 103 - iter 32/47 - loss 1.47568468\n",
      "2019-02-07 18:19:14,053 epoch 103 - iter 36/47 - loss 1.49194385\n",
      "2019-02-07 18:19:14,892 epoch 103 - iter 40/47 - loss 1.45235147\n",
      "2019-02-07 18:19:15,680 epoch 103 - iter 44/47 - loss 1.44783102\n",
      "2019-02-07 18:19:16,021 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:16,022 EPOCH 103 done: loss 1.4276 - lr 0.0125 - bad epochs 0\n",
      "2019-02-07 18:19:16,960 DEV  : loss 1.65154243 - f-score 0.8743 - acc 0.8743\n",
      "2019-02-07 18:19:17,833 TEST : loss 1.19366574 - f-score 0.8435 - acc 0.8435\n",
      "2019-02-07 18:19:17,835 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:18,059 epoch 104 - iter 0/47 - loss 0.71239954\n",
      "2019-02-07 18:19:18,918 epoch 104 - iter 4/47 - loss 1.42375820\n",
      "2019-02-07 18:19:19,851 epoch 104 - iter 8/47 - loss 1.38329958\n",
      "2019-02-07 18:19:20,909 epoch 104 - iter 12/47 - loss 1.36466229\n",
      "2019-02-07 18:19:21,724 epoch 104 - iter 16/47 - loss 1.38267202\n",
      "2019-02-07 18:19:22,537 epoch 104 - iter 20/47 - loss 1.35362747\n",
      "2019-02-07 18:19:23,506 epoch 104 - iter 24/47 - loss 1.38137175\n",
      "2019-02-07 18:19:24,347 epoch 104 - iter 28/47 - loss 1.35902708\n",
      "2019-02-07 18:19:25,089 epoch 104 - iter 32/47 - loss 1.35857941\n",
      "2019-02-07 18:19:25,992 epoch 104 - iter 36/47 - loss 1.35233784\n",
      "2019-02-07 18:19:26,787 epoch 104 - iter 40/47 - loss 1.34330507\n",
      "2019-02-07 18:19:27,601 epoch 104 - iter 44/47 - loss 1.36661206\n",
      "2019-02-07 18:19:27,988 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:27,989 EPOCH 104 done: loss 1.3856 - lr 0.0125 - bad epochs 1\n",
      "2019-02-07 18:19:28,944 DEV  : loss 1.62446868 - f-score 0.8711 - acc 0.8712\n",
      "2019-02-07 18:19:29,808 TEST : loss 1.19192350 - f-score 0.8446 - acc 0.8446\n",
      "2019-02-07 18:19:29,810 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:30,014 epoch 105 - iter 0/47 - loss 0.96166861\n",
      "2019-02-07 18:19:30,872 epoch 105 - iter 4/47 - loss 1.03973649\n",
      "2019-02-07 18:19:31,731 epoch 105 - iter 8/47 - loss 1.28008457\n",
      "2019-02-07 18:19:32,571 epoch 105 - iter 12/47 - loss 1.22844288\n",
      "2019-02-07 18:19:33,489 epoch 105 - iter 16/47 - loss 1.30418825\n",
      "2019-02-07 18:19:34,347 epoch 105 - iter 20/47 - loss 1.23540934\n",
      "2019-02-07 18:19:35,180 epoch 105 - iter 24/47 - loss 1.31916744\n",
      "2019-02-07 18:19:36,262 epoch 105 - iter 28/47 - loss 1.36543188\n",
      "2019-02-07 18:19:37,167 epoch 105 - iter 32/47 - loss 1.37233025\n",
      "2019-02-07 18:19:37,997 epoch 105 - iter 36/47 - loss 1.35158880\n",
      "2019-02-07 18:19:39,203 epoch 105 - iter 40/47 - loss 1.35733853\n",
      "2019-02-07 18:19:40,016 epoch 105 - iter 44/47 - loss 1.34438501\n",
      "2019-02-07 18:19:40,434 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:40,435 EPOCH 105 done: loss 1.3360 - lr 0.0125 - bad epochs 2\n",
      "2019-02-07 18:19:41,421 DEV  : loss 1.61655152 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:19:42,331 TEST : loss 1.18619502 - f-score 0.8530 - acc 0.8531\n",
      "2019-02-07 18:19:45,224 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:45,464 epoch 106 - iter 0/47 - loss 2.49950600\n",
      "2019-02-07 18:19:46,360 epoch 106 - iter 4/47 - loss 1.53134613\n",
      "2019-02-07 18:19:47,505 epoch 106 - iter 8/47 - loss 1.47695758\n",
      "2019-02-07 18:19:48,379 epoch 106 - iter 12/47 - loss 1.56531366\n",
      "2019-02-07 18:19:49,200 epoch 106 - iter 16/47 - loss 1.57561810\n",
      "2019-02-07 18:19:50,029 epoch 106 - iter 20/47 - loss 1.57555154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:19:50,827 epoch 106 - iter 24/47 - loss 1.59431190\n",
      "2019-02-07 18:19:51,698 epoch 106 - iter 28/47 - loss 1.54102696\n",
      "2019-02-07 18:19:52,586 epoch 106 - iter 32/47 - loss 1.56520161\n",
      "2019-02-07 18:19:53,480 epoch 106 - iter 36/47 - loss 1.50582753\n",
      "2019-02-07 18:19:54,332 epoch 106 - iter 40/47 - loss 1.48632904\n",
      "2019-02-07 18:19:55,131 epoch 106 - iter 44/47 - loss 1.47753594\n",
      "2019-02-07 18:19:55,492 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:55,493 EPOCH 106 done: loss 1.5030 - lr 0.0125 - bad epochs 0\n",
      "2019-02-07 18:19:56,456 DEV  : loss 1.60788023 - f-score 0.8706 - acc 0.8706\n",
      "2019-02-07 18:19:57,324 TEST : loss 1.18315530 - f-score 0.8454 - acc 0.8454\n",
      "2019-02-07 18:19:57,326 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:19:57,561 epoch 107 - iter 0/47 - loss 0.91612422\n",
      "2019-02-07 18:19:58,379 epoch 107 - iter 4/47 - loss 1.21349959\n",
      "2019-02-07 18:19:59,305 epoch 107 - iter 8/47 - loss 1.37343801\n",
      "2019-02-07 18:20:00,245 epoch 107 - iter 12/47 - loss 1.48628150\n",
      "2019-02-07 18:20:01,084 epoch 107 - iter 16/47 - loss 1.43471942\n",
      "2019-02-07 18:20:01,875 epoch 107 - iter 20/47 - loss 1.47811256\n",
      "2019-02-07 18:20:02,861 epoch 107 - iter 24/47 - loss 1.44164515\n",
      "2019-02-07 18:20:03,648 epoch 107 - iter 28/47 - loss 1.41937071\n",
      "2019-02-07 18:20:04,490 epoch 107 - iter 32/47 - loss 1.49364573\n",
      "2019-02-07 18:20:05,361 epoch 107 - iter 36/47 - loss 1.53063625\n",
      "2019-02-07 18:20:06,255 epoch 107 - iter 40/47 - loss 1.52472064\n",
      "2019-02-07 18:20:07,650 epoch 107 - iter 44/47 - loss 1.55972746\n",
      "2019-02-07 18:20:08,200 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:08,202 EPOCH 107 done: loss 1.5326 - lr 0.0125 - bad epochs 1\n",
      "2019-02-07 18:20:09,172 DEV  : loss 1.63408303 - f-score 0.8733 - acc 0.8733\n",
      "2019-02-07 18:20:10,039 TEST : loss 1.20097053 - f-score 0.8509 - acc 0.8509\n",
      "2019-02-07 18:20:10,041 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:10,192 epoch 108 - iter 0/47 - loss 0.53555924\n",
      "2019-02-07 18:20:11,103 epoch 108 - iter 4/47 - loss 1.66149863\n",
      "2019-02-07 18:20:12,128 epoch 108 - iter 8/47 - loss 1.43992189\n",
      "2019-02-07 18:20:12,973 epoch 108 - iter 12/47 - loss 1.33570860\n",
      "2019-02-07 18:20:13,810 epoch 108 - iter 16/47 - loss 1.30737113\n",
      "2019-02-07 18:20:14,688 epoch 108 - iter 20/47 - loss 1.34759231\n",
      "2019-02-07 18:20:15,635 epoch 108 - iter 24/47 - loss 1.35535070\n",
      "2019-02-07 18:20:16,427 epoch 108 - iter 28/47 - loss 1.34783647\n",
      "2019-02-07 18:20:17,281 epoch 108 - iter 32/47 - loss 1.34748853\n",
      "2019-02-07 18:20:18,122 epoch 108 - iter 36/47 - loss 1.36437766\n",
      "2019-02-07 18:20:18,910 epoch 108 - iter 40/47 - loss 1.38853849\n",
      "2019-02-07 18:20:19,821 epoch 108 - iter 44/47 - loss 1.36066097\n",
      "2019-02-07 18:20:20,207 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:20,208 EPOCH 108 done: loss 1.3647 - lr 0.0125 - bad epochs 2\n",
      "2019-02-07 18:20:21,186 DEV  : loss 1.62837279 - f-score 0.8714 - acc 0.8715\n",
      "2019-02-07 18:20:22,038 TEST : loss 1.18929958 - f-score 0.8500 - acc 0.8500\n",
      "2019-02-07 18:20:22,040 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:22,240 epoch 109 - iter 0/47 - loss 1.14325178\n",
      "2019-02-07 18:20:23,068 epoch 109 - iter 4/47 - loss 1.52874629\n",
      "2019-02-07 18:20:24,056 epoch 109 - iter 8/47 - loss 1.62026058\n",
      "2019-02-07 18:20:24,810 epoch 109 - iter 12/47 - loss 1.49598876\n",
      "2019-02-07 18:20:25,689 epoch 109 - iter 16/47 - loss 1.39942068\n",
      "2019-02-07 18:20:26,565 epoch 109 - iter 20/47 - loss 1.37184357\n",
      "2019-02-07 18:20:27,465 epoch 109 - iter 24/47 - loss 1.41434932\n",
      "2019-02-07 18:20:28,292 epoch 109 - iter 28/47 - loss 1.45142802\n",
      "2019-02-07 18:20:29,213 epoch 109 - iter 32/47 - loss 1.55748420\n",
      "2019-02-07 18:20:30,142 epoch 109 - iter 36/47 - loss 1.51571469\n",
      "2019-02-07 18:20:30,976 epoch 109 - iter 40/47 - loss 1.47359326\n",
      "2019-02-07 18:20:31,864 epoch 109 - iter 44/47 - loss 1.45690230\n",
      "2019-02-07 18:20:32,250 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:32,251 EPOCH 109 done: loss 1.4377 - lr 0.0125 - bad epochs 3\n",
      "2019-02-07 18:20:33,493 DEV  : loss 1.61435246 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:20:34,391 TEST : loss 1.18791008 - f-score 0.8446 - acc 0.8446\n",
      "Epoch   108: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2019-02-07 18:20:34,393 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:34,605 epoch 110 - iter 0/47 - loss 0.91922259\n",
      "2019-02-07 18:20:35,640 epoch 110 - iter 4/47 - loss 1.24127142\n",
      "2019-02-07 18:20:36,484 epoch 110 - iter 8/47 - loss 1.39071710\n",
      "2019-02-07 18:20:37,387 epoch 110 - iter 12/47 - loss 1.37276097\n",
      "2019-02-07 18:20:38,217 epoch 110 - iter 16/47 - loss 1.33529187\n",
      "2019-02-07 18:20:39,072 epoch 110 - iter 20/47 - loss 1.33941187\n",
      "2019-02-07 18:20:39,909 epoch 110 - iter 24/47 - loss 1.33408385\n",
      "2019-02-07 18:20:40,726 epoch 110 - iter 28/47 - loss 1.32733901\n",
      "2019-02-07 18:20:41,535 epoch 110 - iter 32/47 - loss 1.33784772\n",
      "2019-02-07 18:20:42,353 epoch 110 - iter 36/47 - loss 1.32694253\n",
      "2019-02-07 18:20:43,223 epoch 110 - iter 40/47 - loss 1.38174997\n",
      "2019-02-07 18:20:44,160 epoch 110 - iter 44/47 - loss 1.39967743\n",
      "2019-02-07 18:20:44,560 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:44,561 EPOCH 110 done: loss 1.3806 - lr 0.0063 - bad epochs 0\n",
      "2019-02-07 18:20:45,534 DEV  : loss 1.62039435 - f-score 0.8724 - acc 0.8724\n",
      "2019-02-07 18:20:46,409 TEST : loss 1.19200838 - f-score 0.8473 - acc 0.8473\n",
      "2019-02-07 18:20:46,412 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:46,654 epoch 111 - iter 0/47 - loss 2.67166567\n",
      "2019-02-07 18:20:47,586 epoch 111 - iter 4/47 - loss 1.44027557\n",
      "2019-02-07 18:20:48,554 epoch 111 - iter 8/47 - loss 1.26586607\n",
      "2019-02-07 18:20:49,457 epoch 111 - iter 12/47 - loss 1.35200313\n",
      "2019-02-07 18:20:50,283 epoch 111 - iter 16/47 - loss 1.32231433\n",
      "2019-02-07 18:20:51,227 epoch 111 - iter 20/47 - loss 1.27865202\n",
      "2019-02-07 18:20:52,119 epoch 111 - iter 24/47 - loss 1.26815072\n",
      "2019-02-07 18:20:52,922 epoch 111 - iter 28/47 - loss 1.33636072\n",
      "2019-02-07 18:20:53,871 epoch 111 - iter 32/47 - loss 1.35875284\n",
      "2019-02-07 18:20:54,761 epoch 111 - iter 36/47 - loss 1.37660048\n",
      "2019-02-07 18:20:55,562 epoch 111 - iter 40/47 - loss 1.35869474\n",
      "2019-02-07 18:20:56,393 epoch 111 - iter 44/47 - loss 1.34958672\n",
      "2019-02-07 18:20:56,786 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:56,786 EPOCH 111 done: loss 1.3454 - lr 0.0063 - bad epochs 1\n",
      "2019-02-07 18:20:57,772 DEV  : loss 1.62140119 - f-score 0.8719 - acc 0.8719\n",
      "2019-02-07 18:20:58,642 TEST : loss 1.18811750 - f-score 0.8473 - acc 0.8473\n",
      "2019-02-07 18:20:58,644 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:20:58,864 epoch 112 - iter 0/47 - loss 0.87466371\n",
      "2019-02-07 18:20:59,726 epoch 112 - iter 4/47 - loss 1.25913274\n",
      "2019-02-07 18:21:00,626 epoch 112 - iter 8/47 - loss 1.28858364\n",
      "2019-02-07 18:21:01,577 epoch 112 - iter 12/47 - loss 1.35573093\n",
      "2019-02-07 18:21:02,475 epoch 112 - iter 16/47 - loss 1.31488538\n",
      "2019-02-07 18:21:03,460 epoch 112 - iter 20/47 - loss 1.32927996\n",
      "2019-02-07 18:21:04,325 epoch 112 - iter 24/47 - loss 1.28090787\n",
      "2019-02-07 18:21:05,145 epoch 112 - iter 28/47 - loss 1.30034515\n",
      "2019-02-07 18:21:05,992 epoch 112 - iter 32/47 - loss 1.31408381\n",
      "2019-02-07 18:21:06,753 epoch 112 - iter 36/47 - loss 1.30964332\n",
      "2019-02-07 18:21:07,611 epoch 112 - iter 40/47 - loss 1.32158422\n",
      "2019-02-07 18:21:08,404 epoch 112 - iter 44/47 - loss 1.34671346\n",
      "2019-02-07 18:21:08,859 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:08,860 EPOCH 112 done: loss 1.3599 - lr 0.0063 - bad epochs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:21:09,808 DEV  : loss 1.63118088 - f-score 0.8719 - acc 0.8719\n",
      "2019-02-07 18:21:10,690 TEST : loss 1.18866241 - f-score 0.8473 - acc 0.8473\n",
      "2019-02-07 18:21:10,691 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:10,964 epoch 113 - iter 0/47 - loss 1.91901052\n",
      "2019-02-07 18:21:11,787 epoch 113 - iter 4/47 - loss 1.26789302\n",
      "2019-02-07 18:21:12,840 epoch 113 - iter 8/47 - loss 1.43791935\n",
      "2019-02-07 18:21:13,663 epoch 113 - iter 12/47 - loss 1.38862435\n",
      "2019-02-07 18:21:14,451 epoch 113 - iter 16/47 - loss 1.31515141\n",
      "2019-02-07 18:21:15,395 epoch 113 - iter 20/47 - loss 1.28625768\n",
      "2019-02-07 18:21:16,263 epoch 113 - iter 24/47 - loss 1.32556377\n",
      "2019-02-07 18:21:17,149 epoch 113 - iter 28/47 - loss 1.36480379\n",
      "2019-02-07 18:21:17,982 epoch 113 - iter 32/47 - loss 1.34956740\n",
      "2019-02-07 18:21:18,819 epoch 113 - iter 36/47 - loss 1.35893393\n",
      "2019-02-07 18:21:19,623 epoch 113 - iter 40/47 - loss 1.36226471\n",
      "2019-02-07 18:21:20,535 epoch 113 - iter 44/47 - loss 1.35209257\n",
      "2019-02-07 18:21:20,911 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:20,912 EPOCH 113 done: loss 1.3543 - lr 0.0063 - bad epochs 3\n",
      "2019-02-07 18:21:21,862 DEV  : loss 1.62839937 - f-score 0.8719 - acc 0.8719\n",
      "2019-02-07 18:21:22,721 TEST : loss 1.18460655 - f-score 0.8427 - acc 0.8427\n",
      "Epoch   112: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2019-02-07 18:21:22,723 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:22,919 epoch 114 - iter 0/47 - loss 1.24275172\n",
      "2019-02-07 18:21:23,896 epoch 114 - iter 4/47 - loss 1.16140207\n",
      "2019-02-07 18:21:24,746 epoch 114 - iter 8/47 - loss 1.20402471\n",
      "2019-02-07 18:21:25,553 epoch 114 - iter 12/47 - loss 1.29921968\n",
      "2019-02-07 18:21:26,338 epoch 114 - iter 16/47 - loss 1.36192751\n",
      "2019-02-07 18:21:27,250 epoch 114 - iter 20/47 - loss 1.37434861\n",
      "2019-02-07 18:21:27,983 epoch 114 - iter 24/47 - loss 1.37372602\n",
      "2019-02-07 18:21:28,852 epoch 114 - iter 28/47 - loss 1.40621864\n",
      "2019-02-07 18:21:29,706 epoch 114 - iter 32/47 - loss 1.40771923\n",
      "2019-02-07 18:21:30,721 epoch 114 - iter 36/47 - loss 1.42851436\n",
      "2019-02-07 18:21:31,548 epoch 114 - iter 40/47 - loss 1.39658325\n",
      "2019-02-07 18:21:32,337 epoch 114 - iter 44/47 - loss 1.38884917\n",
      "2019-02-07 18:21:32,811 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:32,812 EPOCH 114 done: loss 1.3903 - lr 0.0031 - bad epochs 0\n",
      "2019-02-07 18:21:33,758 DEV  : loss 1.63467419 - f-score 0.8719 - acc 0.8719\n",
      "2019-02-07 18:21:34,621 TEST : loss 1.18477178 - f-score 0.8465 - acc 0.8465\n",
      "2019-02-07 18:21:34,622 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:34,833 epoch 115 - iter 0/47 - loss 1.14686012\n",
      "2019-02-07 18:21:35,722 epoch 115 - iter 4/47 - loss 1.56680727\n",
      "2019-02-07 18:21:36,633 epoch 115 - iter 8/47 - loss 1.54974665\n",
      "2019-02-07 18:21:37,411 epoch 115 - iter 12/47 - loss 1.40733329\n",
      "2019-02-07 18:21:38,384 epoch 115 - iter 16/47 - loss 1.38491104\n",
      "2019-02-07 18:21:39,325 epoch 115 - iter 20/47 - loss 1.39642742\n",
      "2019-02-07 18:21:40,163 epoch 115 - iter 24/47 - loss 1.37052423\n",
      "2019-02-07 18:21:40,978 epoch 115 - iter 28/47 - loss 1.39831529\n",
      "2019-02-07 18:21:41,812 epoch 115 - iter 32/47 - loss 1.35934862\n",
      "2019-02-07 18:21:42,711 epoch 115 - iter 36/47 - loss 1.36647601\n",
      "2019-02-07 18:21:43,524 epoch 115 - iter 40/47 - loss 1.34971667\n",
      "2019-02-07 18:21:44,362 epoch 115 - iter 44/47 - loss 1.39945937\n",
      "2019-02-07 18:21:44,804 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:44,805 EPOCH 115 done: loss 1.4096 - lr 0.0031 - bad epochs 1\n",
      "2019-02-07 18:21:45,753 DEV  : loss 1.63644576 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:21:46,603 TEST : loss 1.18439364 - f-score 0.8482 - acc 0.8481\n",
      "2019-02-07 18:21:46,605 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:46,965 epoch 116 - iter 0/47 - loss 1.77853942\n",
      "2019-02-07 18:21:47,884 epoch 116 - iter 4/47 - loss 1.47043066\n",
      "2019-02-07 18:21:48,720 epoch 116 - iter 8/47 - loss 1.46964637\n",
      "2019-02-07 18:21:49,505 epoch 116 - iter 12/47 - loss 1.41579009\n",
      "2019-02-07 18:21:50,351 epoch 116 - iter 16/47 - loss 1.47874904\n",
      "2019-02-07 18:21:51,200 epoch 116 - iter 20/47 - loss 1.45612652\n",
      "2019-02-07 18:21:52,035 epoch 116 - iter 24/47 - loss 1.43288787\n",
      "2019-02-07 18:21:52,785 epoch 116 - iter 28/47 - loss 1.40848247\n",
      "2019-02-07 18:21:53,709 epoch 116 - iter 32/47 - loss 1.37916813\n",
      "2019-02-07 18:21:54,560 epoch 116 - iter 36/47 - loss 1.38441968\n",
      "2019-02-07 18:21:55,287 epoch 116 - iter 40/47 - loss 1.36602992\n",
      "2019-02-07 18:21:56,206 epoch 116 - iter 44/47 - loss 1.37848037\n",
      "2019-02-07 18:21:56,605 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:56,606 EPOCH 116 done: loss 1.3992 - lr 0.0031 - bad epochs 2\n",
      "2019-02-07 18:21:57,578 DEV  : loss 1.62706149 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:21:58,464 TEST : loss 1.18248892 - f-score 0.8500 - acc 0.8500\n",
      "2019-02-07 18:21:58,466 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:21:58,763 epoch 117 - iter 0/47 - loss 1.25215125\n",
      "2019-02-07 18:21:59,646 epoch 117 - iter 4/47 - loss 1.26319757\n",
      "2019-02-07 18:22:00,548 epoch 117 - iter 8/47 - loss 1.40477370\n",
      "2019-02-07 18:22:01,373 epoch 117 - iter 12/47 - loss 1.30333987\n",
      "2019-02-07 18:22:02,130 epoch 117 - iter 16/47 - loss 1.41289566\n",
      "2019-02-07 18:22:02,910 epoch 117 - iter 20/47 - loss 1.32268108\n",
      "2019-02-07 18:22:03,777 epoch 117 - iter 24/47 - loss 1.32694765\n",
      "2019-02-07 18:22:04,599 epoch 117 - iter 28/47 - loss 1.32139741\n",
      "2019-02-07 18:22:05,446 epoch 117 - iter 32/47 - loss 1.35157702\n",
      "2019-02-07 18:22:06,317 epoch 117 - iter 36/47 - loss 1.36970297\n",
      "2019-02-07 18:22:07,175 epoch 117 - iter 40/47 - loss 1.36315916\n",
      "2019-02-07 18:22:08,172 epoch 117 - iter 44/47 - loss 1.36015736\n",
      "2019-02-07 18:22:08,753 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:08,754 EPOCH 117 done: loss 1.3651 - lr 0.0031 - bad epochs 3\n",
      "2019-02-07 18:22:09,700 DEV  : loss 1.63312387 - f-score 0.8719 - acc 0.8719\n",
      "2019-02-07 18:22:10,597 TEST : loss 1.18558204 - f-score 0.8500 - acc 0.8500\n",
      "Epoch   116: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2019-02-07 18:22:10,598 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:10,826 epoch 118 - iter 0/47 - loss 2.33955336\n",
      "2019-02-07 18:22:11,633 epoch 118 - iter 4/47 - loss 1.36472259\n",
      "2019-02-07 18:22:12,473 epoch 118 - iter 8/47 - loss 1.39087111\n",
      "2019-02-07 18:22:13,416 epoch 118 - iter 12/47 - loss 1.35687600\n",
      "2019-02-07 18:22:14,172 epoch 118 - iter 16/47 - loss 1.25108010\n",
      "2019-02-07 18:22:15,120 epoch 118 - iter 20/47 - loss 1.31144872\n",
      "2019-02-07 18:22:15,990 epoch 118 - iter 24/47 - loss 1.33570893\n",
      "2019-02-07 18:22:16,827 epoch 118 - iter 28/47 - loss 1.40660091\n",
      "2019-02-07 18:22:17,656 epoch 118 - iter 32/47 - loss 1.38112987\n",
      "2019-02-07 18:22:18,645 epoch 118 - iter 36/47 - loss 1.39485837\n",
      "2019-02-07 18:22:19,490 epoch 118 - iter 40/47 - loss 1.38075512\n",
      "2019-02-07 18:22:20,356 epoch 118 - iter 44/47 - loss 1.37724108\n",
      "2019-02-07 18:22:20,749 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:20,750 EPOCH 118 done: loss 1.3836 - lr 0.0016 - bad epochs 0\n",
      "2019-02-07 18:22:21,716 DEV  : loss 1.62984407 - f-score 0.8719 - acc 0.8719\n",
      "2019-02-07 18:22:22,597 TEST : loss 1.18383288 - f-score 0.8500 - acc 0.8500\n",
      "2019-02-07 18:22:22,598 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:22,799 epoch 119 - iter 0/47 - loss 1.38560724\n",
      "2019-02-07 18:22:23,626 epoch 119 - iter 4/47 - loss 1.47548931\n",
      "2019-02-07 18:22:24,496 epoch 119 - iter 8/47 - loss 1.46066069\n",
      "2019-02-07 18:22:25,400 epoch 119 - iter 12/47 - loss 1.42522314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:22:26,365 epoch 119 - iter 16/47 - loss 1.47026747\n",
      "2019-02-07 18:22:27,228 epoch 119 - iter 20/47 - loss 1.46426323\n",
      "2019-02-07 18:22:28,095 epoch 119 - iter 24/47 - loss 1.43108185\n",
      "2019-02-07 18:22:28,964 epoch 119 - iter 28/47 - loss 1.47521786\n",
      "2019-02-07 18:22:29,904 epoch 119 - iter 32/47 - loss 1.47675438\n",
      "2019-02-07 18:22:30,712 epoch 119 - iter 36/47 - loss 1.45561794\n",
      "2019-02-07 18:22:31,583 epoch 119 - iter 40/47 - loss 1.44083238\n",
      "2019-02-07 18:22:32,329 epoch 119 - iter 44/47 - loss 1.40984761\n",
      "2019-02-07 18:22:32,664 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:32,665 EPOCH 119 done: loss 1.3977 - lr 0.0016 - bad epochs 1\n",
      "2019-02-07 18:22:33,609 DEV  : loss 1.63257682 - f-score 0.8719 - acc 0.8719\n",
      "2019-02-07 18:22:34,467 TEST : loss 1.18435490 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:22:34,469 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:34,662 epoch 120 - iter 0/47 - loss 0.63653630\n",
      "2019-02-07 18:22:35,629 epoch 120 - iter 4/47 - loss 1.45562478\n",
      "2019-02-07 18:22:36,466 epoch 120 - iter 8/47 - loss 1.24439533\n",
      "2019-02-07 18:22:37,378 epoch 120 - iter 12/47 - loss 1.30862386\n",
      "2019-02-07 18:22:38,269 epoch 120 - iter 16/47 - loss 1.23791864\n",
      "2019-02-07 18:22:39,224 epoch 120 - iter 20/47 - loss 1.37354383\n",
      "2019-02-07 18:22:40,048 epoch 120 - iter 24/47 - loss 1.38363111\n",
      "2019-02-07 18:22:40,912 epoch 120 - iter 28/47 - loss 1.36416451\n",
      "2019-02-07 18:22:41,758 epoch 120 - iter 32/47 - loss 1.38914217\n",
      "2019-02-07 18:22:42,543 epoch 120 - iter 36/47 - loss 1.42783092\n",
      "2019-02-07 18:22:43,453 epoch 120 - iter 40/47 - loss 1.42827286\n",
      "2019-02-07 18:22:44,364 epoch 120 - iter 44/47 - loss 1.43580137\n",
      "2019-02-07 18:22:44,717 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:44,718 EPOCH 120 done: loss 1.4307 - lr 0.0016 - bad epochs 2\n",
      "2019-02-07 18:22:45,680 DEV  : loss 1.63023615 - f-score 0.8728 - acc 0.8728\n",
      "2019-02-07 18:22:46,544 TEST : loss 1.18458331 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:22:46,546 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:46,879 epoch 121 - iter 0/47 - loss 1.46062016\n",
      "2019-02-07 18:22:47,843 epoch 121 - iter 4/47 - loss 1.13917918\n",
      "2019-02-07 18:22:48,783 epoch 121 - iter 8/47 - loss 1.18862234\n",
      "2019-02-07 18:22:49,656 epoch 121 - iter 12/47 - loss 1.22191563\n",
      "2019-02-07 18:22:50,514 epoch 121 - iter 16/47 - loss 1.27543226\n",
      "2019-02-07 18:22:51,356 epoch 121 - iter 20/47 - loss 1.31478969\n",
      "2019-02-07 18:22:52,165 epoch 121 - iter 24/47 - loss 1.32664074\n",
      "2019-02-07 18:22:53,003 epoch 121 - iter 28/47 - loss 1.38742587\n",
      "2019-02-07 18:22:53,900 epoch 121 - iter 32/47 - loss 1.38219811\n",
      "2019-02-07 18:22:54,692 epoch 121 - iter 36/47 - loss 1.38632835\n",
      "2019-02-07 18:22:55,602 epoch 121 - iter 40/47 - loss 1.36645627\n",
      "2019-02-07 18:22:56,531 epoch 121 - iter 44/47 - loss 1.35459034\n",
      "2019-02-07 18:22:56,949 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:56,950 EPOCH 121 done: loss 1.3669 - lr 0.0016 - bad epochs 3\n",
      "2019-02-07 18:22:57,924 DEV  : loss 1.63546813 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:22:58,796 TEST : loss 1.18444598 - f-score 0.8482 - acc 0.8481\n",
      "Epoch   120: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2019-02-07 18:22:58,798 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:22:59,051 epoch 122 - iter 0/47 - loss 0.84914225\n",
      "2019-02-07 18:23:00,112 epoch 122 - iter 4/47 - loss 1.50941120\n",
      "2019-02-07 18:23:00,968 epoch 122 - iter 8/47 - loss 1.48765904\n",
      "2019-02-07 18:23:01,869 epoch 122 - iter 12/47 - loss 1.37390023\n",
      "2019-02-07 18:23:02,769 epoch 122 - iter 16/47 - loss 1.39255068\n",
      "2019-02-07 18:23:03,606 epoch 122 - iter 20/47 - loss 1.37053598\n",
      "2019-02-07 18:23:04,702 epoch 122 - iter 24/47 - loss 1.35163746\n",
      "2019-02-07 18:23:05,519 epoch 122 - iter 28/47 - loss 1.36768522\n",
      "2019-02-07 18:23:06,410 epoch 122 - iter 32/47 - loss 1.37001880\n",
      "2019-02-07 18:23:07,259 epoch 122 - iter 36/47 - loss 1.34270046\n",
      "2019-02-07 18:23:08,078 epoch 122 - iter 40/47 - loss 1.37495473\n",
      "2019-02-07 18:23:08,905 epoch 122 - iter 44/47 - loss 1.37226825\n",
      "2019-02-07 18:23:09,307 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:23:09,307 EPOCH 122 done: loss 1.3659 - lr 0.0008 - bad epochs 0\n",
      "2019-02-07 18:23:10,253 DEV  : loss 1.63359487 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:23:11,104 TEST : loss 1.18373954 - f-score 0.8482 - acc 0.8481\n",
      "2019-02-07 18:23:11,106 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:23:11,316 epoch 123 - iter 0/47 - loss 1.72710454\n",
      "2019-02-07 18:23:12,142 epoch 123 - iter 4/47 - loss 1.45361044\n",
      "2019-02-07 18:23:13,017 epoch 123 - iter 8/47 - loss 1.32362736\n",
      "2019-02-07 18:23:13,923 epoch 123 - iter 12/47 - loss 1.28748902\n",
      "2019-02-07 18:23:14,919 epoch 123 - iter 16/47 - loss 1.34467585\n",
      "2019-02-07 18:23:15,919 epoch 123 - iter 20/47 - loss 1.36809178\n",
      "2019-02-07 18:23:16,790 epoch 123 - iter 24/47 - loss 1.32834697\n",
      "2019-02-07 18:23:17,644 epoch 123 - iter 28/47 - loss 1.35229240\n",
      "2019-02-07 18:23:18,465 epoch 123 - iter 32/47 - loss 1.38922030\n",
      "2019-02-07 18:23:19,358 epoch 123 - iter 36/47 - loss 1.39742440\n",
      "2019-02-07 18:23:20,208 epoch 123 - iter 40/47 - loss 1.40788533\n",
      "2019-02-07 18:23:20,994 epoch 123 - iter 44/47 - loss 1.40234182\n",
      "2019-02-07 18:23:21,368 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:23:21,369 EPOCH 123 done: loss 1.3917 - lr 0.0008 - bad epochs 1\n",
      "2019-02-07 18:23:22,329 DEV  : loss 1.63228381 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:23:23,201 TEST : loss 1.18437493 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:23:23,203 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:23:23,366 epoch 124 - iter 0/47 - loss 1.06147122\n",
      "2019-02-07 18:23:24,211 epoch 124 - iter 4/47 - loss 1.49113026\n",
      "2019-02-07 18:23:25,063 epoch 124 - iter 8/47 - loss 1.48765302\n",
      "2019-02-07 18:23:25,985 epoch 124 - iter 12/47 - loss 1.37814674\n",
      "2019-02-07 18:23:26,870 epoch 124 - iter 16/47 - loss 1.38373038\n",
      "2019-02-07 18:23:27,598 epoch 124 - iter 20/47 - loss 1.36458941\n",
      "2019-02-07 18:23:28,688 epoch 124 - iter 24/47 - loss 1.42557956\n",
      "2019-02-07 18:23:29,530 epoch 124 - iter 28/47 - loss 1.43517030\n",
      "2019-02-07 18:23:30,408 epoch 124 - iter 32/47 - loss 1.43066779\n",
      "2019-02-07 18:23:31,385 epoch 124 - iter 36/47 - loss 1.44313509\n",
      "2019-02-07 18:23:32,145 epoch 124 - iter 40/47 - loss 1.44871054\n",
      "2019-02-07 18:23:33,119 epoch 124 - iter 44/47 - loss 1.41627350\n",
      "2019-02-07 18:23:33,481 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:23:33,481 EPOCH 124 done: loss 1.3976 - lr 0.0008 - bad epochs 2\n",
      "2019-02-07 18:23:34,437 DEV  : loss 1.63303065 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:23:35,296 TEST : loss 1.18407381 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:23:35,298 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:23:35,591 epoch 125 - iter 0/47 - loss 1.22953391\n",
      "2019-02-07 18:23:36,413 epoch 125 - iter 4/47 - loss 1.35664399\n",
      "2019-02-07 18:23:37,358 epoch 125 - iter 8/47 - loss 1.35505229\n",
      "2019-02-07 18:23:38,314 epoch 125 - iter 12/47 - loss 1.33622681\n",
      "2019-02-07 18:23:39,221 epoch 125 - iter 16/47 - loss 1.41482544\n",
      "2019-02-07 18:23:40,150 epoch 125 - iter 20/47 - loss 1.40942983\n",
      "2019-02-07 18:23:40,980 epoch 125 - iter 24/47 - loss 1.44893962\n",
      "2019-02-07 18:23:41,802 epoch 125 - iter 28/47 - loss 1.44765669\n",
      "2019-02-07 18:23:42,533 epoch 125 - iter 32/47 - loss 1.40862153\n",
      "2019-02-07 18:23:43,308 epoch 125 - iter 36/47 - loss 1.38359992\n",
      "2019-02-07 18:23:44,195 epoch 125 - iter 40/47 - loss 1.37823262\n",
      "2019-02-07 18:23:45,076 epoch 125 - iter 44/47 - loss 1.39629752\n",
      "2019-02-07 18:23:45,478 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:23:45,479 EPOCH 125 done: loss 1.4015 - lr 0.0008 - bad epochs 3\n",
      "2019-02-07 18:23:46,442 DEV  : loss 1.63099813 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:23:47,303 TEST : loss 1.18343675 - f-score 0.8462 - acc 0.8462\n",
      "Epoch   124: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2019-02-07 18:23:47,306 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:23:47,508 epoch 126 - iter 0/47 - loss 0.90466952\n",
      "2019-02-07 18:23:48,400 epoch 126 - iter 4/47 - loss 1.28337835\n",
      "2019-02-07 18:23:49,320 epoch 126 - iter 8/47 - loss 1.34033722\n",
      "2019-02-07 18:23:50,092 epoch 126 - iter 12/47 - loss 1.38033398\n",
      "2019-02-07 18:23:50,993 epoch 126 - iter 16/47 - loss 1.46851037\n",
      "2019-02-07 18:23:51,756 epoch 126 - iter 20/47 - loss 1.35468053\n",
      "2019-02-07 18:23:52,757 epoch 126 - iter 24/47 - loss 1.35808048\n",
      "2019-02-07 18:23:53,640 epoch 126 - iter 28/47 - loss 1.45370232\n",
      "2019-02-07 18:23:54,591 epoch 126 - iter 32/47 - loss 1.43153923\n",
      "2019-02-07 18:23:55,481 epoch 126 - iter 36/47 - loss 1.40034406\n",
      "2019-02-07 18:23:56,411 epoch 126 - iter 40/47 - loss 1.40747111\n",
      "2019-02-07 18:23:57,240 epoch 126 - iter 44/47 - loss 1.38783316\n",
      "2019-02-07 18:23:57,616 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:23:57,617 EPOCH 126 done: loss 1.3699 - lr 0.0004 - bad epochs 0\n",
      "2019-02-07 18:23:58,616 DEV  : loss 1.63038266 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:23:59,489 TEST : loss 1.18290532 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:23:59,491 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:23:59,784 epoch 127 - iter 0/47 - loss 1.15519381\n",
      "2019-02-07 18:24:00,630 epoch 127 - iter 4/47 - loss 1.18094370\n",
      "2019-02-07 18:24:01,407 epoch 127 - iter 8/47 - loss 1.29208937\n",
      "2019-02-07 18:24:02,229 epoch 127 - iter 12/47 - loss 1.37604083\n",
      "2019-02-07 18:24:03,078 epoch 127 - iter 16/47 - loss 1.35087390\n",
      "2019-02-07 18:24:04,078 epoch 127 - iter 20/47 - loss 1.41076318\n",
      "2019-02-07 18:24:04,895 epoch 127 - iter 24/47 - loss 1.41612189\n",
      "2019-02-07 18:24:05,829 epoch 127 - iter 28/47 - loss 1.39242172\n",
      "2019-02-07 18:24:06,699 epoch 127 - iter 32/47 - loss 1.37203489\n",
      "2019-02-07 18:24:07,550 epoch 127 - iter 36/47 - loss 1.39806159\n",
      "2019-02-07 18:24:08,677 epoch 127 - iter 40/47 - loss 1.41809764\n",
      "2019-02-07 18:24:09,483 epoch 127 - iter 44/47 - loss 1.41542648\n",
      "2019-02-07 18:24:09,849 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:24:09,850 EPOCH 127 done: loss 1.4257 - lr 0.0004 - bad epochs 1\n",
      "2019-02-07 18:24:10,877 DEV  : loss 1.63050938 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:24:11,772 TEST : loss 1.18304777 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:24:11,774 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:24:11,977 epoch 128 - iter 0/47 - loss 0.97215623\n",
      "2019-02-07 18:24:13,016 epoch 128 - iter 4/47 - loss 1.79074162\n",
      "2019-02-07 18:24:13,885 epoch 128 - iter 8/47 - loss 1.48336787\n",
      "2019-02-07 18:24:14,831 epoch 128 - iter 12/47 - loss 1.36684163\n",
      "2019-02-07 18:24:15,699 epoch 128 - iter 16/47 - loss 1.45201820\n",
      "2019-02-07 18:24:16,637 epoch 128 - iter 20/47 - loss 1.41482123\n",
      "2019-02-07 18:24:17,603 epoch 128 - iter 24/47 - loss 1.43682356\n",
      "2019-02-07 18:24:18,421 epoch 128 - iter 28/47 - loss 1.39359260\n",
      "2019-02-07 18:24:19,296 epoch 128 - iter 32/47 - loss 1.40684775\n",
      "2019-02-07 18:24:20,090 epoch 128 - iter 36/47 - loss 1.38135711\n",
      "2019-02-07 18:24:20,964 epoch 128 - iter 40/47 - loss 1.38917926\n",
      "2019-02-07 18:24:21,737 epoch 128 - iter 44/47 - loss 1.39570148\n",
      "2019-02-07 18:24:22,110 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:24:22,111 EPOCH 128 done: loss 1.3984 - lr 0.0004 - bad epochs 2\n",
      "2019-02-07 18:24:23,059 DEV  : loss 1.63148487 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:24:23,948 TEST : loss 1.18365908 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:24:23,950 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:24:24,167 epoch 129 - iter 0/47 - loss 0.95101160\n",
      "2019-02-07 18:24:25,095 epoch 129 - iter 4/47 - loss 1.18627476\n",
      "2019-02-07 18:24:25,951 epoch 129 - iter 8/47 - loss 1.21012326\n",
      "2019-02-07 18:24:26,713 epoch 129 - iter 12/47 - loss 1.15952205\n",
      "2019-02-07 18:24:27,599 epoch 129 - iter 16/47 - loss 1.16069131\n",
      "2019-02-07 18:24:28,484 epoch 129 - iter 20/47 - loss 1.15127521\n",
      "2019-02-07 18:24:29,364 epoch 129 - iter 24/47 - loss 1.26028614\n",
      "2019-02-07 18:24:30,305 epoch 129 - iter 28/47 - loss 1.26396864\n",
      "2019-02-07 18:24:31,310 epoch 129 - iter 32/47 - loss 1.29021327\n",
      "2019-02-07 18:24:32,155 epoch 129 - iter 36/47 - loss 1.28227217\n",
      "2019-02-07 18:24:32,951 epoch 129 - iter 40/47 - loss 1.26511715\n",
      "2019-02-07 18:24:33,710 epoch 129 - iter 44/47 - loss 1.27888460\n",
      "2019-02-07 18:24:34,162 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:24:34,163 EPOCH 129 done: loss 1.2803 - lr 0.0004 - bad epochs 3\n",
      "2019-02-07 18:24:35,120 DEV  : loss 1.63263381 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:24:35,978 TEST : loss 1.18431556 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:24:38,772 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:24:38,985 epoch 130 - iter 0/47 - loss 1.18374610\n",
      "2019-02-07 18:24:39,859 epoch 130 - iter 4/47 - loss 1.37380652\n",
      "2019-02-07 18:24:40,639 epoch 130 - iter 8/47 - loss 1.30041958\n",
      "2019-02-07 18:24:41,508 epoch 130 - iter 12/47 - loss 1.43793653\n",
      "2019-02-07 18:24:42,346 epoch 130 - iter 16/47 - loss 1.39395132\n",
      "2019-02-07 18:24:43,294 epoch 130 - iter 20/47 - loss 1.39836647\n",
      "2019-02-07 18:24:44,068 epoch 130 - iter 24/47 - loss 1.39324183\n",
      "2019-02-07 18:24:44,861 epoch 130 - iter 28/47 - loss 1.38492949\n",
      "2019-02-07 18:24:45,794 epoch 130 - iter 32/47 - loss 1.38929608\n",
      "2019-02-07 18:24:46,705 epoch 130 - iter 36/47 - loss 1.39848431\n",
      "2019-02-07 18:24:47,832 epoch 130 - iter 40/47 - loss 1.38592717\n",
      "2019-02-07 18:24:48,665 epoch 130 - iter 44/47 - loss 1.36063807\n",
      "2019-02-07 18:24:49,071 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:24:49,072 EPOCH 130 done: loss 1.3485 - lr 0.0004 - bad epochs 0\n",
      "2019-02-07 18:24:50,072 DEV  : loss 1.63210857 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:24:51,188 TEST : loss 1.18389273 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:24:51,190 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:24:51,403 epoch 131 - iter 0/47 - loss 1.41118681\n",
      "2019-02-07 18:24:52,282 epoch 131 - iter 4/47 - loss 1.06040200\n",
      "2019-02-07 18:24:53,165 epoch 131 - iter 8/47 - loss 1.19213173\n",
      "2019-02-07 18:24:54,021 epoch 131 - iter 12/47 - loss 1.15682718\n",
      "2019-02-07 18:24:54,913 epoch 131 - iter 16/47 - loss 1.20908101\n",
      "2019-02-07 18:24:55,814 epoch 131 - iter 20/47 - loss 1.14936927\n",
      "2019-02-07 18:24:56,635 epoch 131 - iter 24/47 - loss 1.19883115\n",
      "2019-02-07 18:24:57,613 epoch 131 - iter 28/47 - loss 1.21718775\n",
      "2019-02-07 18:24:58,437 epoch 131 - iter 32/47 - loss 1.22319870\n",
      "2019-02-07 18:24:59,286 epoch 131 - iter 36/47 - loss 1.23707956\n",
      "2019-02-07 18:25:00,218 epoch 131 - iter 40/47 - loss 1.25534200\n",
      "2019-02-07 18:25:01,127 epoch 131 - iter 44/47 - loss 1.27088273\n",
      "2019-02-07 18:25:01,528 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:01,529 EPOCH 131 done: loss 1.2893 - lr 0.0004 - bad epochs 1\n",
      "2019-02-07 18:25:02,501 DEV  : loss 1.63252807 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:25:03,365 TEST : loss 1.18417323 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:25:03,371 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:03,577 epoch 132 - iter 0/47 - loss 1.34578848\n",
      "2019-02-07 18:25:04,501 epoch 132 - iter 4/47 - loss 1.45934098\n",
      "2019-02-07 18:25:05,258 epoch 132 - iter 8/47 - loss 1.34693453\n",
      "2019-02-07 18:25:06,279 epoch 132 - iter 12/47 - loss 1.34246888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:25:07,199 epoch 132 - iter 16/47 - loss 1.26343305\n",
      "2019-02-07 18:25:07,984 epoch 132 - iter 20/47 - loss 1.29516709\n",
      "2019-02-07 18:25:08,816 epoch 132 - iter 24/47 - loss 1.28432345\n",
      "2019-02-07 18:25:09,756 epoch 132 - iter 28/47 - loss 1.40401079\n",
      "2019-02-07 18:25:10,661 epoch 132 - iter 32/47 - loss 1.37881717\n",
      "2019-02-07 18:25:11,560 epoch 132 - iter 36/47 - loss 1.40042025\n",
      "2019-02-07 18:25:12,467 epoch 132 - iter 40/47 - loss 1.40045773\n",
      "2019-02-07 18:25:13,152 epoch 132 - iter 44/47 - loss 1.37093024\n",
      "2019-02-07 18:25:13,523 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:13,524 EPOCH 132 done: loss 1.3696 - lr 0.0004 - bad epochs 2\n",
      "2019-02-07 18:25:14,460 DEV  : loss 1.63134730 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:25:15,319 TEST : loss 1.18347764 - f-score 0.8462 - acc 0.8462\n",
      "2019-02-07 18:25:15,321 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:15,475 epoch 133 - iter 0/47 - loss 0.85750353\n",
      "2019-02-07 18:25:16,336 epoch 133 - iter 4/47 - loss 1.26459761\n",
      "2019-02-07 18:25:17,143 epoch 133 - iter 8/47 - loss 1.26130023\n",
      "2019-02-07 18:25:17,957 epoch 133 - iter 12/47 - loss 1.29643568\n",
      "2019-02-07 18:25:18,782 epoch 133 - iter 16/47 - loss 1.25983425\n",
      "2019-02-07 18:25:19,698 epoch 133 - iter 20/47 - loss 1.37882392\n",
      "2019-02-07 18:25:20,603 epoch 133 - iter 24/47 - loss 1.37369437\n",
      "2019-02-07 18:25:21,451 epoch 133 - iter 28/47 - loss 1.35816180\n",
      "2019-02-07 18:25:22,338 epoch 133 - iter 32/47 - loss 1.37840938\n",
      "2019-02-07 18:25:23,151 epoch 133 - iter 36/47 - loss 1.32585508\n",
      "2019-02-07 18:25:24,033 epoch 133 - iter 40/47 - loss 1.37375239\n",
      "2019-02-07 18:25:24,929 epoch 133 - iter 44/47 - loss 1.33788661\n",
      "2019-02-07 18:25:25,454 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:25,455 EPOCH 133 done: loss 1.3576 - lr 0.0004 - bad epochs 3\n",
      "2019-02-07 18:25:26,425 DEV  : loss 1.63361788 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:25:27,290 TEST : loss 1.18481243 - f-score 0.8482 - acc 0.8481\n",
      "Epoch   132: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2019-02-07 18:25:27,293 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:27,514 epoch 134 - iter 0/47 - loss 1.28431046\n",
      "2019-02-07 18:25:28,506 epoch 134 - iter 4/47 - loss 1.28705354\n",
      "2019-02-07 18:25:29,354 epoch 134 - iter 8/47 - loss 1.39759165\n",
      "2019-02-07 18:25:30,356 epoch 134 - iter 12/47 - loss 1.39469620\n",
      "2019-02-07 18:25:31,165 epoch 134 - iter 16/47 - loss 1.35741452\n",
      "2019-02-07 18:25:32,042 epoch 134 - iter 20/47 - loss 1.39377726\n",
      "2019-02-07 18:25:33,356 epoch 134 - iter 24/47 - loss 1.40607807\n",
      "2019-02-07 18:25:34,459 epoch 134 - iter 28/47 - loss 1.40559201\n",
      "2019-02-07 18:25:35,709 epoch 134 - iter 32/47 - loss 1.39583278\n",
      "2019-02-07 18:25:36,934 epoch 134 - iter 36/47 - loss 1.38059091\n",
      "2019-02-07 18:25:38,035 epoch 134 - iter 40/47 - loss 1.35942161\n",
      "2019-02-07 18:25:38,835 epoch 134 - iter 44/47 - loss 1.36488706\n",
      "2019-02-07 18:25:39,270 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:39,271 EPOCH 134 done: loss 1.3621 - lr 0.0002 - bad epochs 0\n",
      "2019-02-07 18:25:40,267 DEV  : loss 1.63318753 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:25:41,157 TEST : loss 1.18484974 - f-score 0.8482 - acc 0.8481\n",
      "2019-02-07 18:25:41,162 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:41,489 epoch 135 - iter 0/47 - loss 1.81979299\n",
      "2019-02-07 18:25:42,366 epoch 135 - iter 4/47 - loss 1.79130290\n",
      "2019-02-07 18:25:43,329 epoch 135 - iter 8/47 - loss 1.68070079\n",
      "2019-02-07 18:25:44,262 epoch 135 - iter 12/47 - loss 1.62274653\n",
      "2019-02-07 18:25:45,099 epoch 135 - iter 16/47 - loss 1.56222663\n",
      "2019-02-07 18:25:46,085 epoch 135 - iter 20/47 - loss 1.55112303\n",
      "2019-02-07 18:25:47,203 epoch 135 - iter 24/47 - loss 1.50593251\n",
      "2019-02-07 18:25:48,294 epoch 135 - iter 28/47 - loss 1.45119680\n",
      "2019-02-07 18:25:49,164 epoch 135 - iter 32/47 - loss 1.50107110\n",
      "2019-02-07 18:25:50,009 epoch 135 - iter 36/47 - loss 1.46243743\n",
      "2019-02-07 18:25:50,878 epoch 135 - iter 40/47 - loss 1.43636615\n",
      "2019-02-07 18:25:51,736 epoch 135 - iter 44/47 - loss 1.40842160\n",
      "2019-02-07 18:25:52,214 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:52,215 EPOCH 135 done: loss 1.3897 - lr 0.0002 - bad epochs 1\n",
      "2019-02-07 18:25:53,310 DEV  : loss 1.63297427 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:25:54,217 TEST : loss 1.18497312 - f-score 0.8482 - acc 0.8481\n",
      "2019-02-07 18:25:54,219 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:25:54,434 epoch 136 - iter 0/47 - loss 1.12456179\n",
      "2019-02-07 18:25:55,339 epoch 136 - iter 4/47 - loss 1.36327994\n",
      "2019-02-07 18:25:56,249 epoch 136 - iter 8/47 - loss 1.45801692\n",
      "2019-02-07 18:25:57,224 epoch 136 - iter 12/47 - loss 1.44294424\n",
      "2019-02-07 18:25:58,113 epoch 136 - iter 16/47 - loss 1.34887929\n",
      "2019-02-07 18:25:59,035 epoch 136 - iter 20/47 - loss 1.41473668\n",
      "2019-02-07 18:25:59,974 epoch 136 - iter 24/47 - loss 1.39171540\n",
      "2019-02-07 18:26:00,933 epoch 136 - iter 28/47 - loss 1.41269246\n",
      "2019-02-07 18:26:01,744 epoch 136 - iter 32/47 - loss 1.40738490\n",
      "2019-02-07 18:26:02,646 epoch 136 - iter 36/47 - loss 1.43570662\n",
      "2019-02-07 18:26:03,676 epoch 136 - iter 40/47 - loss 1.43245018\n",
      "2019-02-07 18:26:04,523 epoch 136 - iter 44/47 - loss 1.40086732\n",
      "2019-02-07 18:26:04,911 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:26:04,912 EPOCH 136 done: loss 1.3937 - lr 0.0002 - bad epochs 2\n",
      "2019-02-07 18:26:05,887 DEV  : loss 1.63263118 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:26:06,761 TEST : loss 1.18495190 - f-score 0.8482 - acc 0.8481\n",
      "2019-02-07 18:26:06,764 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:26:07,034 epoch 137 - iter 0/47 - loss 1.36309397\n",
      "2019-02-07 18:26:08,020 epoch 137 - iter 4/47 - loss 1.33368218\n",
      "2019-02-07 18:26:08,886 epoch 137 - iter 8/47 - loss 1.36211116\n",
      "2019-02-07 18:26:09,737 epoch 137 - iter 12/47 - loss 1.50492172\n",
      "2019-02-07 18:26:10,463 epoch 137 - iter 16/47 - loss 1.50914419\n",
      "2019-02-07 18:26:11,216 epoch 137 - iter 20/47 - loss 1.41938485\n",
      "2019-02-07 18:26:12,065 epoch 137 - iter 24/47 - loss 1.50407670\n",
      "2019-02-07 18:26:12,966 epoch 137 - iter 28/47 - loss 1.47074433\n",
      "2019-02-07 18:26:13,909 epoch 137 - iter 32/47 - loss 1.42411162\n",
      "2019-02-07 18:26:14,848 epoch 137 - iter 36/47 - loss 1.40971936\n",
      "2019-02-07 18:26:15,658 epoch 137 - iter 40/47 - loss 1.36659866\n",
      "2019-02-07 18:26:16,532 epoch 137 - iter 44/47 - loss 1.36491685\n",
      "2019-02-07 18:26:16,971 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:26:16,972 EPOCH 137 done: loss 1.3583 - lr 0.0002 - bad epochs 3\n",
      "2019-02-07 18:26:17,926 DEV  : loss 1.63259399 - f-score 0.8726 - acc 0.8726\n",
      "2019-02-07 18:26:18,799 TEST : loss 1.18507063 - f-score 0.8482 - acc 0.8481\n",
      "Epoch   136: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2019-02-07 18:26:18,801 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:26:18,802 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:26:18,803 learning rate too small - quitting training!\n",
      "2019-02-07 18:26:18,804 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:26:21,510 ----------------------------------------------------------------------------------------------------\n",
      "2019-02-07 18:26:21,511 Testing using best model ...\n",
      "2019-02-07 18:26:24,150 MICRO_AVG: acc 0.8462 - f1-score 0.8462\n",
      "2019-02-07 18:26:24,151 MARCO_AVG: acc 0.8261 - f1-score 0.8755\n",
      "2019-02-07 18:26:24,153 LOC        tp: 143 - fp: 26 - fn: 13 - tn: 143 - precision: 0.8462 - recall: 0.9167 - accuracy: 0.8800 - f1-score: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 18:26:24,154 MISC       tp: 40 - fp: 7 - fn: 23 - tn: 40 - precision: 0.8511 - recall: 0.6349 - accuracy: 0.7273 - f1-score: 0.7273\n",
      "2019-02-07 18:26:24,154 ORG        tp: 120 - fp: 14 - fn: 44 - tn: 120 - precision: 0.8955 - recall: 0.7317 - accuracy: 0.8054 - f1-score: 0.8054\n",
      "2019-02-07 18:26:24,155 PER        tp: 140 - fp: 14 - fn: 20 - tn: 140 - precision: 0.9091 - recall: 0.8750 - accuracy: 0.8917 - f1-score: 0.8917\n",
      "2019-02-07 18:26:24,156 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8462,\n",
       " 'dev_score_history': [0.0151,\n",
       "  0.4041,\n",
       "  0.4304,\n",
       "  0.4596,\n",
       "  0.6164,\n",
       "  0.6085,\n",
       "  0.6385,\n",
       "  0.6302,\n",
       "  0.657,\n",
       "  0.7299,\n",
       "  0.7282,\n",
       "  0.7382,\n",
       "  0.7521,\n",
       "  0.7273,\n",
       "  0.7453,\n",
       "  0.7644,\n",
       "  0.7629,\n",
       "  0.7841,\n",
       "  0.7846,\n",
       "  0.7826,\n",
       "  0.7866,\n",
       "  0.8079,\n",
       "  0.7973,\n",
       "  0.7835,\n",
       "  0.7925,\n",
       "  0.8076,\n",
       "  0.8135,\n",
       "  0.8071,\n",
       "  0.8126,\n",
       "  0.822,\n",
       "  0.8283,\n",
       "  0.832,\n",
       "  0.8242,\n",
       "  0.8207,\n",
       "  0.8152,\n",
       "  0.8322,\n",
       "  0.8359,\n",
       "  0.8371,\n",
       "  0.8328,\n",
       "  0.8383,\n",
       "  0.8391,\n",
       "  0.8359,\n",
       "  0.8448,\n",
       "  0.8319,\n",
       "  0.8329,\n",
       "  0.8454,\n",
       "  0.8516,\n",
       "  0.8492,\n",
       "  0.8444,\n",
       "  0.8461,\n",
       "  0.8545,\n",
       "  0.8552,\n",
       "  0.8521,\n",
       "  0.8574,\n",
       "  0.8441,\n",
       "  0.8543,\n",
       "  0.8557,\n",
       "  0.8524,\n",
       "  0.8591,\n",
       "  0.8562,\n",
       "  0.8673,\n",
       "  0.8598,\n",
       "  0.8618,\n",
       "  0.8579,\n",
       "  0.8619,\n",
       "  0.8504,\n",
       "  0.8576,\n",
       "  0.855,\n",
       "  0.8717,\n",
       "  0.8657,\n",
       "  0.8685,\n",
       "  0.8699,\n",
       "  0.8693,\n",
       "  0.8677,\n",
       "  0.8619,\n",
       "  0.8672,\n",
       "  0.8702,\n",
       "  0.8661,\n",
       "  0.8678,\n",
       "  0.8702,\n",
       "  0.87,\n",
       "  0.8728,\n",
       "  0.8723,\n",
       "  0.87,\n",
       "  0.87,\n",
       "  0.8686,\n",
       "  0.8677,\n",
       "  0.8624,\n",
       "  0.8717,\n",
       "  0.87,\n",
       "  0.8664,\n",
       "  0.8695,\n",
       "  0.8719,\n",
       "  0.8734,\n",
       "  0.8709,\n",
       "  0.8711,\n",
       "  0.8713,\n",
       "  0.8685,\n",
       "  0.8723,\n",
       "  0.8735,\n",
       "  0.8743,\n",
       "  0.8721,\n",
       "  0.8743,\n",
       "  0.8711,\n",
       "  0.8726,\n",
       "  0.8706,\n",
       "  0.8733,\n",
       "  0.8714,\n",
       "  0.8726,\n",
       "  0.8724,\n",
       "  0.8719,\n",
       "  0.8719,\n",
       "  0.8719,\n",
       "  0.8719,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8719,\n",
       "  0.8719,\n",
       "  0.8719,\n",
       "  0.8728,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726,\n",
       "  0.8726],\n",
       " 'train_loss_history': [14.399444356133255,\n",
       "  9.329391001064511,\n",
       "  7.389685113562036,\n",
       "  6.559455026699115,\n",
       "  5.9062535220420385,\n",
       "  5.393319550476685,\n",
       "  4.952076357789959,\n",
       "  4.666250833278501,\n",
       "  4.374378303593997,\n",
       "  4.212774351805827,\n",
       "  4.0175851130978595,\n",
       "  3.8864776122721136,\n",
       "  3.6960591347397287,\n",
       "  3.5553400778945403,\n",
       "  3.5916844419513727,\n",
       "  3.3427725340860377,\n",
       "  3.4096074145662536,\n",
       "  3.39632506876329,\n",
       "  3.1839031883682547,\n",
       "  3.083974877701671,\n",
       "  3.0839644718997237,\n",
       "  2.932190061013169,\n",
       "  2.808694143467064,\n",
       "  2.828658306892909,\n",
       "  2.819837062497231,\n",
       "  2.7327936209385357,\n",
       "  2.662932743940296,\n",
       "  2.5984946257913806,\n",
       "  2.569731444498155,\n",
       "  2.615456485048463,\n",
       "  2.5819341698990734,\n",
       "  2.5015997247269666,\n",
       "  2.3499804592832394,\n",
       "  2.346273339534299,\n",
       "  2.4048491332274904,\n",
       "  2.3163956762394005,\n",
       "  2.5050112168895473,\n",
       "  2.4319247881359383,\n",
       "  2.2888100835941407,\n",
       "  2.2803534850667044,\n",
       "  2.380142570734819,\n",
       "  2.2259158719134695,\n",
       "  2.1900450812728507,\n",
       "  2.1456408357524808,\n",
       "  2.1880153963930056,\n",
       "  2.1396329662177944,\n",
       "  2.1147685773059317,\n",
       "  2.200956914645978,\n",
       "  2.106231007439204,\n",
       "  1.976600187631191,\n",
       "  1.9498362194465908,\n",
       "  1.9590007649651362,\n",
       "  1.97276202068876,\n",
       "  1.9209103167573955,\n",
       "  1.885184686926701,\n",
       "  1.8670130087742414,\n",
       "  1.9628781388011116,\n",
       "  1.8780460319493595,\n",
       "  1.8619749592176034,\n",
       "  1.8906614368481982,\n",
       "  1.7542383869621576,\n",
       "  1.8384630726209237,\n",
       "  1.8155331042228022,\n",
       "  1.7332555937560261,\n",
       "  1.855639875690646,\n",
       "  1.802851188970137,\n",
       "  1.7339647597197774,\n",
       "  1.7885098295103636,\n",
       "  1.667981455054102,\n",
       "  1.6480952995152693,\n",
       "  1.5283431790525552,\n",
       "  1.6263920553053435,\n",
       "  1.5398272144706986,\n",
       "  1.5857192173729426,\n",
       "  1.6726131082933056,\n",
       "  1.546754186832563,\n",
       "  1.536747814735784,\n",
       "  1.5728944469245774,\n",
       "  1.5095684288182682,\n",
       "  1.6794480953000241,\n",
       "  1.6258920500324598,\n",
       "  1.5008884503731654,\n",
       "  1.4839349216107451,\n",
       "  1.5567845655648687,\n",
       "  1.4773584051558462,\n",
       "  1.5075111732711945,\n",
       "  1.5367369521371996,\n",
       "  1.4683333569323722,\n",
       "  1.500920704796443,\n",
       "  1.4652581001775435,\n",
       "  1.421536700736689,\n",
       "  1.4603787588230206,\n",
       "  1.418167704657923,\n",
       "  1.357044264505194,\n",
       "  1.422190844972902,\n",
       "  1.3793087870856775,\n",
       "  1.4968815778715758,\n",
       "  1.429821714232014,\n",
       "  1.4543540298024205,\n",
       "  1.4737602842100626,\n",
       "  1.4484453983828574,\n",
       "  1.353400274305999,\n",
       "  1.4276235986344412,\n",
       "  1.3856293765444052,\n",
       "  1.335951147912899,\n",
       "  1.5030285833357493,\n",
       "  1.5326322373586785,\n",
       "  1.3647027502384401,\n",
       "  1.4376861287244882,\n",
       "  1.3806411292729495,\n",
       "  1.345424267830572,\n",
       "  1.3599304494418805,\n",
       "  1.3542963833392183,\n",
       "  1.3902841470017284,\n",
       "  1.4095893081145894,\n",
       "  1.399207198516459,\n",
       "  1.365138057075078,\n",
       "  1.3836247480416632,\n",
       "  1.3976882237287422,\n",
       "  1.4306914524844363,\n",
       "  1.3669153522697586,\n",
       "  1.3659021696939397,\n",
       "  1.39170546146772,\n",
       "  1.3976162483566519,\n",
       "  1.4015252213226788,\n",
       "  1.3699010921526624,\n",
       "  1.4256673422235104,\n",
       "  1.3983758858953659,\n",
       "  1.280252499927116,\n",
       "  1.3485279897596933,\n",
       "  1.2892528047873386,\n",
       "  1.3695555935707626,\n",
       "  1.3576480402319808,\n",
       "  1.3621030455036431,\n",
       "  1.3896872079555316,\n",
       "  1.3937273579012799,\n",
       "  1.3583397804855744],\n",
       " 'dev_loss_history': [11.484651565551758,\n",
       "  8.00063419342041,\n",
       "  6.865268707275391,\n",
       "  6.161204814910889,\n",
       "  5.04851770401001,\n",
       "  4.802422523498535,\n",
       "  4.708132266998291,\n",
       "  4.269636154174805,\n",
       "  3.7752463817596436,\n",
       "  3.421383857727051,\n",
       "  3.2870492935180664,\n",
       "  3.1554534435272217,\n",
       "  3.080587863922119,\n",
       "  3.3360908031463623,\n",
       "  3.1279313564300537,\n",
       "  2.6770544052124023,\n",
       "  2.7906570434570312,\n",
       "  2.560436248779297,\n",
       "  2.474886655807495,\n",
       "  2.5945229530334473,\n",
       "  2.42755126953125,\n",
       "  2.29115891456604,\n",
       "  2.286991596221924,\n",
       "  2.5909337997436523,\n",
       "  2.3506197929382324,\n",
       "  2.3370070457458496,\n",
       "  2.2573094367980957,\n",
       "  2.283285140991211,\n",
       "  2.085336208343506,\n",
       "  2.1221773624420166,\n",
       "  2.037412643432617,\n",
       "  2.0328619480133057,\n",
       "  2.189157247543335,\n",
       "  2.0500149726867676,\n",
       "  2.252671718597412,\n",
       "  1.930732250213623,\n",
       "  1.955492377281189,\n",
       "  1.9176994562149048,\n",
       "  1.9768410921096802,\n",
       "  1.8904988765716553,\n",
       "  1.9148156642913818,\n",
       "  1.9272228479385376,\n",
       "  1.8999634981155396,\n",
       "  2.1089909076690674,\n",
       "  2.019475221633911,\n",
       "  1.808577537536621,\n",
       "  1.7896325588226318,\n",
       "  1.7735211849212646,\n",
       "  1.880953311920166,\n",
       "  1.9321056604385376,\n",
       "  1.8169724941253662,\n",
       "  1.7750849723815918,\n",
       "  1.8130601644515991,\n",
       "  1.6607931852340698,\n",
       "  1.8676754236221313,\n",
       "  1.7711015939712524,\n",
       "  1.698488473892212,\n",
       "  1.7513738870620728,\n",
       "  1.6861191987991333,\n",
       "  1.8663150072097778,\n",
       "  1.6008226871490479,\n",
       "  1.6946018934249878,\n",
       "  1.622973918914795,\n",
       "  1.8497562408447266,\n",
       "  1.7609425783157349,\n",
       "  1.8775790929794312,\n",
       "  1.764596939086914,\n",
       "  1.6924940347671509,\n",
       "  1.7016375064849854,\n",
       "  1.6979480981826782,\n",
       "  1.650462031364441,\n",
       "  1.7104101181030273,\n",
       "  1.6786069869995117,\n",
       "  1.690239429473877,\n",
       "  1.6657755374908447,\n",
       "  1.657780408859253,\n",
       "  1.662394642829895,\n",
       "  1.6111981868743896,\n",
       "  1.6615263223648071,\n",
       "  1.6597117185592651,\n",
       "  1.6301988363265991,\n",
       "  1.6370697021484375,\n",
       "  1.62530517578125,\n",
       "  1.647095799446106,\n",
       "  1.6221667528152466,\n",
       "  1.6968814134597778,\n",
       "  1.6469906568527222,\n",
       "  1.6472229957580566,\n",
       "  1.6333950757980347,\n",
       "  1.6390137672424316,\n",
       "  1.6092621088027954,\n",
       "  1.613816499710083,\n",
       "  1.5773279666900635,\n",
       "  1.683760166168213,\n",
       "  1.640235424041748,\n",
       "  1.6114338636398315,\n",
       "  1.619263768196106,\n",
       "  1.6508713960647583,\n",
       "  1.62396240234375,\n",
       "  1.6395841836929321,\n",
       "  1.6367250680923462,\n",
       "  1.6294230222702026,\n",
       "  1.6515424251556396,\n",
       "  1.6244686841964722,\n",
       "  1.6165515184402466,\n",
       "  1.6078802347183228,\n",
       "  1.6340830326080322,\n",
       "  1.6283727884292603,\n",
       "  1.6143524646759033,\n",
       "  1.6203943490982056,\n",
       "  1.6214011907577515,\n",
       "  1.6311808824539185,\n",
       "  1.62839937210083,\n",
       "  1.6346741914749146,\n",
       "  1.6364457607269287,\n",
       "  1.6270614862442017,\n",
       "  1.6331238746643066,\n",
       "  1.629844069480896,\n",
       "  1.632576823234558,\n",
       "  1.6302361488342285,\n",
       "  1.6354681253433228,\n",
       "  1.6335948705673218,\n",
       "  1.6322838068008423,\n",
       "  1.633030652999878,\n",
       "  1.630998134613037,\n",
       "  1.6303826570510864,\n",
       "  1.630509376525879,\n",
       "  1.631484866142273,\n",
       "  1.6326338052749634,\n",
       "  1.6321085691452026,\n",
       "  1.6325280666351318,\n",
       "  1.6313472986221313,\n",
       "  1.633617877960205,\n",
       "  1.6331875324249268,\n",
       "  1.6329742670059204,\n",
       "  1.6326311826705933,\n",
       "  1.6325939893722534]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-ner',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. plot training curves (optional)\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_training_curves('resources/taggers/example-ner/loss.tsv')\n",
    "plotter.plot_weights('resources/taggers/example-ner/weights.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Training Curves](resources/taggers/example-ner/training.png \"Training Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Weights](resources/taggers/example-ner/weights.png \"Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model you trained\n",
    "model = SequenceTagger.load_from_file('resources/taggers/example-ner/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IU <S-ORG> is a great place to study NLP.\n",
      "Damir <B-PER> Cavar <E-PER> is on the faculty\n",
      "Bertolt <S-LOC> is a student.\n",
      "He was named after the playwright Bertolt Brecht.\n"
     ]
    }
   ],
   "source": [
    "# create example sentence\n",
    "sentences = [Sentence('IU is a great place to study NLP.'),\n",
    "             Sentence('Damir Cavar is on the faculty'),\n",
    "             Sentence('Bertolt is a student.'),\n",
    "             Sentence('He was named after the playwright Bertolt Brecht.')]\n",
    "\n",
    "# predict tags and print\n",
    "for sentence in sentences:\n",
    "    model.predict(sentence)\n",
    "    print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
